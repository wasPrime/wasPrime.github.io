{"meta":{"title":"wasPrime","subtitle":"Welcome to my Blog","description":"wasPrime's Blog","author":"wasPrime","url":"http://yoursite.com","root":"/"},"pages":[{"title":"[404]","date":"2020-03-31T02:34:38.955Z","updated":"2020-03-31T02:34:38.955Z","comments":true,"path":"404.html","permalink":"http://yoursite.com/404.html","excerpt":"","text":""},{"title":"about","date":"2020-03-12T11:53:45.000Z","updated":"2020-03-12T11:53:45.000Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"这里写正文，支持Markdown、HTML"},{"title":"categories","date":"2020-03-31T03:09:37.444Z","updated":"2020-03-31T03:09:37.444Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-03-31T03:10:24.082Z","updated":"2020-03-31T03:10:24.082Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"设计模式","slug":"设计模式","date":"2020-04-11T09:45:21.000Z","updated":"2020-04-11T09:45:21.000Z","comments":true,"path":"2020/04/11/设计模式/","link":"","permalink":"http://yoursite.com/2020/04/11/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","excerpt":"设计模式一览","text":"设计模式一览 常见的设计模式单例模式单例模式主要解决一个全局使用的类频繁的创建和销毁的问题。单例模式下可以确保某一个类只有一个实例，而且自行实例化并向整个系统提供这个实例。 单例模式有三个要素： 一是某个类只能有一个实例； 二是它必须自行创建这个实例； 三是它必须自行向整个系统提供这个实例。 优点： 在内存里只有一个实例，减少了内存的开销，尤其是频繁的创建和销毁实例（比如管理学院首页页面缓存）； 避免对资源的多重占用（比如写文件操作）。 缺点：没有接口，不能继承，与单一职责原则冲突，一个类应该只关心内部逻辑，而不关心外面怎么样来实例化。 使用场景 要求生产唯一序列号； WEB 中的计数器，不用每次刷新都在数据库里加一次，用单例先缓存起来； 创建的一个对象需要消耗的资源过多，比如 I/O 与数据库的连接等。 工厂模式工厂模式主要解决接口选择的问题。该模式下定义一个创建对象的接口，让其子类自己决定实例化哪一个工厂类，使其创建过程延迟到子类进行。 观察者模式定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。 装饰器模式对已经存在的某些类进行装饰，以此来扩展一些功能，从而动态的为一个对象增加新的功能。装饰器模式是一种用于代替继承的技术，无需通过继承增加子类就能扩展对象的新功能。使用对象的关联关系代替继承关系，更加灵活，同时避免类型体系的快速膨胀。 优点：装饰类和被装饰类可以独立发展，不会相互耦合，装饰模式是继承的一个替代模式，装饰模式可以动态扩展一个实现类的功能。 缺点：多层装饰比较复杂。 使用场景 扩展一个类的功能； 动态增加功能，动态撤销。 单例模式的多线程安全问题在单例模式的实现中，如果不采取任何措施，在多线程下是不安全的，可能会同时创建多个实例。因此，为了保证单例模式在多线程下的线程安全，一般采用下面几种方式实现单例模式 饿汉式基于class loader机制避免多线程的同步问题，不过，instance在类装载时就实例化，可能会产生垃圾对象。 懒汉式通过双重锁机制实现线程安全。 如何保证单例模式只有唯一实例？你知道的都有哪些方法单例的实现主要是通过以下两个步骤： 将该类的构造方法定义为私有方法，这样其他处的代码就无法通过调用该类的构造方法来实例化该类的对象，只有通过该类提供的静态方法来得到该类的唯一实例； 在该类内提供一个静态方法，当我们调用这个方法时，如果类持有的引用不为空就返回这个引用，如果类保持的引用为空就创建该类的实例并将实例的引用赋予该类保持的引用。 方法 饿汉式 懒汉式 OOP的设计模式的五项原则单一职责原则单一职责有2个含义，一个是避免相同的职责分散到不同的类中，另一个是避免一个类承担太多职责。减少类的耦合，提高类的复用性。 接口隔离原则表明客户端不应该被强迫实现一些他们不会使用的接口，应该把接口中的方法分组，然后用多个接口代替它，每个接口服务于一个子模块。简单说，就是使用多个专门的接口比使用单个接口好很多。 该原则观点如下： 一个类对另外一个类的依赖性应当是建立在最小的接口上； 客户端程序不应该依赖它不需要的接口方法。 开放-封闭原则open模块的行为必须是开放的、支持扩展的，而不是僵化的。 closed在对模块的功能进行扩展时，不应该影响或大规模影响已有的程序模块。一句话概括：一个模块在扩展性方面应该是开放的而在更改性方面应该是封闭的。核心思想就是对抽象编程，而不对具体编程。 替换原则子类型必须能够替换掉他们的父类型、并出现在父类能够出现的任何地方。 主要针对继承的设计原则： 父类的方法都要在子类中实现或者重写，并且派生类只实现其抽象类中生命的方法，而不应当给出多余的,方法定义或实现。 在客户端程序中只应该使用父类对象而不应当直接使用子类对象，这样可以实现运行期间绑定。 依赖倒置原则上层模块不应该依赖于下层模块，他们共同依赖于一个抽象，即：父类不能依赖子类，他们都要依赖抽象类。 抽象不能依赖于具体，具体应该要依赖于抽象。 说说工厂模式的优点解耦，代码复用，更改功能容易。 说一下观察者模式观察者模式中分为观察者和被观察者，当被观察者发生装填改变时，观察者会受到通知。主要为了解决对象状态改变给其他对象通知的问题，其实现类似于观察者在被观察者那注册了一个回调函数。 介绍一下单例模式C++的实现有两种，一种通过局部静态变量，利用其只初始化一次的特点，返回对象。另外一种，则是定义全局的指针，getInstance判断该指针是否为空，为空时才实例化对象。 C++实现Meyers Singleton（最推荐的写法）class Singleton { public: static Singleton &amp;getInstance() { static Singleton instance; return instance; } private: Singleton() { cout &lt;&lt; &quot;构造&quot; &lt;&lt; endl; } Singleton(const Singleton &amp;) {} Singleton operator=(const Singleton &amp;) {} ~Singleton() { cout &lt;&lt; &quot;析构&quot; &lt;&lt; endl; } }; 饿汉式class Singleton { public: static Singleton &amp;getInstance() { return instance; } private: static Singleton instance; Singleton() { cout &lt;&lt; &quot;构造&quot; &lt;&lt; endl; } Singleton(const Singleton &amp;) {} Singleton operator=(const Singleton &amp;) {} ~Singleton() { cout &lt;&lt; &quot;析构&quot; &lt;&lt; endl; } }; Singleton Singleton::instance; 懒汉式class Singleton { private: static Singleton *instance; Singleton() { cout &lt;&lt; &quot;构造&quot; &lt;&lt; endl; }; Singleton(const Singleton &amp;); Singleton &amp;operator=(const Singleton &amp;); ~Singleton() { cout &lt;&lt; &quot;析构&quot; &lt;&lt; endl; }; public: static Singleton *getInstance() { if (instance == nullptr) instance = new Singleton(); return instance; } }; Singleton *Singleton::instance = nullptr; 但是上述写法存在内存泄漏问题 单例模式中的懒汉加载，如果并发访问该怎么做使用锁机制，防止多次访问。 第一次判断为空不加锁，若为空，再进行加锁判断是否为空，若为空则生成对象。","categories":[{"name":"面经知识汇总","slug":"面经知识汇总","permalink":"http://yoursite.com/categories/%E9%9D%A2%E7%BB%8F%E7%9F%A5%E8%AF%86%E6%B1%87%E6%80%BB/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://yoursite.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"数据库整理","slug":"数据库整理","date":"2020-04-04T02:08:54.000Z","updated":"2020-04-04T02:08:54.000Z","comments":true,"path":"2020/04/04/数据库整理/","link":"","permalink":"http://yoursite.com/2020/04/04/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%95%B4%E7%90%86/","excerpt":"面试常见的数据库考点","text":"面试常见的数据库考点 增删改查库 增 create database 库名称; create database 库名称 charset 编码方式; 删 drop database 库名称; 改 修改编码方式：alter database 库名称 charset 编码方式; 查 查看所有库：show databases; 表 增 增加表单：create table 表名称(字段1 数据类型, 字段2 数据类型…限制条件); 删 删除表：drop table 表名称; 清空表里面数据：truncate table 表名称; 改 字段 添加字段：alter table 表名称 add 字段 字段数据类型; 删除字段：alter table 表名称 drop 字段; 修改字段数据类型：alter table 表名称 modify 字段 新的数据类型; 替换字段：alter table 表名称 change 旧字段名称 新字段 新字段数据类型; 表 改表名称：rename table 表名称 to 新名称; 改表的编码：alter table 表名 charset 新编码; 查 查看所有表：show tables; 查看指定表信息：desc table 表名称; 查看指定表创建信息：show create table 表名称; 表里数据 增 插入一个值 insert into 表名 values(v1, v2,…); # 该方式必须保证插入的数据个数与表格字段一一对应 insert into 表名(字段名称1, 字段名称2) values(v1,v2) 插入多个值 insert into 表名 values(v1), (v2); insert into 表名(字段名称1, 字段名称2) values(v1, v1), (v2, v2); 删 删除所有：delete from 表名; 删除指定条件下：delete from 表名 where 条件; 改 修改所有数据：update 表名 set 字段名称 = 新的值, 字段名称2 = 值2; 修改满足条件的数据：update 表名 set 字段名称 = 新的值, 字段名称2 = 值2 where 条件; 查 查看所有字段：select * from 表名; 查看指定字段：select 字段 from 表名; 查看某个条件所有的字段：select * from 表名 where 条件; 查看某个条件下的某个字段：select 字段 from 表名 where 条件; 数据库基础说一说数据库索引索引是对数据库表中一列或多列的值进行排序的一种结构，使用索引可快速访问数据库表中的特定信息。如果想按特定职员的姓来查找他或她，则与在表中搜索所有的行相比，索引有助于更快地获取信息。索引的一个主要目的就是加快检索表中数据的方法，亦即能协助信息搜索者尽快的找到符合限制条件的记录ID的辅助数据结构。 说一说数据库事务数据库事务(Database Transaction) ，是指作为单个逻辑工作单元执行的一系列操作，要么完全地执行，要么完全地不执行。 事务处理可以确保除非事务性单元内的所有操作都成功完成，否则不会永久更新面向数据的资源。通过将一组相关操作组合为一个要么全部成功要么全部失败的单元，可以简化错误恢复并使应用程序更加可靠。一个逻辑工作单元要成为事务，必须满足所谓的ACID（原子性、一致性、隔离性和持久性）属性。事务是数据库运行中的逻辑工作单位，由DBMS中的事务管理子系统负责事务的处理。 数据库事务隔离同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰。比如A正在从一张银行卡中取钱，在A取钱的过程结束前，B不能向这张卡转账。 说一说inner join和left join left join（左联接）返回包括左表中的所有记录和右表中联结字段相等的记录 right join（右联接）返回包括右表中的所有记录和左表中联结字段相等的记录 inner join（等值连接）只返回两个表中联结字段相等的行 聊一聊数据库事物的一致性事务（Transaction）是由一系列对系统中数据进行访问与更新的操作所组成的一个程序执行逻辑单元。事务是DBMS中最基础的单位，事务不可分割。事务具有4个基本特征，分别是：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Duration），简称ACID。 原子性（Atomicity）原子性是指事务包含的所有操作要么全部成功，要么全部失败回滚，因此事务的操作如果成功就必须要完全应用到数据库，如果操作失败则不能对数据库有任何影响。 一致性（Consistency）一致性是指事务必须使数据库从一个一致性状态变换到另一个一致性状态，也就是说一个事务执行之前和执行之后都必须处于一致性状态。拿转账来说，假设用户A和用户B两者的钱加起来一共是5000，那么不管A和B之间如何转账，转几次账，事务结束后两个用户的钱相加起来应该还得是5000，这就是事务的一致性。 隔离性（Isolation）隔离性是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。即要达到这么一种效果：对于任意两个并发的事务T1和T2，在事务T1看来，T2要么在T1开始之前就已经结束，要么在T1结束之后才开始，这样每个事务都感觉不到有其他事务在并发地执行。多个事务并发访问时，事务之间是隔离的，一个事务不应该影响其它事务运行效果。这指的是在并发环境中，当不同的事务同时操纵相同的数据时，每个事务都有各自的完整数据空间。由并发事务所做的修改必须与任何其他并发事务所做的修改隔离。不同的隔离级别：Read Uncommitted（读取未提交内容）：最低的隔离级别，什么都不需要做，一个事务可以读到另一个事务未提交的结果。所有的并发事务问题都会发生。Read Committed（读取提交内容）：只有在事务提交后，其更新结果才会被其他事务看见。可以解决脏读问题。Repeated Read（可重复读）：在一个事务中，对于同一份数据的读取结果总是相同的，无论是否有其他事务对这份数据进行操作，以及这个事务是否提交。可以解决脏读、不可重复读。Serialization（可串行化）：事务串行化执行，隔离级别最高，牺牲了系统的并发性。可以解决并发事务的所有问题。 另一种解读未提交读READ UNCOMMITTED：一个事务在提交之前，对其他事务是可见的，即事务可以读取未提交的数据。存在“脏读”（读到了脏数据）问题；提交读READ COMMITTED：事务在提交之前，对其它事务是不可见的。存在“不可重复读”（两次查询的得到的结果可能不同，即可能在查询的间隙，有事务提交了修改）问题。解决了“脏读”问题。可重复读REPEATABLE READ：在同一事务中多次读取的数据是一致的。解决了脏读和不可重复读问题，存在“幻读”（在事务两次查询间隙，有其他事务又插入或删除了新的记录）。—- MySQL默认隔离级别。可串行化SERIALIZABLE：强制事务串行化执行。即一个事物一个事物挨个来执行，可以解决上述所有问题。 持久性（Durability）持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。例如我们在使用JDBC操作数据库时，在提交事务方法后，提示用户事务操作完成，当我们程序执行完成直到看到提示后，就可以认定事务以及正确提交，即使这时候数据库出现了问题，也必须要将我们的事务完全执行完成，否则就会造成我们看到提示事务处理完毕，但是数据库因为故障而没有执行事务的重大错误。 索引数据库索引是为了增加查询速度而对表字段附加的一种标识，是对数据库表中一列或多列的值进行排序的一种结构。 DB在执行一条SQL语句的时候，默认的方式是根据搜索条件进行全表扫描，遇到匹配条件的就加入搜索结果集合。如果我们对某一字段增加索引，查询时就会先去索引列表中一次定位到特定值的行数，大大减少遍历匹配的行数，所以能明显增加查询的速度。 实现方法一般分为B+树索引和哈希索引。 B+树索引在B-tree上改进得到，其非叶子节点均为key值，叶子节点是key-data键值对。叶子节点前后相连且有序。 哈希索引通过对key进行hash(crc/MD5/sha1/sha256…)而将记录存储在不同的bucket种，可以做到常数时间的查找，但要注意哈希冲突的避免（链表法、线性探测、二次探测、公共溢出区的方法）。其中MD5 128位，和sha1/256码都较长不太适合作为hash函数。默认无序。 为什么有了B+树索引还要hash索引 B+树默认有序，hash默认无序，所以哈希索引无法用于排序； 哈希索引 $O(1)$ 在速度上毋庸置疑要快于B+树近似 $O(\\log_2n)$； 哈希索引只能进行等值查询（因为他要计算hash(key)再去匹配）而B+树索引可以进行等值、部分前缀、范围查询； 底层实现结构不同：B+树是非线性结构，hash桶是线性结构。 对于某些场景如热点页/活跃查询页，需要借助哈希索引来实现快速查询。 优点 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。 可以大大加快数据的检索速度，这也是创建索引的最主要的原因。 可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义。 在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间。 通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。 缺点 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。 索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果要建立聚簇索引，那么需要的空间就会更大。 当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度。 添加索引原则 在查询中很少使用或者参考的列不应该创建索引。 这是因为，既然这些列很少使用到，因此有索引或者无索引，并不能提高查询速度。相反，由于增加了索引，反而降低了系统的维护速度和增大了空间需求。 只有很少数据值的列也不应该增加索引。 这是因为，由于这些列的取值很少，例如人事表的性别列，在查询的结果中，结果集的数据行占了表中数据行的很大比例，即需要在表中搜索的数据行的比例很大。增加索引，并不能明显加快检索速度。 定义为text、image和bit数据类型的列不应该增加索引。 这是因为，这些列的数据量要么相当大，要么取值很少。 当修改性能远远大于检索性能时，不应该创建索引。 这是因为，修改性能和检索性能是互相矛盾的。当增加索引时，会提高检索性能，但是会降低修改性能。当减少索引时，会提高修改性能，降低检索性能。因此，当修改性能远远大于检索性能时，不应该创建索引。 索引不是越多越快此言差矣，索引并非是虚无缥缈的，是实实在在的一种数据结构（B+树/hash桶）要占内存、维护它要系统开销，一般的插入删除都要进行结构的调整，这要消耗时间，所以索引太多反而拖慢查找时间。有时候，见数据量不多时，建立索引还不如全表查询。索引加快了检索的速度，但是插入删除修改都需要DBMS动态更新内部索引结构，要耗费开销。 说一说数据库的三大范式 第一范式：当关系模式R的所有属性都不能再分解为更基本的数据单位时，称R是满足第一范式，即属性不可分。 第二范式：如果关系模式R满足第一范式，并且R得所有非主属性都完全依赖于R的每一个候选关键属性，称R满足第二范式 第三范式：设R是一个满足第一范式条件的关系模式，X是R的任意属性集，如果X非传递依赖于R的任意一个候选关键字，称R满足第三范式，即非主属性不传递依赖于键码。 MySQLMySQL的四种隔离状态MySQL主要包含四种隔离状态： 事务隔离级别 脏读 不可重复读 幻读 未提交读（read-uncommitted） 是 是 是 不可重复读（提交读）（read-committed） 否 是 是 可重复读（repeatable-read） 否 否 是 串行化（serializable） 否 否 否 MySQL的MVCC机制MVCC是一种多版本并发控制机制，是MySQL的InnoDB存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别。MVCC是通过保存数据在某个时间点的快照来实现该机制，其在每行记录后面保存两个隐藏的列，分别保存这个行的创建版本号和删除版本号，然后Innodb的MVCC使用到的快照存储在Undo日志中，该日志通过回滚指针把一个数据行所有快照连接起来。 SQL优化方法有哪些 通过建立索引对查询进行优化 对查询进行优化，应尽量避免全表扫描 MySQL引擎和区别MySQL引擎MySQL中的数据用各种不同的技术存储在文件（或者内存）中。这些技术中的每一种技术都使用不同的存储机制、索引技巧、锁定水平并且最终提供广泛的不同的功能和能力。通过选择不同的技术，你能够获得额外的速度或者功能，从而改善你的应用的整体功能。 数据库引擎是用于存储、处理和保护数据的核心服务。利用数据库引擎可控制访问权限并快速处理事务，从而满足企业内大多数需要处理大量数据的应用程序的要求。使用数据库引擎创建用于联机事务处理或联机分析处理数据的关系数据库。这包括创建用于存储数据的表和用于查看、管理和保护数据安全的数据库对象（如索引、视图和存储过程）。 MySQL存储引擎主要有： MyIsam、InnoDB、Memory、Blackhole、CSV、Performance_Schema、Archive、Federated、Mrg_Myisam。 但是最常用的是InnoDB和Mylsam。 InnoDBInnoDB是一个事务型的存储引擎，有行级锁定和外键约束。 Innodb引擎提供了对数据库ACID事务的支持，并且实现了SQL标准的四种隔离级别，关于数据库事务与其隔离级别的内容请见数据库事务与其隔离级别这类型的文章。该引擎还提供了行级锁和外键约束，它的设计目标是处理大容量数据库系统，它本身其实就是基于MySQL后台的完整数据库系统，MySQL运行时Innodb会在内存中建立缓冲池，用于缓冲数据和索引。但是该引擎不支持FULLTEXT类型的索引，而且它没有保存表的行数，当SELECT COUNT(*) FROM TABLE时需要扫描全表。当需要使用数据库事务时，该引擎当然是首选。由于锁的粒度更小，写操作不会锁定全表，所以在并发较高时，使用Innodb引擎会提升效率。但是使用行级锁也不是绝对的，如果在执行一个SQL语句时MySQL不能确定要扫描的范围，InnoDB表同样会锁全表。 适用场景：经常更新的表，适合处理多重并发的更新请求。 支持事务。 可以从灾难中恢复（通过bin-log日志等）。 外键约束。只有它支持外键。 支持自动增加列属性auto_increment。 索引结构： InnoDB也是B+Tree索引结构。Innodb的索引文件本身就是数据文件，即B+Tree的数据域存储的就是实际的数据，这种索引就是聚集索引。这个索引的key就是数据表的主键，因此InnoDB表数据文件本身就是主索引。 InnoDB的辅助索引数据域存储的也是相应记录主键的值而不是地址，所以当以辅助索引查找时，会先根据辅助索引找到主键，再根据主键索引找到实际的数据。所以Innodb不建议使用过长的主键，否则会使辅助索引变得过大。建议使用自增的字段作为主键，这样B+Tree的每一个结点都会被顺序的填满，而不会频繁的分裂调整，会有效的提升插入数据的效率。 MylsamMyIASM是MySQL默认的引擎，但是它没有提供对数据库事务的支持，也不支持行级锁和外键，因此当INSERT或UPDATE数据时即写操作需要锁定整个表，效率便会低一些。MyIsam 存储引擎独立于操作系统，也就是可以在windows上使用，也可以比较简单的将数据转移到linux操作系统上去。 适用场景： 不支持事务的设计，但是并不代表着有事务操作的项目不能用MyIsam存储引擎，可以在service层进行根据自己的业务需求进行相应的控制。 不支持外键的表设计。 查询速度很快，如果数据库insert和update的操作比较多的话比较适用。 整天对表进行加锁的场景。 MyISAM极度强调快速读取操作。 MyIASM中存储了表的行数，于是SELECT COUNT(*) FROM TABLE时只需要直接读取已经保存好的值而不需要进行全表扫描。如果表的读操作远远多于写操作且不需要数据库事务的支持，那么MyIASM也是很好的选择。 缺点：就是不能在表损坏后主动恢复数据。 索引结构： MyISAM索引结构：MyISAM索引用的B+ tree来储存数据，MyISAM索引的指针指向的是键值的地址，地址存储的是数据。B+Tree的数据域存储的内容为实际数据的地址，也就是说它的索引和实际的数据是分开的，只不过是用索引指向了实际的数据，这种索引就是所谓的非聚集索引。 InnoDB和Mylsam的区别 事务：MyISAM类型不支持事务处理等高级处理，而InnoDB类型支持，提供事务支持已经外部键等高级数据库功能。 性能：MyISAM类型的表强调的是性能，其执行数度比InnoDB类型更快。 行数保存：InnoDB 中不保存表的具体行数，也就是说，执行select count() fromtable时，InnoDB要扫描一遍整个表来计算有多少行，但是MyISAM只要简单的读出保存好的行数即可。注意的是，当count()语句包含where条件时，两种表的操作是一样的。 索引存储：对于AUTO_INCREMENT类型的字段，InnoDB中必须包含只有该字段的索引，但是在MyISAM表中，可以和其他字段一起建立联合索引。MyISAM支持全文索引（FULLTEXT）、压缩索引，InnoDB不支持。MyISAM的索引和数据是分开的，并且索引是有压缩的，内存使用率就对应提高了不少。能加载更多索引，而Innodb是索引和数据是紧密捆绑的，没有使用压缩从而会造成Innodb比MyISAM体积庞大不小。（InnoDB缺点）InnoDB存储引擎被完全与MySQL服务器整合，InnoDB存储引擎为在主内存中缓存数据和索引而维持它自己的缓冲池。InnoDB存储它的表＆索引在一个表空间中，表空间可以包含数个文件（或原始磁盘分区）。这与MyISAM表不同，比如在MyISAM表中每个表被存在分离的文件中。InnoDB 表可以是任何尺寸，即使在文件尺寸被限制为2GB的操作系统上。 服务器数据备份：InnoDB必须导出SQL来备份，LOAD TABLE FROM MASTER操作对InnoDB是不起作用的，解决方法是首先把InnoDB表改成MyISAM表，导入数据后再改成InnoDB表，但是对于使用的额外的InnoDB特性（例如外键）的表不适用。MyISAM应对错误编码导致的数据恢复速度快。MyISAM的数据是以文件的形式存储，所以在跨平台的数据转移中会很方便。在备份和恢复时可单独针对某个表进行操作。InnoDB是拷贝数据文件、备份 binlog，或者用 mysqldump，在数据量达到几十G的时候就相对痛苦了。 锁的支持：MyISAM只支持表锁。InnoDB支持表锁、行锁，行锁大幅度提高了多用户并发操作的新能。但是InnoDB的行锁，只是在WHERE的主键是有效的，非主键的WHERE都会锁全表的。","categories":[{"name":"面经知识汇总","slug":"面经知识汇总","permalink":"http://yoursite.com/categories/%E9%9D%A2%E7%BB%8F%E7%9F%A5%E8%AF%86%E6%B1%87%E6%80%BB/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"计算机网络整理","slug":"计算机网络整理","date":"2020-04-03T13:53:10.000Z","updated":"2020-04-03T13:53:10.000Z","comments":true,"path":"2020/04/03/计算机网络整理/","link":"","permalink":"http://yoursite.com/2020/04/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%95%B4%E7%90%86/","excerpt":"面试常见的计算机网络考点","text":"面试常见的计算机网络考点 综合OSI七层模型和TCP/IP四层模型，每层列举2个协议OSI七层模型及其包含的协议如下：物理层：通过媒介传输比特，确定机械及电气规范，传输单位为 bit，主要包括的协议为：IEE802.3、CLOCK、RJ45数据链路层：将比特组装成帧和点到点的传递，传输单位为 帧，主要包括的协议为MAC、VLAN、PPP网络层：负责数据包从源到宿的传递和网际互连，传输单位为 包，主要包括的协议为IP、ARP、ICMP传输层：提供端到端的可靠报文传递和错误恢复，传输单位为 报文，主要包括的协议为TCP、UDP会话层：建立、管理和终止会话，传输单位为 SPDU，主要包括的协议为RPC、NFS表示层：对数据进行翻译、加密和压缩，传输单位为 PPDU，主要包括的协议为JPEG、ASCII应用层：允许访问OSI环境的手段，传输单位为 APDU，主要包括的协议为FTP、HTTP、DNS TCP/IP4层模型包括：网络接口层：MAC、VLAN网络层:IP、ARP、ICMP传输层:TCP、UDP应用层:HTTP、DNS、SMTP 搜索baidu，会用到计算机网络中的什么层？每层是干什么的浏览器中输入URL，浏览器要将URL解析为IP地址，解析域名就要用到DNS协议，首先主机会查询DNS的缓存，如果没有就给本地DNS发送查询请求。DNS查询分为两种方式，一种是 递归查询，一种是 迭代查询。如果是迭代查询，本地的DNS服务器，向根域名服务器发送查询请求，根域名服务器告知该域名的一级域名服务器，然后本地服务器给该一级域名服务器发送查询请求，然后依次类推直到查询到该域名的IP地址。DNS服务器是基于UDP的，因此会用到UDP协议。 递归查询： 也就是DNS客户端送出查询要求后，如果DNS服务器内没有需要的数据，则DNS服务器会代替客户端向其他的DNS服务顺查询。（我帮你查） 循环查询： 一般DNS服务器与DNS服务器之间的查询属于这种查询方式。当第一台DNS服务器在向第2台DNS服务器提出查询要求后，如果第2台DNS服务器内没有所需要的数据，则它会提供第3台DNS服务器的IP地址给第1台。（我把下个的地址给你你自己去查） 得到IP地址后，浏览器就要与服务器建立一个http连接。因此要用到 http协议，http协议报文格式上面已经提到。http生成一个get请求报文，将该报文传给TCP层处理，所以还会用到 TCP协议。如果采用https还会使用https协议先对http数据进行加密。TCP层如果有需要先将HTTP数据包分片，分片依据路径MTU和MSS。TCP的数据包然后会发送给IP层，用到 IP协议。IP层通过路由选路，一跳一跳发送到目的地址。当然在一个网段内的寻址是通过以太网协议实现（也可以是其他物理层协议，比如PPP、SLIP），以太网协议需要直到目的IP地址的物理地址，有需要 ARP协议。 其中： DNS协议、http协议、https协议属于应用层 应用层是体系结构中的最高层。应用层确定进程之间通信的性质以满足用户的需要。这里的进程就是指正在运行的程序。应用层不仅要提供应用进程所需要的信息交换和远地操作，而且还要作为互相作用的应用进程的用户代理，来完成一些为进行语义上有意义的信息交换所必须的功能。应用层直接为用户的应用进程提供服务。 TCP/UDP属于传输层 传输层的任务就是负责主机中两个进程之间的通信。因特网的传输层可使用两种不同协议：即面向连接的传输控制协议TCP，和无连接的用户数据报协议UDP。面向连接的服务能够提供可靠的交付，但无连接服务则不保证提供可靠的交付，它只是“尽最大努力交付”。这两种服务方式都很有用，备有其优缺点。在分组交换网内的各个交换结点机都没有传输层。 IP协议、ARP协议属于网络层 网络层负责为分组交换网上的不同主机提供通信。在发送数据时，网络层将运输层产生的报文段或用户数据报封装成分组或包进行传送。在TCP/IP体系中，分组也叫作IP数据报，或简称为数据报。网络层的另一个任务就是要选择合适的路由，使源主机运输层所传下来的分组能够交付到目的主机。 数据链路层 当发送数据时，数据链路层的任务是将在网络层交下来的IP数据报组装成帧，在两个相邻结点间的链路上传送以帧为单位的数据。每一帧包括数据和必要的控制信息（如同步信息、地址信息、差错控制、以及流量控制信息等）。控制信息使接收端能够知道—个帧从哪个比特开始和到哪个比特结束。控制信息还使接收端能够检测到所收到的帧中有无差错。 物理层 物理层的任务就是透明地传送比特流。在物理层上所传数据的单位是比特。传递信息所利用的一些物理媒体，如双绞线、同轴电缆、光缆等，并不在物理层之内而是在物理层的下面。因此也有人把物理媒体当做第0层。 过程在浏览器地址栏键入URL，按下回车之后会经历以下流程：1、浏览器向 DNS 服务器请求解析该 URL 中的域名所对应的 IP 地址；2、解析出 IP 地址后，根据该 IP 地址和默认端口80，和服务器建立TCP连接；3、浏览器发出读取文件（URL中域名后面部分对应的文件）的HTTP 请求，该请求报文作为 TCP 三次握手的第三个报文的数据发送给服务器；4、服务器对浏览器请求作出响应，并把对应的 html 文本发送给浏览器；5、释放 TCP 连接；6、浏览器将该 html 文本并显示内容。 TCP/IPTCP的三次握手与四次挥手序列号seq：占4个字节，用来标记数据段的顺序，TCP把连接中发送的所有数据字节都编上一个序号，第一个字节的编号由本地随机产生；给字节编上序号后，就给每一个报文段指派一个序号；序列号seq就是这个报文段中的第一个字节的数据编号。 确认号ack：占4个字节，期待收到对方下一个报文段的第一个数据字节的序号；序列号表示报文段携带数据的第一个字节的编号；而确认号指的是期望接收到下一个字节的编号；因此当前报文段最后一个字节的编号+1即为确认号。 确认ACK：占1位，仅当ACK = 1时，确认号字段才有效。ACK = 0时，确认号无效 同步SYN：连接建立时用于同步序号。当SYN=1，ACK=0时表示：这是一个连接请求报文段。若同意连接，则在响应报文段中使得SYN=1，ACK=1。因此，SYN=1表示这是一个连接请求，或连接接受报文。SYN这个标志位只有在TCP建产连接时才会被置1，握手完成后SYN标志位被置0。 终止FIN：用来释放一个连接。FIN = 1表示：此报文段的发送方的数据已经发送完毕，并要求释放运输连接 PS：ACK、SYN和FIN这些大写的单词表示标志位，其值要么是1，要么是0；ack、seq小写的单词表示序号。 字段 含义 URG 紧急指针是否有效。为1，表示某一位需要被优先处理 ACK 确认号是否有效，一般置为1。 PSH 提示接收端应用程序立即从TCP缓冲区把数据读走。 RST 对方要求重新建立连接，复位。 SYN 请求建立连接，并在其序列号的字段进行序列号的初始值设定。建立连接，设置为1 FIN 希望断开连接。 三次握手理解 第一次握手：建立连接时，客户端发送syn包（syn=x）到服务器，并进入SYN_SENT状态，等待服务器确认；SYN：同步序列编号（Synchronize Sequence Numbers）。 第二次握手：服务器收到syn包，必须确认客户的SYN（ack=x+1），同时自己也发送一个SYN包（syn=y），即SYN+ACK包，此时服务器进入SYN_RECV状态； 第三次握手：客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK(ack=y+1），此包发送完毕，客户端和服务器进入ESTABLISHED（TCP连接成功）状态，完成三次握手。 四次挥手过程理解 客户端进程发出连接释放报文，并且停止发送数据。释放数据报文首部，FIN=1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时，客户端进入FIN-WAIT-1（终止等待1）状态。 TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。 服务器收到连接释放报文，发出确认报文，ACK=1，ack=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了CLOSE-WAIT（关闭等待）状态。TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。 客户端收到服务器的确认请求后，此时，客户端就进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。 服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，FIN=1，ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。 客户端收到服务器的连接释放报文后，必须发出确认，ACK=1，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态。注意此时TCP连接还没有释放，必须经过2∗∗MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入CLOSED状态。 服务器只要收到了客户端发出的确认，立即进入CLOSED状态。同样，撤销TCB后，就结束了这次的TCP连接。可以看到，服务器结束TCP连接的时间要比客户端早一些。 常见考点为什么连接的时候是三次握手，关闭的时候却是四次握手答：因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，”你发的FIN报文我收到了”。只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。 为什么TIME_WAIT状态需要经过2MSL(最大报文段生存时间)才能返回到CLOSE状态答：虽然按道理，四个报文都发送完毕，我们可以直接进入CLOSE状态了，但是我们必须假设网络是不可靠的，有可以最后一个ACK丢失。所以TIME_WAIT状态就是用来重发可能丢失的ACK报文。在Client发送出最后的ACK回复，但该ACK可能丢失。Server如果没有收到ACK，将不断重复发送FIN片段。所以Client不能立即关闭，它必须确认Server接收到了该ACK。Client会在发送出ACK之后进入到TIME_WAIT状态。Client会设置一个计时器，等待2MSL的时间。如果在该时间内再次收到FIN，那么Client会重发ACK并再次等待2MSL。所谓的2MSL是两倍的MSL(Maximum Segment Lifetime)。MSL指一个片段在网络中最大的存活时间，2MSL就是一个发送和一个回复所需的最大时间。如果直到2MSL，Client都没有再次收到FIN，那么Client推断ACK已经被成功接收，则结束TCP连接。 为什么不能用两次握手进行连接答：3次握手完成两个重要的功能，既要双方做好发送数据的准备工作（双方都知道彼此已准备好），也要允许双方就初始序列号进行协商，这个序列号在握手过程中被发送和确认。 现在把三次握手改成仅需要两次握手，有两种解释： 死锁 是可能发生的。作为例子，考虑计算机S和C之间的通信，假定C给S发送一个连接请求分组，S收到了这个分组，并发 送了确认应答分组。按照两次握手的协定，S认为连接已经成功地建立了，可以开始发送数据分组。可是，C在S的应答分组在传输中被丢失的情况下，将不知道S 是否已准备好，不知道S建立什么样的序列号，C甚至怀疑S是否收到自己的连接请求分组。在这种情况下，C认为连接还未建立成功，将忽略S发来的任何数据分组，只等待连接确认应答分组。而S在发出的分组超时后，重复发送同样的分组。这样就形成了死锁。 客户端发起了一个连接请求在网络中滞留了很长时间，以至于在连接建立好并断开连接后，它才到达服务端，那么服务端就会认为这是新的连接请求，于是建立连接，但是实际上客户端根本就没有发送建立请求，也不会理睬服务端，因此导致服务端空等而浪费资源。 如果已经建立了连接，但是客户端突然出现故障了怎么办答：TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。 UDP 和 TCP 的特点 用户数据报协议 UDP（User Datagram Protocol） 是 无连接 的，尽最大可能交付，没有拥塞控制，面向报文（对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部），支持一对一、一对多、多对一和多对多的交互通信。 传输控制协议 TCP（Transmission Control Protocol） 是 面向连接 的，提供可靠交付，有流量控制，拥塞控制，提供全双工通信，面向字节流（把应用层传下来的报文看成字节流，把字节流组织成大小不等的数据块），每一条 TCP 连接只能是点对点的（一对一）。 TCP拥塞控制，以及达到什么情况的时候开始减慢增长的速度拥塞控制是防止过多的数据注入网络，使得网络中的路由器或者链路过载。流量控制是点对点的通信量控制，而拥塞控制是全局的网络流量整体性的控制。发送双方都有一个拥塞窗口——cwnd。 慢开始最开始发送方的拥塞窗口为1，由小到大逐渐增大发送窗口和拥塞窗口。每经过一个传输轮次，拥塞窗口cwnd加倍。当cwnd超过慢开始门限，则使用拥塞避免算法，避免cwnd增长过大。 拥塞避免每经过一个往返时间RTT，cwnd就增长1。在慢开始和拥塞避免的过程中，一旦发现网络拥塞，就把慢开始门限设为当前值的一半，并且重新设置cwnd为1，重新慢启动。（乘法减小，加法增大） 快重传接收方每次收到一个失序的报文段后就立即发出重复确认，发送方只要连续收到三个重复确认就立即重传（尽早重传未被确认的报文段）。 快恢复当发送方连续收到了三个重复确认，就乘法减半（慢开始门限减半），将当前的cwnd设置为慢开始门限，并且采用拥塞避免算法（连续收到了三个重复请求，说明当前网络可能没有拥塞）。采用快恢复算法时，慢开始只在建立连接和网络超时才使用。 达到什么情况的时候开始减慢增长的速度？ 答： 采用慢开始和拥塞避免算法的时候 一旦cwnd &gt; 慢开始门限，就采用拥塞避免算法，减慢增长速度 一旦出现丢包的情况，就重新进行慢开始，减慢增长速度 采用快恢复和快重传算法的时候 一旦cwnd &gt; 慢开始门限，就采用拥塞避免算法，减慢增长速度 一旦发送方连续收到了三个重复确认，就采用拥塞避免算法，减慢增长速度 TCP用了哪些措施保证其可靠性 序列号、确认应答、超时重传数据到达接收方，接收方需要发出一个确认应答，表示已经收到该数据段，并且确认序号会说明了它下一次需要接收的数据序列号。如果发送发迟迟未收到确认应答，那么可能是发送的数据丢失，也可能是确认应答丢失，这时发送方在等待一定时间后会进行重传。这个时间一般是2*RTT(报文段往返时间）+一个偏差值。 窗口控制与高速重发控制/快速重传（重复确认应答）TCP会利用窗口控制来提高传输速度，意思是在一个窗口大小内，不用一定要等到应答才能发送下一段数据，窗口大小就是无需等待确认而可以继续发送数据的最大值。如果不使用窗口控制，每一个没收到确认应答的数据都要重发。使用窗口控制，如果数据段1001-2000丢失，后面数据每次传输，确认应答都会不停地发送序号为1001的应答，表示我要接收1001开始的数据，发送端如果收到3次相同应答，就会立刻进行重发；但还有种情况有可能是数据都收到了，但是有的应答丢失了，这种情况不会进行重发，因为发送端知道，如果是数据段丢失，接收端不会放过它的，会疯狂向它提醒…… 拥塞控制如果把窗口定的很大，发送端连续发送大量的数据，可能会造成网络的拥堵（大家都在用网，你在这狂发，吞吐量就那么大，当然会堵），甚至造成网络的瘫痪。所以TCP在为了防止这种情况而进行了拥塞控制。慢启动：定义拥塞窗口，一开始将该窗口大小设为1，之后每次收到确认应答（经过一个RTT），将拥塞窗口大小*2。拥塞避免：设置慢启动阈值，一般开始都设为65536。拥塞避免是指当拥塞窗口大小达到这个阈值，拥塞窗口的值不再指数上升，而是加法增加（每次确认应答/每个RTT，拥塞窗口大小+1），以此来避免拥塞。将报文段的超时重传看做拥塞，则一旦发生超时重传，我们需要先将阈值设为当前窗口大小的一半，并且将窗口大小设为初值1，然后重新进入慢启动过程。快速重传：在遇到3次重复确认应答（高速重发控制）时，代表收到了3个报文段，但是这之前的1个段丢失了，便对它进行立即重传。然后，先将阈值设为当前窗口大小的一半，然后将拥塞窗口大小设为慢启动阈值+3的大小。这样可以达到：在TCP通信时，网络吞吐量呈现逐渐的上升，并且随着拥堵来降低吞吐量，再进入慢慢上升的过程，网络不会轻易的发生瘫痪。 IP地址作用，以及MAC地址作用MAC地址是一个硬件地址，用来定义网络设备的位置，主要由 数据链路层 负责。而IP地址是IP协议提供的一种 统一的地址格式，为互联网上的每一个网络和每一台主机分配一个逻辑地址，以此来屏蔽物理地址的差异。 TCP/IP数据链路层的交互过程网络层等到数据链路层用MAC地址作为通信目标，数据包到达网络等准备往数据链层发送的时候，首先会去自己的ARP缓存表(存着IP-MAC对应关系)去查找改目标IP的MAC地址，如果查到了，就讲目标IP的MAC地址封装到链路层数据包的包头。如果缓存中没有找到，会发起一个广播：who is ip XXX tell ip XXX，所有收到的广播的机器看这个IP是不是自己的，如果是自己的，则以单拨的形式将自己的MAC地址回复给请求的机器。 传递到IP层怎么知道报文该给哪个应用程序，它怎么区分UDP报文还是TCP报文根据端口区分：看ip头中的协议标识字段，17是UDP，6是TCP。 DNSDNS解析 在浏览器中输入一个域名，例如www.tmall.com，操作系统会先检查自己本地的hosts文件是否有这个网址映射关系，如果有，就先调用这个IP地址映射，完成域名解析， windows下hosts文件在C:/Windows/System32/drivers/etc/hosts下，linux一般都在/etc/hosts下。 如果hosts里没有这个ip到域名的映射，那么就要查找本地DNS解析器缓存，是否有这个域名到ip地址的映射关系，如果有，直接返回，完成域名解析。 如果本机的hosts与本地DNS解析器缓存都没有相应的网址映射关系，那么就要找到你的TCP/ip参数中设置的首选DNS服务器，我们叫它本地DNS服务器，此服务器收到查询时，如果要查询的域名，包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析，此解析具有权威性。 如果要查询的域名，不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个域名到ip地址的映射，完成域名解析，但是此解析不具有权威性。 如果本地DNS服务器本地区域文件与缓存解析都失效，则根据本地DNS服务器的设置（是否设置转发器）进行查询，如果未用转发模式，本地DNS就把请求发至13台根DNS，根DNS服务器收到请求后会判断这个域名(.com)是谁来授权管理，并会返回一个负责该顶级域名服务器的一个IP。本地DNS服务器收到IP信息后，将会联系负责.com域的这台服务器。这台负责(.com)域名的服务器收到请求后，如果自己无法解析，它就会找一个管理(.com)域的下一级DNS服务器地址 (tmall.com)给本地DNS服务器。当本地DNS服务器收到这个地址后，就会找(tmall.com)域服务器，重复上面的动作，进行查询，直至找到 (www.tmall.com)主机。 如果用的是转发模式，此DNS服 务器就会把请求转发至上一级DNS服务器，由上一级服务器进行解析，上一级服务器如果不能解析，或找根DNS或把转请求转至上上级，以此循环。不管是本地 DNS服务器用是是转发，还是根提示，最后都是把结果返回给本地DNS服务器，由此DNS服务器再返回给客户机。 这里我们把从客户端到本地DNS服务器的查找称为递归查询，而DNS服务器之间的交互查询称为迭代查询。 DNS劫持DNS劫持又称域名劫持，是指在劫持的网络范围内拦截域名解析的请求，分析请求的域名，把审查范围以外的请求放行，否则返回假的IP地址或者什么都不做使请求失去响应，其效果就是对特定的网络不能反应或访问的是假网址。举一个简单的例子，比如你输入的域名地址是www.google.cn然后弹出来百度的页面，很明显发生了DNS域名劫持。 应对DNS劫持的方法 我们都知道，访问一个网站用域名而不用ip地址的原因就是逻辑地址不好记，但是如果你知道这个网页的ip地址的话，你可以直接输入ip地址来访问从而绕开DNS解析。 将自己的电脑DNS解析地址手动设置为国内比较权威又稳定的服务器地址，例如114.114.114.114、8.8.8.8。 修改你的路由器密码，登录路由器192.168.1.1，更改你的用户密码，然后最好重新启动路由器。 作为运营商来处理DNS劫持，一般运营商都会有提供多台DNS解析服务器，负责一个区域的DNS解析至少会有两台，其中的一台发生了DNS劫持运营商就会停止该服务器的网络地址解析工作而启动备预案，这样就可以预防发生DNS劫持而导致用户主机受到攻击甚至发生某些不法的钓鱼网站窃取用户账户密码，造成财务损失的严重事故。 HTTP/HTTPSHTTP和HTTPS的区别，以及HTTPS有什么缺点HTTP协议和HTTPS协议区别如下： HTTP协议是以 明文 的方式在网络中传输数据，而HTTPS协议传输的数据则是经过 TLS加密 后的，HTTPS具有更高的安全性 HTTPS在TCP三次握手阶段之后，还需要进行SSL的handshake，协商加密使用的对称加密密钥 HTTPS协议需要服务端申请证书，浏览器端安装对应的根证书 HTTP协议端口是80，HTTPS协议端口是443 HTTPS优点： HTTPS传输数据过程中使用密钥进行加密，所以安全性更高 HTTPS协议可以认证用户和服务器，确保数据发送到正确的用户和服务器 HTTPS缺点： HTTPS握手阶段延时较高：由于在进行HTTP会话之前还需要进行SSL握手，因此HTTPS协议握手阶段延时增加 HTTPS部署成本高：一方面HTTPS协议需要使用证书来验证自身的安全性，所以需要购买CA证书；另一方面由于采用HTTPS协议需要进行加解密的计算，占用CPU资源较多，需要的服务器配置或数目高。 HTTP返回码HTTP协议的响应报文由状态行、响应头部和响应包体组成，其响应状态码总体描述如下：1xx：指示信息——表示请求已接收，继续处理。2xx：成功——表示请求已被成功接收、理解、接受。3xx：重定向——要完成请求必须进行更进一步的操作。4xx：客户端错误——请求有语法错误或请求无法实现。5xx：服务器端错误——服务器未能实现合法的请求。 常见状态代码、状态描述的详细说明如下：200 OK：客户端请求成功。206 partial content服务器已经正确处理部分GET请求，实现断点续传或同时分片下载，该请求必须包含Range请求头来指示客户端期望得到的范围。300 multiple choices（可选重定向）:被请求的资源有一系列可供选择的反馈信息，由浏览器/用户自行选择其中一个。301 moved permanently（永久重定向）：该资源已被永久移动到新位置，将来任何对该资源的访问都要使用本响应返回的若干个URI之一。302 move temporarily(临时重定向)：请求的资源现在临时从不同的URI中获得，304 not modified:如果客户端发送一个待条件的GET请求并且该请求以经被允许，而文档内容未被改变，则返回304,该响应不包含包体（即可直接使用缓存）。403 Forbidden：服务器收到请求，但是拒绝提供服务。404 not Found：请求资源不存在，举个例子：输入了错误的URL。 HTTP过程概述HTTP协议定义Web客户端如何从Web服务器请求Web页面，以及服务器如何把Web页面传送给客户端。HTTP协议采用了请求/响应模型。客户端向服务器发送一个请求报文，请求报文包含请求的方法、URL、协议版本、请求头部和请求数据。服务器以一个状态行作为响应，响应的内容包括协议的版本、成功或者错误代码、服务器信息、响应头部和响应数据。 HTTP请求/响应的步骤如下： 客户端连接到Web服务器一个HTTP客户端，通常是浏览器，与Web服务器的HTTP端口（默认为80）建立一个TCP套接字连接。例如：http://www.baidu.com 发送HTTP请求通过TCP套接字，客户端向Web服务器发送一个文本的请求报文，一个请求报文由请求行、请求头部、空行和请求数据4部分组成。 服务器接受请求并返回HTTP响应Web服务器解析请求，定位请求资源。服务器将资源复本写到TCP套接字，由客户端读取。一个响应由状态行、响应头部、空行和响应数据4部分组成。 释放连接TCP连接若connection模式为close，则服务器主动关闭TCP连接，客户端被动关闭连接，释放TCP连接；若connection模式为keepalive，则该连接会保持一段时间，在该时间内可以继续接收请求。 客户端浏览器解析HTML内容客户端浏览器首先解析状态行，查看表明请求是否成功的状态代码。然后解析每一个响应头，响应头告知以下为若干字节的HTML文档和文档的字符集。客户端浏览器读取响应数据HTML，根据HTML的语法对其进行格式化，并在浏览器窗口中显示。 GET和POST的区别 概括对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）；而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据） 区别： get参数通过url传递，post放在request body中。 get请求在url中传递的参数是有长度限制的，而post没有。 get比post更不安全，因为参数直接暴露在url中，所以不能用来传递敏感信息。 get请求只能进行url编码，而post支持多种编码方式。 get请求会浏览器主动cache，而post支持多种编码方式。 get请求参数会被完整保留在浏览历史记录里，而post中的参数不会被保留。 GET和POST本质上就是TCP链接，并无差别。但是由于HTTP的规定和浏览器/服务器的限制，导致他们在应用过程中体现出一些不同。 GET产生一个TCP数据包；POST产生两个TCP数据包。 session和cookie的区别 cookie数据存放在客户的浏览器上，session数据放在服务器上。 cookie不是很安全，别人可以分析存放在本地的cookie并进行cookie欺骗，考虑到安全应当使用session。 session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能，考虑到减轻服务器性能方面，应当使用cookie。 单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie。 可以考虑将登陆信息等重要信息存放为session，其他信息如果需要保留，可以放在cookie中。","categories":[{"name":"面经知识汇总","slug":"面经知识汇总","permalink":"http://yoursite.com/categories/%E9%9D%A2%E7%BB%8F%E7%9F%A5%E8%AF%86%E6%B1%87%E6%80%BB/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://yoursite.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"常见排序及时间复杂度","slug":"常见排序及时间复杂度","date":"2020-03-31T09:15:19.000Z","updated":"2020-03-31T09:15:19.000Z","comments":true,"path":"2020/03/31/常见排序及时间复杂度/","link":"","permalink":"http://yoursite.com/2020/03/31/%E5%B8%B8%E8%A7%81%E6%8E%92%E5%BA%8F%E5%8F%8A%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6/","excerpt":"必知必会排序方式","text":"必知必会排序方式 冒泡排序时间复杂度 $O(n ^ 2)$ def BubbleSort(nums: List[int]) -&gt; None: n = len(nums) for i in range(n - 1): for j in range(n - i - 1): if nums[j] &gt; nums[j + 1]: nums[j], nums[j + 1] = nums[j + 1], nums[j] 插入排序顺序插入时间复杂度 $O(n ^ 2)$ def InsertSort(nums: List[int]) -&gt; None: n = len(nums) for i in range(n): temp = nums[i] j = i - 1 while j &gt;= 0 and nums[j] &gt; temp: nums[j + 1] = nums[j] j -= 1 nums[j + 1] = temp 折半插入时间复杂度 $O(n ^ 2)$ （内循环查找复杂度为 $O(n\\log_2n)$，移位复杂度为 $O(n)$，故内循环总复杂度为 $O(n ^ 2)$） def HInsertSort(nums: List[int]) -&gt; None: n = len(nums) for i in range(n): temp = nums[i] low, high = 0, i - 1 while low &lt;= high: mid = low + (high - low) // 2 if nums[mid] &gt; temp: high = mid - 1 else: low = mid + 1 for j in range(i - 1, high, -1): nums[j + 1] = nums[j] nums[high + 1] = temp 希尔排序时间复杂度比 $O(n ^ 2)$ 要好 def ShellSort(nums: List[int]) -&gt; None: n = len(nums) dk = n // 2 # 外层步长控制 while dk &gt;= 1: # 开始插入排序 for i in range(dk, n): # 满足条件则交换 while i &gt;= dk and nums[i]&lt;nums[i-dk]: nums[i], nums[i-dk] = nums[i-dk], nums[i] i-=dk dk //= 2 快速排序时间复杂度 $O(n\\log_2n)$ def QuickSort(nums: List[int], low: int, high: int) -&gt; None: def partition(nums: List[int], low: int, high: int) -&gt; int: pivot = nums[low] while low &lt; high: while low &lt; high and nums[high] &gt;= pivot: high -= 1 nums[low] = nums[high] while low &lt; high and nums[low] &lt;= pivot: low += 1 nums[high] = nums[low] nums[low] = pivot return low if low &lt; high: pos = partition(nums, low, high) QuickSort(nums, low, pos - 1) QuickSort(nums, pos + 1, high) 简单选择排序时间复杂度 $O(n ^ 2)$ def SelectSort(nums: List[int]) -&gt; None: n = len(nums) for i in range(n - 1): min = i for j in range(i + 1, n): if nums[j] &lt; nums[min]: min = j if min != i: nums[i], nums[min] = nums[min], nums[i] 堆排序时间复杂度 $O(n\\log_2n)$ def HeapSort(nums: List[int]) -&gt; None: # 调整为大根堆 def adjust(nums: List[int], length: int, index: int) -&gt; None: left, right = 2 * index + 1, 2 * index + 2 # index的左右子节点 maxIdx = index if left &lt; length and nums[left] &gt; nums[maxIdx]: maxIdx = left if right &lt; length and nums[right] &gt; nums[maxIdx]: maxIdx = right if maxIdx != index: nums[maxIdx], nums[index] = nums[index], nums[maxIdx] adjust(nums, length, maxIdx) n = len(nums) for i in range(n // 2 - 1, -1, -1): adjust(nums, n, i) for i in range(n - 1, 0, -1): nums[0], nums[i] = nums[i], nums[0] adjust(nums, i, 0)","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"http://yoursite.com/categories/Algorithm/"}],"tags":[{"name":"排序","slug":"排序","permalink":"http://yoursite.com/tags/%E6%8E%92%E5%BA%8F/"}]},{"title":"操作系统整理","slug":"操作系统整理","date":"2020-03-21T06:53:58.000Z","updated":"2020-03-21T06:53:58.000Z","comments":true,"path":"2020/03/21/操作系统整理/","link":"","permalink":"http://yoursite.com/2020/03/21/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%95%B4%E7%90%86/","excerpt":"面试常见的操作系统考点","text":"面试常见的操作系统考点 说一下进程与线程的概念，以及为什么要有进程线程，其中有什么区别，他们各自又是怎么同步的基本概念 进程 是对运行时程序的 封装，是系统进行资源调度和分配的的基本单位，实现了操作系统的并发； 线程 是进程的子任务，是CPU调度和分派的基本单位，用于保证程序的实时性，实现进程内部的并发；线程是 操作系统可识别的最小执行和调度单位。每个线程都独自占用一个虚拟处理器：独自的寄存器组，指令计数器和处理器状态。每个线程完成不同的任务，但是共享同一地址空间（也就是同样的动态内存，映射文件，目标代码等等），打开的文件队列和其他内核资源。 区别 一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。线程依赖于进程而存在。 进程在执行过程中拥有独立的内存单元，而多个线程共享进程的内存。（资源分配给进程，同一进程的所有线程共享该进程的所有资源。同一进程中的多个线程共享代码段（代码和常量），数据段（全局变量和静态变量），扩展段（堆存储）。 但是每个线程拥有自己的栈段，栈段又叫运行时段，用来存放所有局部变量和临时变量。） 进程是资源分配的最小单位，线程是CPU调度的最小单位； 系统开销：由于在创建或撤消进程时，系统都要为之分配或回收资源，如内存空间、I／O设备等。因此，操作系统所付出的开销将显著地大于在创建或撤消线程时的开销。类似地，在进行进程切换时，涉及到整个当前进程CPU环境的保存以及新被调度运行的进程的CPU环境的设置。而线程切换只须保存和设置少量寄存器的内容，并不涉及存储器管理方面的操作。可见，进程切换的开销也远大于线程切换的开销。 通信：由于同一进程中的多个线程具有相同的地址空间，致使它们之间的同步和通信的实现，也变得比较容易。进程间通信IPC，线程间可以直接读写进程数据段（如全局变量）来进行通信——需要进程同步和互斥手段的辅助，以保证数据的一致性。在有的系统中，线程的切换、同步和通信都无须操作系统内核的干预。 进程编程调试简单可靠性高，但是创建销毁开销大；线程正相反，开销小，切换速度快，但是编程调试相对复杂。 进程间不会相互影响；线程一个线程挂掉将导致整个进程挂掉 进程适应于多核、多机分布；线程适用于多核。 进程间通信的方式进程间通信主要包括 管道、系统IPC（包括消息队列、信号量、信号、共享内存等）、以及 套接字socket。 管道 管道 主要包括 无名管道 和 命名管道：管道可用于具有亲缘关系的父子进程间的通信，有名管道除了具有管道所具有的功能外，它还允许无亲缘关系进程间的通信。 普通管道PIPE 它是 半双工 的（即数据只能在一个方向上流动），具有固定的读端和写端； 它只能用于具有亲缘关系的进程之间的通信（也是父子进程或者兄弟进程之间）； 它可以看成是一种特殊的文件，对于它的读写也可以使用普通的read、write等函数。但是它不是普通的文件，并不属于其他任何文件系统，并且只存在于内存中。 命名管道FIFO FIFO可以在无关的进程之间交换数据 FIFO有路径名与之相关联，它以一种特殊设备文件形式存在于文件系统中。 系统IPC 消息队列 消息队列，是消息的链接表，存放在内核中。一个消息队列由一个标识符（即队列ID）来标记。（消息队列克服了信号传递信息少，管道只能承载无格式字节流以及缓冲区大小受限等特点）具有写权限得进程可以按照一定得规则向消息队列中添加新信息；对消息队列有读权限得进程则可以从消息队列中读取信息； 特点： 消息队列是面向记录的，其中的消息具有特定的格式以及特定的优先级。 消息队列独立于发送与接收进程。进程终止时，消息队列及其内容并不会被删除。 消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取。 信号量semaphore 信号量（semaphore）与已经介绍过的 IPC 结构不同，它是一个计数器，可以用来控制多个进程对共享资源的访问。信号量用于实现进程间的互斥与同步，而不是用于存储进程间通信数据。 特点： 信号量用于进程间同步，若要在进程间传递数据需要结合共享内存。 信号量基于操作系统的 PV 操作，程序对信号量的操作都是原子操作。 每次对信号量的 PV 操作不仅限于对信号量值加 1 或减 1，而且可以加减任意正整数。 支持信号量组。 信号signal 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。 共享内存（Shared Memory） 它使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据得更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等 特点： 共享内存是最快的一种IPC，因为进程是直接对内存进行存取； 因为多个进程可以同时操作，所以需要进行同步； 信号量+共享内存通常结合在一起使用，信号量用来同步对共享内存的访问。 套接字socket socket 也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同主机之间的进程通信。 线程间通信的方式 临界区：通过多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问； 互斥量Synchronized/Lock：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问 信号量Semaphore：为控制具有有限数量的用户资源而设计的，它允许多个线程在同一时刻去访问同一个资源，但一般需要限制同一时刻访问此资源的最大线程数目。 事件（信号），Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作 说一说Linux虚拟地址空间为了防止不同进程同一时刻在物理内存中运行而对物理内存的争夺和践踏，采用了虚拟内存。虚拟内存技术使得不同进程在运行过程中，它所看到的是自己独自占有了当前系统的4G内存。所有进程共享同一物理内存，每个进程只把自己目前需要的虚拟内存空间映射并存储到物理内存上。 事实上，在每个进程创建加载时，内核只是为进程「创建」了虚拟内存的布局，具体就是初始化进程控制表中内存相关的链表，实际上并不立即就把虚拟内存对应位置的程序数据和代码（比如 .text、.data 段）拷贝到物理内存中，只是建立好虚拟内存和磁盘文件之间的映射就好（叫做存储器映射），等到运行到对应的程序时，才会通过缺页异常，来拷贝数据。还有进程运行过程中，要动态分配内存，比如 malloc 时，也只是分配了虚拟内存，即为这块虚拟内存对应的页表项做相应设置，当进程真正访问到此数据时，才引发缺页异常。 请求分页系统、请求分段系统和请求段页式系统都是针对虚拟内存的，通过请求实现内存与外存的信息置换。 虚拟内存的好处： 扩大地址空间； 内存保护：每个进程运行在各自的虚拟内存地址空间，互相不能干扰对方。虚存还对特定的内存地址提供写保护，可以防止代码或数据被恶意篡改。 公平内存分配：采用了虚存之后，每个进程都相当于有同样大小的虚存空间。 当进程通信时，可采用虚存共享的方式实现。 当不同的进程使用同样的代码时，比如库文件中的代码，物理内存中可以只存储一份这样的代码，不同的进程只需要把自己的虚拟内存映射过去就可以了，节省内存。 虚拟内存很适合在多道程序设计系统中使用，许多程序的片段同时保存在内存中。当一个程序等待它的一部分读入内存时，可以把CPU交给另一个进程使用。在内存中可以保留多个进程，系统并发度提高。 在程序需要分配连续的内存空间的时候，只需要在虚拟内存空间分配连续空间，而不需要实际物理内存的连续空间，可以利用碎片。 虚拟内存的代价： 虚存的管理需要建立很多数据结构，这些数据结构要占用额外的内存。 虚拟地址到物理地址的转换，增加了指令的执行时间。 页面的换入换出需要磁盘I/O，这是很耗时的。 如果一页中只有一部分数据，会浪费内存。 说一说操作系统中的程序的内存结构一个程序本质上都是由 BSS段、data段、text段 三个组成的。可以看到一个可执行程序在存储（没有调入内存）时分为代码段、数据区和未初始化数据区三部分。 BSS段（未初始化数据区）： 通常用来存放程序中未初始化的全局变量和静态变量的一块内存区域。BSS段属于静态分配，程序结束后静态变量资源由系统自动释放。 数据段： 存放程序中已初始化的全局变量的一块内存区域。数据段也属于静态内存分配 代码段： 存放程序执行代码的一块内存区域。这部分区域的大小在程序运行前就已经确定，并且内存区域属于只读。在代码段中，也有可能包含一些只读的常数变量 text段和data段在编译时已经分配了空间，而BSS段并不占用可执行文件的大小，它是由链接器来获取内存的。 BSS段（未进行初始化的数据）的内容并不存放在磁盘上的程序文件中。其原因是内核在程序开始运行前将它们设置为0。需要存放在程序文件中的只有正文段和初始化数据段。 data段（已经初始化的数据）则为数据分配空间，数据保存到目标文件中。 数据段包含经过初始化的全局变量以及它们的值。BSS段的大小从可执行文件中得到，然后链接器得到这个大小的内存块，紧跟在数据段的后面。当这个内存进入程序的地址空间后全部清零。包含数据段和BSS段的整个区段此时通常称为数据区。 可执行程序在运行时又多出两个区域：栈区和堆区。 栈区： 由编译器自动释放，存放函数的参数值、局部变量等。每当一个函数被调用时，该函数的返回类型和一些调用的信息被存放到栈中。然后这个被调用的函数再为他的自动变量和临时变量在栈上分配空间。每调用一个函数一个新的栈就会被使用。栈区是从高地址位向低地址位增长的，是一块连续的内存区域，最大容量是由系统预先定义好的，申请的栈空间超过这个界限时会提示溢出，用户能从栈中获取的空间较小。 堆区： 用于动态分配内存，位于BSS和栈中间的地址区域。由程序员申请分配和释放。堆是从低地址位向高地址位增长，采用链式存储结构。频繁的malloc/free造成内存空间的不连续，产生碎片。当申请堆空间时库函数是按照一定的算法搜索可用的足够大的空间。因此堆的效率比栈要低的多。 A* a = new A; a-&gt;i = 10; 在内核中的内存分配上发生了什么 A *a：a是一个局部变量，类型为指针，故而操作系统在程序栈区开辟4/8字节的空间（0x000m），分配给指针a。 new A：通过new动态的在堆区申请类A大小的空间（0x000n）。 a = new A：将指针a的内存区域填入栈中类A申请到的地址的地址。即*(0x000m) = 0x000n。 a-&gt;i：先找到指针a的地址0x000m，通过a的值0x000n和i在类a中偏移offset，得到a-&gt;i的地址0x000n + offset，进行 *(0x000n + offset) = 10 的赋值操作，即内存0x000n + offset的值是10。 说一说操作系统中的缺页中断malloc() 和 mmap() 等内存分配函数，在分配时只是建立了进程虚拟地址空间，并没有分配虚拟内存对应的物理内存。当进程访问这些没有建立映射关系的虚拟内存时，处理器自动触发一个缺页异常。 缺页中断：在请求分页系统中，可以通过查询页表中的状态位来确定所要访问的页面是否存在于内存中。每当所要访问的页面不在内存是，会产生一次缺页中断，此时操作系统会根据页表中的外存地址在外存中找到所缺的一页，将其调入内存。 缺页本身是一种中断，与一般的中断一样，需要经过4个处理步骤： 保护CPU现场； 分析中断原因； 转入缺页中断处理程序进行处理； 恢复CPU现场，继续执行。 但是缺页中断是由于所要访问的页面不存在于内存时，由硬件所产生的一种特殊的中断，因此，与一般的中断存在 区别： 在指令执行期间产生和处理缺页中断信号； 一条指令在执行期间，可能产生多次缺页中断； 缺页中断返回是，执行产生中断的一条指令，而一般的中断返回是，执行下一条指令。 回答一下 fork 和 vfork 的区别fork的基础知识fork：创建一个和当前进程映像一样的进程可以通过 fork() 系统调用： #include &lt;sys/types.h&gt; #include &lt;unistd.h&gt; pid_t fork(void); 成功调用 fork() 会创建一个新的进程，它几乎与调用 fork() 的进程一模一样，这两个进程都会继续运行。在子进程中，成功的 fork() 调用会返回0。在父进程中 fork() 返回子进程的pid。如果出现错误，fork() 返回一个负值。 最常见的 fork() 用法是创建一个新的进程，然后使用 exec() 载入二进制映像，替换当前进程的映像。这种情况下，派生（fork）了新的进程，而这个子进程会执行一个新的二进制可执行文件的映像。这种“派生加执行”的方式是很常见的。 在早期的Unix系统中，创建进程比较原始。当调用fork时，内核会把所有的内部数据结构复制一份，复制进程的页表项，然后把父进程的地址空间中的内容逐页的复制到子进程的地址空间中。但从内核角度来说，逐页的复制方式是十分耗时的。现代的Unix系统采取了更多的优化，例如Linux，采用了写时复制的方法，而不是对父进程空间进程整体复制。 vfork的基础知识在实现写时复制之前，Unix的设计者们就一直很关注在fork后立刻执行exec所造成的地址空间的浪费。BSD的开发者们在3.0的BSD系统中引入了 vfork( ) 系统调用。 #include &lt;sys/types.h&gt; #include &lt;unistd.h&gt; pid_t vfork(void); 除了子进程必须要立刻执行一次对exec的系统调用，或者调用 _exit() 退出，对 vfork() 的成功调用所产生的结果和 fork() 是一样的。 vfork() 会挂起父进程直到子进程终止或者运行了一个新的可执行文件的映像。通过这样的方式，vfork() 避免了地址空间的按页复制。在这个过程中，父进程和子进程共享相同的地址空间和页表项。实际上 vfork() 只完成了一件事：复制内部的内核数据结构。因此，子进程也就不能修改地址空间中的任何内存。 vfork() 是一个历史遗留产物，Linux本不应该实现它。需要注意的是，即使增加了写时复制，vfork() 也要比 fork() 快，因为它没有进行页表项的复制。然而，写时复制的出现减少了对于替换 fork() 争论。实际上，直到2.2.0内核，vfork() 只是一个封装过的 fork()。因为对 vfork() 的需求要小于 fork()，所以 vfork() 的这种实现方式是可行的。 补充知识点：写时复制 Linux采用了写时复制的方法，以减少fork时对父进程空间进程整体复制带来的开销。 写时复制是一种采取了惰性优化方法来避免复制时的系统开销。它的前提很简单：如果有多个进程要读取它们自己的那部门资源的副本，那么复制是不必要的。每个进程只要保存一个指向这个资源的指针就可以了。只要没有进程要去修改自己的“副本”，就存在着这样的幻觉：每个进程好像独占那个资源。从而就避免了复制带来的负担。如果一个进程要修改自己的那份资源“副本”，那么就会复制那份资源，并把复制的那份提供给进程。不过其中的复制对进程来说是透明的。这个进程就可以修改复制后的资源了，同时其他的进程仍然共享那份没有修改过的资源。所以这就是名称的由来：在写入时进行复制。 写时复制的主要好处在于：如果进程从来就不需要修改资源，则不需要进行复制。惰性算法的好处就在于它们尽量推迟代价高昂的操作，直到必要的时刻才会去执行。 在使用虚拟内存的情况下，写时复制（Copy-On-Write）是以页为基础进行的。所以，只要进程不修改它全部的地址空间，那么就不必复制整个地址空间。在fork( )调用结束后，父进程和子进程都相信它们有一个自己的地址空间，但实际上它们共享父进程的原始页，接下来这些页又可以被其他的父进程或子进程共享。 写时复制在内核中的实现非常简单。与内核页相关的数据结构可以被标记为只读和写时复制。如果有进程试图修改一个页，就会产生一个缺页中断。内核处理缺页中断的方式就是对该页进行一次透明复制。这时会清除页面的COW属性，表示着它不再被共享。 现代的计算机系统结构中都在内存管理单元（MMU）提供了硬件级别的写时复制支持，所以实现是很容易的。 在调用 fork() 时，写时复制是有很大优势的。因为大量的fork之后都会跟着执行exec，那么复制整个父进程地址空间中的内容到子进程的地址空间完全是在浪费时间：如果子进程立刻执行一个新的二进制可执行文件的映像，它先前的地址空间就会被交换出去。写时复制可以对这种情况进行优化。 fork和vfork的区别 fork() 的子进程拷贝父进程的数据段和代码段；vfork() 的子进程与父进程共享数据段 fork() 的父子进程的执行次序不确定；vfork() 保证子进程先运行，在调用exec或exit之前与父进程数据是共享的，在它调用exec或exit之后父进程才可能被调度运行。 vfork() 保证子进程先运行，在它调用exec或exit之后父进程才可能被调度运行。如果在调用这两个函数之前子进程依赖于父进程的进一步动作，则会导致死锁。 当需要改变共享数据段中变量的值，则拷贝父进程。 如何修改文件最大句柄数linux默认最大文件句柄数是1024个，在linux服务器文件并发量比较大的情况下，系统会报”too many open files”的错误。故在linux服务器高并发调优时，往往需要预先调优Linux参数，修改Linux最大文件句柄数。 有两种方法： ulimit -n &lt;可以同时打开的文件数&gt; 将当前进程的最大句柄数修改为指定的参数（注：该方法只针对当前进程有效，重新打开一个shell或者重新开启一个进程，参数还是之前的值） 首先用ulimit -a查询Linux相关的参数，如下所示： core file size (blocks, -c) 0data seg size (kbytes, -d) unlimitedscheduling priority (-e) 0file size (blocks, -f) unlimitedpending signals (-i) 94739max locked memory (kbytes, -l) 64max memory size (kbytes, -m) unlimitedopen files (-n) 1024pipe size (512 bytes, -p) 8POSIX message queues (bytes, -q) 819200real-time priority (-r) 0stack size (kbytes, -s) 8192cpu time (seconds, -t) unlimitedmax user processes (-u) 94739virtual memory (kbytes, -v) unlimitedfile locks (-x) unlimited 其中，open files就是最大文件句柄数，默认是1024个。 修改Linux最大文件句柄数：ulimit -n 2048，将最大句柄数修改为2048个。 对所有进程都有效的方法，修改Linux系统参数 vi /etc/security/limits.conf 添加 soft nofile 65536 hard nofile 65536 将最大句柄数改为65536，修改以后保存，注销当前用户，重新登录，修改后的参数就生效了。 说一说并发(concurrency)和并行(parallelism)并发（concurrency）：指宏观上看起来两个程序在同时运行，比如说在单核CPU上的多任务。但是从微观上看两个程序的指令是交织着运行的，你的指令之间穿插着我的指令，我的指令之间穿插着你的，在单个周期内只运行了一个指令。这种并发并不能提高计算机的性能，只能提高效率。 并行（parallelism）：指严格物理意义上的同时运行，比如多核CPU，两个程序分别运行在两个核上，两者之间互不影响，单个周期内每个程序都运行了自己的指令，也就是运行了两条指令。这样说来并行的确提高了计算机的效率。所以现在的CPU都是往多核方面发展。 MySQL的端口号是多少，如何修改这个端口号查看端口号使用命令 show global variables like &#39;port&#39;; 查看端口号 ，MySQL的默认端口是3306。（补充：sqlserver默认端口号为：1433；oracle默认端口号为：1521；DB2默认端口号为：5000；PostgreSQL默认端口号为：5432） 修改端口号编辑 /etc/my.cnf 文件，早期版本有可能是 my.conf 文件名，增加端口参数，并且设定端口，注意该端口未被使用，保存退出。 说一说操作系统中的页表寻址页式内存管理，内存分成固定长度的一个个页片。操作系统为每一个进程维护了一个从虚拟地址到物理地址的映射关系的数据结构，叫页表，页表的内容就是该进程的虚拟地址到物理地址的一个映射。页表中的每一项都记录了这个页的基地址。通过页表，由逻辑地址的高位部分先找到逻辑地址对应的页基地址，再由页基地址偏移一定长度就得到最后的物理地址，偏移的长度由逻辑地址的低位部分决定。一般情况下，这个过程都可以由硬件完成，所以效率还是比较高的。页式内存管理的优点就是比较灵活，内存管理以较小的页为单位，方便内存换入换出和扩充地址空间。 Linux最初的两级页表机制两级分页机制将32位的虚拟空间分成三段，低12位表示页内偏移，高20位分成两段分别表示两级页表的偏移。 PGD(Page Global Directory)：最高10位，全局页目录表索引 PTE(Page Table Entry)：中间10位，页表入口索引 当在进行地址转换时，结合在CR3寄存器中存放的页目录(page directory，PGD)的这一页的物理地址，再加上从虚拟地址中抽出高10位叫做页目录表项(内核也称这为PGD)的部分作为偏移，即定位到可以描述该地址的PGD；从该PGD中可以获取可以描述该地址的页表的物理地址，再加上从虚拟地址中抽取中间10位作为偏移，即定位到可以描述该地址的PTE；在这个PTE中即可获取该地址对应的页的物理地址，加上从虚拟地址中抽取的最后12位，即形成该页的页内偏移，即可最终完成从虚拟地址到物理地址的转换。从上述过程中，可以看出，对虚拟地址的分级解析过程，实际上就是不断深入页表层次，逐渐定位到最终地址的过程，所以这一过程被叫做page table walk。 Linux的三级页表机制当x86引入物理地址扩展(Pisycal Addrress Extension，PAE)后，可以支持大于4G的物理内存(32位），但虚拟地址依然是32位，原先的页表项不适用，它实际多4bytes被扩充到8bytes，这意味着，每一页现在能存放的PTE数目从1024变成512了(4k/8)。相应地，页表层级发生了变化，Linux新增加了一个层级，叫做页中间目录(page middle directory，PMD)，变成： 字段 描述 位数 cr3 指向一个PDPT crs寄存器存储 PGD 指向PDPT中4个项中的一个 位31~30 PMD 指向页目录中512项中的一个 位29~21 PTE 指向页表中512项中的一个 位20~12 page offset 4KB页中的偏移 位11~0 现在就同时存在2级页表和3级页表，在代码管理上肯定不方便。巧妙的是，Linux采取了一种抽象方法：所有架构全部使用3级页表：即PGD -&gt; PMD -&gt; PTE。那只使用2级页表(如非PAE的x86)怎么办？ 办法是针对使用2级页表的架构，把PMD抽象掉，即虚设一个PMD表项。这样在page table walk过程中，PGD本直接指向PTE的，现在不了，指向一个虚拟的PMD，然后再由PMD指向PTE。这种抽象保持了代码结构的统一。 Linux的四级页表机制硬件在发展，3级页表很快又捉襟见肘了，原因是64位CPU出现了，比如x86_64，它的硬件是实实在在支持4级页表的。它支持48位的虚拟地址空间。如下： 字段 描述 位数 PML4 指向一个PDPT 位47~39 PGD 指向PDPT中4个项中的一个 位38~30 PMD 指向页目录中512项中的一个 位29~21 PTE 指向页表中512项中的一个 位20~12 page offset 4KB页中的偏移 位11~0 Linux内核针为使用原来的3级列表(PGD-&gt;PMD-&gt;PTE)，做了折衷。即采用一个唯一的，共享的顶级层次，叫PML4。这个PML4没有编码在地址中，这样就能套用原来的3级列表方案了。不过代价就是，由于只有唯一的PML4，寻址空间被局限在 $(2^{39}=)$ 512G，而本来PML4段有9位，可以支持512个PML4表项的。现在为了使用3级列表方案，只能限制使用一个，512G的空间很快就又不够用了，解决方案呼之欲出。 在2004年10月，当时的X86_64架构代码的维护者Andi Kleen提交了一个叫做4 level page tables for Linux的PATCH系列，为Linux内核带来了4级页表的支持。在他的解决方案中，不出意料地，按照x86_64规范，新增了一个PML4的层级，在这种解决方案中，x86_64拥一个有512条目的PML4，512条目的PGD，512条目的PMD，512条目的PTE。对于仍使用3级目录的架构来说，它们依然拥有一个虚拟的PML4，相关的代码会在编译时被优化掉。 这样，就把Linux内核的3级列表扩充为4级列表。这系列PATCH工作得不错，不久被纳入Andrew Morton的-mm树接受测试。不出意外的话，它将在v2.6.11版本中释出。但是，另一个知名开发者Nick Piggin提出了一些看法，他认为Andi的Patch很不错，不过他认为最好还是把PGD作为第一级目录，把新增加的层次放在中间，并给出了他自己的Patch：alternate 4-level page tables patches。Andi更想保持自己的PATCH，他认为Nick不过是玩了改名的游戏，而且他的PATCH经过测试很稳定，快被合并到主线了，不宜再折腾。不过Linus却表达了对Nick Piggin的支持，理由是Nick的做法conceptually least intrusive。毕竟作为Linux的扛把子，稳定对于Linus来说意义重大。最终，不意外地，最后Nick Piggin的PATCH在v2.6.11版本中被合并入主线。在这种方案中，4级页表分别是：PGD -&gt; PUD -&gt; PMD -&gt; PTE。 说一说有了进程，为什么还要有线程线程产生的原因： 进程可以使多个程序能并发执行，以提高资源的利用率和系统的吞吐量；但是其具有一些缺点： 进程在同一时间只能干一件事 进程在执行的过程中如果阻塞，整个进程就会挂起，即使进程中有些工作不依赖于等待的资源，仍然不会执行。 因此，操作系统引入了比进程粒度更小的线程，作为并发执行的基本单位，从而减少程序在并发执行时所付出的时空开销，提高并发性。和进程相比，线程的优势如下： 从 资源 上来讲，线程是一种非常”节俭”的多任务操作方式。在Linux系统下，启动一个新的进程必须分配给它独立的地址空间，建立众多的数据表来维护它的代码段、堆栈段和数据段，这是一种”昂贵”的多任务工作方式。 从 切换效率 上来讲，运行于一个进程中的多个线程，它们之间使用相同的地址空间，而且线程间彼此切换所需时间也远远小于进程间切换所需要的时间。据统计，一个进程的开销大约是一个线程开销的30倍左右。 从 通信机制 上来讲，线程间方便的通信机制。对不同进程来说，它们具有独立的数据空间，要进行数据的传递只能通过进程间通信的方式进行，这种方式不仅费时，而且很不方便。线程则不然，由于同一进城下的线程之间贡献数据空间，所以一个线程的数据可以直接为其他线程所用，这不仅快捷，而且方便。 除以上优点外，多线程程序作为一种多任务、并发的工作方式，还有如下优点： 使多CPU系统更加有效。操作系统会保证当线程数不大于CPU数目时，不同的线程运行于不同的CPU上。 改善程序结构。一个既长又复杂的进程可以考虑分为多个线程，成为几个独立或半独立的运行部分，这样的程序才会利于理解和修改。 单核机器上写多线程程序，是否需要考虑加锁，为什么在单核机器上写多线程程序，仍然需要线程锁。 因为线程锁通常用来实现线程的同步和通信。在单核机器上的多线程程序，仍然存在线程同步的问题。因为在抢占式操作系统中，通常为每个线程分配一个时间片，当某个线程时间片耗尽时，操作系统会将其挂起，然后运行另一个线程。如果这两个线程共享某些数据，不使用线程锁的前提下，可能会导致共享数据修改引起冲突。 线程需要保存哪些上下文，SP、PC、EAX这些寄存器是干嘛用的线程在切换的过程中需要保存当前线程Id、线程状态、堆栈、寄存器状态等信息。其中寄存器主要包括SP、PC、EAX等寄存器，其主要功能如下： SP:堆栈指针，指向当前栈的栈顶地址 PC:程序计数器，存储下一条将要执行的指令 EAX:累加寄存器，用于加法乘法的缺省寄存器 线程间的同步方式，最好说出具体的系统调用 信号量 信号量是一种特殊的变量，可用于线程同步。它只取自然数值，并且只支持两种操作： P(SV)： 如果信号量SV大于0，将它减一；如果SV值为0，则挂起该线程。 V(SV)： 如果有其他进程因为等待SV而挂起，则唤醒，然后将SV+1；否则直接将SV+1。 其系统调用为： sem_wait(sem_t *sem)：以原子操作的方式将信号量减1，如果信号量值为0，则sem_wait将被阻塞，直到这个信号量具有非0值。 sem_post(sem_t *sem)：以原子操作将信号量值+1。当信号量大于0时，其他正在调用sem_wait等待信号量的线程将被唤醒。 互斥量 互斥量又称互斥锁，主要用于线程互斥，不能保证按序访问，可以和条件锁一起实现同步。当进入临界区时，需要获得互斥锁并且加锁；当离开临界区时，需要对互斥锁解锁，以唤醒其他等待该互斥锁的线程。其主要的系统调用如下： pthread_mutex_init：初始化互斥锁 pthread_mutex_destroy：销毁互斥锁 pthread_mutex_lock：以原子操作的方式给一个互斥锁加锁，如果目标互斥锁已经被上锁，pthread_mutex_lock调用将阻塞，直到该互斥锁的占有者将其解锁。 pthread_mutex_unlock：以一个原子操作的方式给一个互斥锁解锁。 条件变量 条件变量，又称条件锁，用于在线程之间同步共享数据的值。条件变量提供一种线程间通信机制：当某个共享数据达到某个值时，唤醒等待这个共享数据的一个/多个线程。即，当某个共享变量等于某个值时，调用 signal/broadcast。此时操作共享变量时需要加锁。其主要的系统调用如下： pthread_cond_init：初始化条件变量 pthread_cond_destroy：销毁条件变量 pthread_cond_signal：唤醒一个等待目标条件变量的线程。哪个线程被唤醒取决于调度策略和优先级。 pthread_cond_wait：等待目标条件变量。需要一个加锁的互斥锁确保操作的原子性。该函数中在进入wait状态前首先进行解锁，然后接收到信号后会再加锁，保证该线程对共享资源正确访问。 说一下多线程和多进程的不同进程是资源分配的最小单位，而线程时CPU调度的最小单位。 多线程之间共享同一个进程的地址空间，线程间通信简单，同步复杂，线程创建、销毁和切换简单，速度快，占用内存少，适用于多核分布式系统，但是线程间会相互影响，一个线程意外终止会导致同一个进程的其他线程也终止，程序可靠性弱。 而多进程间拥有各自独立的运行地址空间，进程间不会相互影响，程序可靠性强，但是进程创建、销毁和切换复杂，速度慢，占用内存多，进程间通信复杂，但是同步简单，适用于多核、多机分布。 游戏服务器应该为每个用户开辟一个线程还是一个进程，为什么游戏服务器应该为每个用户开辟一个进程。 因为同一进程间的线程会相互影响，一个线程死掉会影响其他线程，从而导致进程崩溃。因此为了保证不同用户之间不会相互影响，应该为每个用户开辟一个进程。 说一说OS缺页置换算法当访问一个内存中不存在的页，并且内存已满，则需要从内存中调出一个页或将数据送至磁盘对换区，替换一个页，这种现象叫做缺页置换。 当前操作系统最常采用的缺页置换算法如下： 先进先出（FIFO）算法置换最先调入内存的页面，即置换在内存中驻留时间最久的页面。按照进入内存的先后次序排列成队列，从队尾进入，从队首删除。 思想：最近刚访问的，将来访问的可能性比较大。 实现：使用一个队列，新加入的页面放入队尾，每次淘汰队首的页面，即最先进入的数据，最先被淘汰。 弊端：无法体现页面冷热信息。 最不经常访问淘汰（LFU）算法 思想：如果数据过去被访问多次，那么将来被访问的频率也更高。 实现：每个数据块一个引用计数，所有数据块按照引用计数排序，具有相同引用计数的数据块则按照时间排序。每次淘汰队尾数据块。 开销：排序开销。 弊端：缓存颠簸。 最近最少使用（LRU）算法置换最近一段时间以来最长时间未访问过的页面。根据程序局部性原理，刚被访问的页面，可能马上又要被访问；而较长时间内没有被访问的页面，可能最近不会被访问。 思想：如果数据最近被访问过，那么将来被访问的几率也更高。 实现：使用一个栈，新页面或者命中的页面则将该页面移动到栈底，每次替换栈顶的缓存页面。 优点：LRU算法对热点数据命中率是很高的。 缺陷： 缓存颠簸，当缓存（1，2，3）满了，之后数据访问（0，3，2，1，0，3，2，1。。。）。 缓存污染，突然大量偶发性的数据访问，会让内存中存放大量冷数据。 说一下多进程和多线程的使用场景 多进程模型的优势是CPU，适用于CPU密集型。同时，多进程模型也适用于多机分布式场景中，易于多机扩展。 多线程模型主要优势为线程间切换代价较小，因此适用于I/O密集型的工作场景，因此I/O密集型的工作场景经常会由于I/O阻塞导致频繁的切换线程。同时，多线程模型也适用于单机多核分布式场景。 说一说死锁发生的条件以及如何解决死锁死锁是指两个或两个以上进程在执行过程中，因争夺资源而造成的下相互等待的现象。 死锁发生的四个必要条件互斥条件一个资源一段时间内只能由一个进程占用。 请求和保持（占用并等待）条件进程获得一定的资源后，又对其他资源发出请求，但是该资源可能被其他进程占有，此时请求阻塞，但该进程不会释放自己已经占有的资源。 不可剥夺条件进程已获得的资源，在未完成使用之前，不可被剥夺，只能在使用后自己释放。 环路等待条件进程发生死锁后，必然存在一个进程-资源之间的环形链。 解决死锁的方法即破坏上述四个条件之一主要方法如下： 资源一次性分配，从而剥夺请求和保持条件； 可剥夺资源：即当进程新的资源未得到满足时，释放已占有的资源，从而破坏不可剥夺的条件； 有序资源分配法：系统给每类资源赋予一个序号，每个进程按编号递增的请求资源，释放则相反，从而破坏环路等待的条件。 死锁检测 银行家算法：如果系统现存的各种资源可以满足申请者的最大需求量，就满足。 死锁排除 资源剥夺 撤销进程 进程回退 虚拟内存和物理内存怎么对应概念物理地址（physical address）用于内存芯片级的单元寻址，与处理器和CPU连接的地址总线相对应。 虽然可以直接把物理地址理解成插在机器上那根内存本身，把内存看成一个从0字节一直到最大空量逐字节的编号的大数组，然后把这个数组叫做物理地址，但是事实上，这只是一个硬件提供给软件的抽象，内存的寻址方式并不是这样。所以，说它是“与地址总线相对应”，是更贴切一些，不过抛开对物理内存寻址方式的考虑，直接把物理地址与物理的内存一一对应，也是可以接受的。也许错误的理解更利于形而上的抽象。 虚拟地址(virtual memory)这是对整个内存（不要与机器上插那条对上号）的抽象描述。它是相对于物理内存来讲的，可以直接理解成“不直实的”，“假的”内存，例如，一个0x08000000内存地址，它并不对就物理地址上那个大数组中0x08000000 - 1那个地址元素； 之所以是这样，是因为现代操作系统都提供了一种内存管理的抽象，即虚拟内存（virtual memory）。进程使用虚拟内存中的地址，由操作系统协助相关硬件，把它“转换”成真正的物理地址。这个“转换”，是所有问题讨论的关键。 有了这样的抽象，一个程序，就可以使用比真实物理地址大得多的地址空间。甚至多个进程可以使用相同的地址。不奇怪，因为转换后的物理地址并非相同的。 可以把连接后的程序反编译看一下，发现连接器已经为程序分配了一个地址，例如，要调用某个函数A，代码不是call A，而是call 0x0811111111 ，也就是说，函数A的地址已经被定下来了。没有这样的“转换”，没有虚拟地址的概念，这样做是根本行不通的。 地址转换第一步：CPU段式管理中——逻辑地址转线性地址CPU要利用其段式内存管理单元，先将一个逻辑地址转换成一个线程地址。 一个逻辑地址由两部分组成，[段标识符:段内偏移量]。 段标识符是由一个16位长的字段组成，称为段选择符。其中前13位是一个索引号。后面3位包含一些硬件细节，如图： 通过段标识符中的索引号从GDT或者LDT找到该段的段描述符，段描述符中的base字段是段的起始地址 段描述符：Base字段，它描述了一个段的开始位置的线性地址。 一些全局的段描述符，就放在全局段描述符表(GDT)中，一些局部的，例如每个进程自己的，就放在所谓的局部段描述符表(LDT)中。 GDT在内存中的地址和大小存放在CPU的GDTR控制寄存器中，而LDT则在LDTR寄存器中。 段起始地址 + 段内偏移量 = 线性地址 首先，给定一个完整的逻辑地址 [段选择符:段内偏移地址]， 看段选择符的T1 = 0还是1，知道当前要转换是GDT中的段，还是LDT中的段，再根据相应寄存器，得到其地址和大小。我们就有了一个数组了。 拿出段选择符中前13位，可以在这个数组中，查找到对应的段描述符，这样，它了Base，即基地址就知道了。 把Base + offset，就是要转换的线性地址了。 第二步：页式管理——线性地址转物理地址再利用其页式内存管理单元，转换为最终物理地址。 linux假的段式管理Intel要求两次转换，这样虽说是兼容了，但是却是很冗余，但是这是Intel硬件的要求。 其它某些硬件平台，没有二次转换的概念，Linux也需要提供一个高层抽象，来提供一个统一的界面。 所以，Linux的段式管理，事实上只是“哄骗”了一下硬件而已。 按照Intel的本意，全局的用GDT，每个进程自己的用LDT——不过Linux则对所有的进程都使用了相同的段来对指令和数据寻址。即用户数据段，用户代码段，对应的，内核中的是内核数据段和内核代码段。 在Linux下，逻辑地址与线性地址总是一致的，即逻辑地址的偏移量字段的值与线性地址的值总是相同的。 linux页式管理CPU的页式内存管理单元，负责把一个线性地址，最终翻译为一个物理地址。 线性地址被分为以固定长度为单位的组，称为页（page），例如一个32位的机器，线性地址最大可为4G，可以用4KB为一个页来划分，这页，整个线性地址就被划分为一个total_page[$2^{20}$]的大数组，共有2的20个次方个页。 另一类“页”，我们称之为物理页，或者是页框、页桢的。是分页单元把所有的物理内存也划分为固定长度的管理单位，它的长度一般与内存页是一一对应的。 每个进程都有自己的页目录，当进程处于运行态的时候，其页目录地址存放在cr3寄存器中。 每一个32位的线性地址被划分为三部份：[页目录索引(10位):页表索引(10位):页内偏移(12位)] 依据以下步骤进行转换： 从cr3中取出进程的页目录地址（操作系统负责在调度进程的时候，把这个地址装入对应寄存器）； 根据线性地址前十位，在数组中，找到对应的索引项，因为引入了二级管理模式，页目录中的项，不再是页的地址，而是一个页表的地址。（又引入了一个数组），页的地址被放到页表中去了。 根据线性地址的中间十位，在页表（也是数组）中找到页的起始地址； 将页的起始地址与线性地址中最后12位相加。 目的内存节约：如果一级页表中的一个页表条目为空，那么那所指的二级页表就根本不会存在。这表现出一种巨大的潜在节约，因为对于一个典型的程序，4GB虚拟地址空间的大部份都会是未分配的； 32位，PGD = 10bit，PUD = PMD = 0，table = 10bit，offset = 12bit 64位，PUD和PMD ≠ 0 说一说操作系统中的结构体对齐，字节对齐原因 平台原因（移植原因）：不是所有的硬件平台都能访问任意地址上的任意数据的；某些硬件平台只能在某些地址处取某些特定类型的数据，否则抛出硬件异常。 性能原因：数据结构（尤其是栈）应该尽可能地在自然边界上对齐。原因在于，为了访问未对齐的内存，处理器需要作两次内存访问；而对齐的内存访问仅需要一次访问。 规则 数据成员对齐规则：结构（struct）（或联合（union））的数据成员，第一个数据成员放在offset为0的地方，以后每个数据成员的对齐按照 #pragma pack 指定的数值和这个数据成员自身长度中，比较小的那个进行。 结构（或联合）的整体对齐规则：在数据成员完成各自对齐之后，结构（或联合）本身也要进行对齐，对齐将按照 #pragma pack 指定的数值和结构（或联合）最大数据成员长度中，比较小的那个进行。 结构体作为成员：如果一个结构里有某些结构体成员，则结构体成员要从其内部最大元素大小的整数倍地址开始存储。 定义结构体对齐可以通过预编译命令 #pragma pack(n), n = 1, 2, 4, 8, 16 来改变这一系数，其中的n就是指定的“对齐系数”。 举例#pragma pack(2) struct AA { int a; //长度4 &gt; 2 按2对齐；偏移量为0；存放位置区间[0,3] char b; //长度1 &lt; 2 按1对齐；偏移量为4；存放位置区间[4] short c; //长度2 = 2 按2对齐；偏移量要提升到2的倍数6；存放位置区间[6,7] char d; //长度1 &lt; 2 按1对齐；偏移量为8；存放位置区间[8]；共九个字节 }; #pragma pack() 互斥锁（mutex）机制，以及互斥锁和读写锁的区别概念互斥锁mutex用于保证在任何时刻，都只能有一个线程访问该对象。当获取锁操作失败时，线程会进入睡眠，等待锁释放时被唤醒。 读写锁rwlock分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作。但是同一时刻只能有一个线程可以获得写锁。其它获取写锁失败的线程都会进入睡眠状态，直到写锁释放时被唤醒。 注意：写锁会阻塞其它读写锁。当有一个线程获得写锁在写时，读锁也不能被其它线程获取；写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）。适用于读取数据的频率远远大于写数据的频率的场合。 互斥锁和读写锁的区别 读写锁区分读者和写者，而互斥锁不区分； 互斥锁同一时间只允许一个线程访问该对象，无论读写；读写锁同一时间内只允许一个写者，但是允许多个读者同时读对象。 Linux的4种锁机制互斥锁mutex用于保证在任何时刻，都只能有一个线程访问该对象。当获取锁操作失败时，线程会进入睡眠，等待锁释放时被唤醒。 读写锁rwlock分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作。但是同一时刻只能有一个线程可以获得写锁。其它获取写锁失败的线程都会进入睡眠状态，直到写锁释放时被唤醒。 注意：写锁会阻塞其它读写锁。当有一个线程获得写锁在写时，读锁也不能被其它线程获取；写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）。适用于读取数据的频率远远大于写数据的频率的场合。 自旋锁spinlock在任何时刻同样只能有一个线程访问对象。但是当获取锁操作失败时，不会进入睡眠，而是会在原地自旋，直到锁被释放。这样节省了线程从睡眠状态到被唤醒期间的消耗，在加锁时间短暂的环境下会极大的提高效率。但如果加锁时间过长，则会非常浪费CPU资源。 RCU（read-copy-update）在修改数据时，首先需要读取数据，然后生成一个副本，对副本进行修改。修改完成后，再将老数据update成新的数据。使用RCU时，读者几乎不需要同步开销，既不需要获得锁，也不使用原子指令，不会导致锁竞争，因此就不用考虑死锁问题了。而对于写者的同步开销较大，它需要复制被修改的数据，还必须使用锁机制同步并行其它写者的修改操作。在有大量读操作，少量写操作的情况下效率非常高。 说一说进程状态转换图，动态就绪，静态就绪，动态阻塞，静态阻塞进程的5种基本状态 创建状态：进程正在被创建； 就绪状态：进程被加入到就绪队列中等待CPU调度运行； 执行状态：进程正在被运行； 等待阻塞状态：进程因为某种原因，比如等待I/O，等待设备，而暂时不能运行； 终止状态：进程运行完毕。 交换技术当多个进程竞争内存资源时，会造成内存资源紧张，并且，如果此时没有就绪进程，处理机会空闲，I/0速度比处理机速度慢得多，可能出现全部进程阻塞等待I/O。 针对以上问题，提出了两种解决方法： 交换技术：换出一部分进程到外存，腾出内存空间。 虚拟存储技术：每个进程只能装入一部分程序和数据。 在交换技术上，将内存暂时不能运行的进程，或者暂时不用的数据和程序，换出到外存，来腾出足够的内存空间，把已经具备运行条件的进程，或进程所需的数据和程序换入到内存。 从而出现了进程的挂起状态：进程被交换到外存，进程状态就成为了挂起状态。 活动阻塞，静止阻塞，活动就绪，静止就绪 活动阻塞：进程在内存，但是由于某种原因被阻塞了。 静止阻塞：进程在外存，同时被某种原因阻塞了。 活动就绪：进程在内存，处于就绪状态，只要给CPU和调度就可以直接运行。 静止就绪：进程在外存，处于就绪状态，只要调度到内存，给CPU和调度就可以运行。 从而出现了： 活动就绪 —— 静止就绪（内存不够，调到外存） 活动阻塞 —— 静止阻塞（内存不够，调到外存） 执行 —— 静止就绪（时间片用完） 给你一个类，里面有static、virtual之类的，来说一说这个类的内存分布static修饰符static修饰成员变量对于非静态数据成员，每个类对象都有自己的拷贝。而静态数据成员被当做是类的成员，无论这个类被定义了多少个，静态数据成员都只有一份拷贝，为该类型的所有对象所共享（包括其派生类）。所以，静态数据成员的值对每个对象都是一样的，它的值可以更新。 因为静态数据成员在全局数据区分配内存，属于本类的所有对象共享，所以它不属于特定的类对象，在没有产生类对象前就可以使用。 static修饰成员函数与普通的成员函数相比，静态成员函数由于不是与任何的对象相联系，因此它不具有this指针。从这个意义上来说，它无法访问属于类对象的非静态数据成员，也无法访问非静态成员函数，只能调用其他的静态成员函数。 static修饰的成员函数，在代码区分配内存。 C++继承和虚函数C++多态分为静态多态和动态多态。静态多态是通过重载和模板技术实现，在编译的时候确定。动态多态通过虚函数和继承关系来实现，执行动态绑定，在运行的时候确定。 动态多态实现有几个条件： 虚函数； 一个基类的指针或引用指向派生类的对象； 基类指针在调用成员函数（虚函数）时，就会去查找该对象的虚函数表。虚函数表的地址在每个对象的首地址。查找该虚函数表中该函数的指针进行调用。 每个对象中保存的只是一个虚函数表的指针，C++内部为每一个类维持一个虚函数表，该类的对象的都指向这同一个虚函数表。 虚函数表中为什么就能准确查找相应的函数指针呢？因为在类设计的时候，虚函数表直接从基类也继承过来，如果覆盖了其中的某个虚函数，那么虚函数表的指针就会被替换，因此可以根据指针准确找到该调用哪个函数。 virtual修饰符如果一个类是局部变量则该类数据存储在栈区，如果一个类是通过new/malloc动态申请的，则该类数据存储在堆区。 如果该类是virutal继承而来的子类，则该类的虚函数表指针和该类其他成员一起存储。虚函数表指针指向只读数据段中的类虚函数表，虚函数表中存放着一个个函数指针，函数指针指向代码段中的具体函数。 如果类中成员是virtual属性，会隐藏父类对应的属性。 回答一下软链接和硬链接区别为了解决文件共享问题，Linux引入了软链接和硬链接。除了为Linux解决文件共享使用，还带来了隐藏文件路径、增加权限安全及节省存储等好处。 若1个inode号对应多个文件名，则为硬链接，即硬链接就是同一个文件使用了不同的 别名，使用 ln 创建。 若文件用户数据块中存放的内容是另一个文件的路径名指向，则该文件是软连接。软连接是一个普通文件，有自己独立的inode，但是其数据块内容比较特殊。 什么是大端小端以及如何判断大端小端大端是指低字节存储在高地址；小端存储是指低字节存储在低地址。 我们可以根据联合体来判断该系统是大端还是小端。因为联合体变量总是从低地址存储。 静态变量什么时候初始化静态变量存储在虚拟地址空间的数据段和BSS段。 C语言中其在代码执行之前初始化，属于编译期初始化。 而C++中由于引入对象，对象生成必须调用构造函数，因此C++规定全局或局部静态对象当且仅当对象首次用到时进行构造。 说一说用户态和内核态区别用户态和内核态是操作系统的两种运行级别，两者最大的区别就是特权级不同。用户态拥有最低的特权级，内核态拥有较高的特权级。运行在用户态的程序不能直接访问操作系统内核数据结构和程序。 内核态和用户态之间的转换方式主要包括：系统调用、异常和中断。 如何设计server，使得能够接收多个客户端的请求多线程，线程池，IO复用 死循环+来连接时新建线程的方法效率有点低，怎么改进提前创建好一个线程池，用生产者消费者模型，创建一个任务队列，队列作为临界资源，有了新连接，就挂在到任务队列上，队列为空所有线程睡眠。 改进死循环：使用select epoll这样的技术。 怎么唤醒被阻塞的socket线程给阻塞时候缺少的资源。 怎样确定当前线程是繁忙还是阻塞使用ps命令查看。 请问就绪状态的进程在等待什么被调度使用cpu的运行权。 说一说多线程的同步，锁的机制同步的时候用一个互斥量，在访问共享资源前对互斥量进行加锁，在访问完成后释放互斥量上的锁。对互斥量进行加锁以后，任何其他试图再次对互斥量加锁的线程将会被阻塞直到当前线程释放该互斥锁。如果释放互斥锁时有多个线程阻塞，所有在该互斥锁上的阻塞线程都会变成可运行状态，第一个变为运行状态的线程可以对互斥量加锁，其他线程将会看到互斥锁依然被锁住，只能回去再次等待它重新变为可用。在这种方式下，每次只有一个线程可以向前执行。 两个进程访问临界区资源，会不会出现都获得自旋锁的情况单核cpu，并且开了抢占可以造成这种情况。 说一说内存溢出和内存泄漏内存溢出指程序申请内存时，没有足够的内存供申请者使用。内存溢出就是你要的内存空间超过了系统实际分配给你的空间，此时系统相当于没法满足你的需求，就会报内存溢出的错误。 内存溢出原因 内存中加载的数据量过于庞大，如一次从数据库取出过多数据； 集合类中有对对象的引用，使用完后未清空，使得不能回收； 代码中存在死循环或循环产生过多重复的对象实体； 使用的第三方软件中的BUG； 启动参数内存值设定的过小。 内存泄漏内存泄漏是指由于疏忽或错误造成了程序未能释放掉不再使用的内存的情况。内存泄漏并非指内存在物理上的消失，而是应用程序分配某段内存后，由于设计错误，失去了对该段内存的控制，因而造成了内存的浪费。 内存泄漏的分类 堆内存泄漏（Heap leak）。对内存指的是程序运行中根据需要分配通过malloc、realloc、new等从堆中分配的一块内存，再是完成后必须通过调用对应的free或者delete删掉。如果程序的设计的错误导致这部分内存没有被释放，那么此后这块内存将不会被使用，就会产生Heap Leak。 系统资源泄露（Resource Leak）。主要指程序使用系统分配的资源比如Bitmap、handle、socket等没有使用相应的函数释放掉，导致系统资源的浪费，严重可导致系统效能降低，系统运行不稳定。 没有将基类的析构函数定义为虚函数。当基类指针指向子类对象时，如果基类的析构函数不是virtual，那么子类的析构函数将不会被调用，子类的资源没有正确是释放，因此造成内存泄露。 常用线程模型Future模型该模型通常在使用的时候需要结合Callable接口配合使用。 Future是把结果放在将来获取，当前主线程并不急于获取处理结果。允许子线程先进行处理一段时间，处理结束之后就把结果保存下来，当主线程需要使用的时候再向子线程索取。 Callable是类似于Runnable的接口，其中call方法类似于run方法，所不同的是run方法不能抛出受检异常没有返回值，而call方法则可以抛出受检异常并可设置返回值。两者的方法体都是线程执行体。 fork&amp;join模型该模型包含递归思想和回溯思想，递归用来拆分任务，回溯用合并结果。可以用来处理一些可以进行拆分的大任务。其主要是把一个大任务逐级拆分为多个子任务，然后分别在子线程中执行，当每个子线程执行结束之后逐级回溯，返回结果进行汇总合并，最终得出想要的结果。 这里模拟一个摘苹果的场景：有100棵苹果树，每棵苹果树有10个苹果，现在要把他们摘下来。为了节约时间，规定每个线程最多只能摘10棵苹树以便于节约时间。各个线程摘完之后汇总计算总苹果树。 actor模型actor模型属于一种基于消息传递机制并行任务处理思想，它以消息的形式来进行线程间数据传输，避免了全局变量的使用，进而避免了数据同步错误的隐患。actor在接受到消息之后可以自己进行处理，也可以继续传递（分发）给其它actor进行处理。在使用actor模型的时候需要使用第三方Akka提供的框架。 生产者消费者模型生产者消费者模型都比较熟悉，其核心是使用一个缓存来保存任务。开启一个/多个线程来生产任务，然后再开启一个/多个来从缓存中取出任务进行处理。这样的好处是任务的生成和处理分隔开，生产者不需要处理任务，只负责向生成任务然后保存到缓存。而消费者只需要从缓存中取出任务进行处理。使用的时候可以根据任务的生成情况和处理情况开启不同的线程来处理。比如，生成的任务速度较快，那么就可以灵活的多开启几个消费者线程进行处理，这样就可以避免任务的处理响应缓慢的问题。 master-worker模型master-worker模型类似于任务分发策略，开启一个master线程接收任务，然后在master中根据任务的具体情况进行分发给其它worker子线程，然后由子线程处理任务。如需返回结果，则worker处理结束之后把处理结果返回给master。 说一说协程概念协程，又称微线程，纤程，英文名Coroutine。协程看上去也是子程序，但执行过程中，在子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行。 例如： def A(): print(&#39;1&#39;) print(&#39;2&#39;) print(&#39;3&#39;) def B(): print(&#39;x&#39;) print(&#39;y&#39;) print(&#39;z&#39;) 由协程运行结果可能是12x3yz。在执行A的过程中，可以随时中断，去执行B，B也可能在执行过程中中断再去执行A。但协程的特点在于是一个线程执行。 协程和线程区别那和多线程比，协程最大的优势就是协程极高的执行效率。 因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。 第二大优势就是 不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。 其他在协程上利用多核CPU呢——多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。 Python对协程的支持还非常有限，用在generator中的yield可以一定程度上实现协程。虽然支持不完全，但已经可以发挥相当大的威力了。 系统调用是什么，你用过哪些系统调用概念在计算机中，系统调用（英语：system call），又称为系统呼叫，指运行在使用者空间的程序向操作系统内核请求需要更高权限运行的服务。系统调用提供了用户程序与操作系统之间的接口（即系统调用是用户程序和内核交互的接口）。 操作系统中的状态分为管态（内核态）和目态（用户态）。大多数系统交互式操作需求在内核态执行。如设备IO操作或者进程间通信。特权指令：一类只能在核心态下运行而不能在用户态下运行的特殊指令。不同的操作系统特权指令会有所差异，但是一般来说主要是和硬件相关的一些指令。用户程序只在用户态下运行，有时需要访问系统核心功能，这时通过系统调用接口使用系统调用。 应用程序有时会需要一些危险的、权限很高的指令，如果把这些权限放心地交给用户程序是很危险的（比如一个进程可能修改另一个进程的内存区，导致其不能运行），但是又不能完全不给这些权限。于是有了系统调用，危险的指令被包装成系统调用，用户程序只能调用而无权自己运行那些危险的指令。另外，计算机硬件的资源是有限的，为了更好的管理这些资源，所有的资源都由操作系统控制，进程只能向操作系统请求这些资源。操作系统是这些资源的唯一入口，这个入口就是系统调用。 系统调用举例对文件进行写操作，程序向打开的文件写入字符串“hello world”，open和write都是系统调用。如下： #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;string.h&gt; #include &lt;errno.h&gt; #include &lt;unistd.h&gt; #include &lt;sys/types.h&gt; #include &lt;sys/stat.h&gt; #include &lt;fcntl.h&gt; int main(int argc, char *argv[]) { if (argc &lt; 2) return 0; //用读写追加方式打开一个已经存在的文件 int fd = open(argv[1], O_RDWR | O_APPEND); if (fd == -1) { printf(&quot;error is %s\\n&quot;, strerror(errno)); } else { //打印文件描述符号 printf(&quot;success fd = %d\\n&quot;, fd); char buf[100]; memset(buf, 0, sizeof(buf)); strcpy(buf, &quot;hello world\\n&quot;); write(fd, buf, strlen(buf)); close(fd); } return 0; } 还有写数据write，创建进程fork，vfork等都是系统调用。 手写一下fork调用示例概念fork：创建一个和当前进程映像一样的进程可以通过 fork() 系统调用： 成功调用 fork() 会创建一个新的进程，它几乎与调用 fork() 的进程一模一样，这两个进程都会继续运行。在子进程中，成功的 fork() 调用会返回0。在父进程中 fork() 返回子进程的pid。如果出现错误，fork() 返回一个负值。 最常见的 fork() 用法是创建一个新的进程，然后使用exec()载入二进制映像，替换当前进程的映像。这种情况下，派生（fork）了新的进程，而这个子进程会执行一个新的二进制可执行文件的映像。这种“派生加执行”的方式是很常见的。 在早期的Unix系统中，创建进程比较原始。当调用fork时，内核会把所有的内部数据结构复制一份，复制进程的页表项，然后把父进程的地址空间中的内容逐页的复制到子进程的地址空间中。但从内核角度来说，逐页的复制方式是十分耗时的。现代的Unix系统采取了更多的优化，例如Linux，采用了写时复制的方法，而不是对父进程空间进程整体复制。 fork实例int main(void) { pid_t pid; signal(SIGCHLD, SIG_IGN); printf(&quot;before fork pid:%d\\n&quot;, getpid()); int abc = 10; pid = fork(); if (pid == -1) //错误返回 { perror(&quot;tile&quot;); return -1; } if (pid &gt; 0) //父进程空间 { abc++; printf(&quot;parent:pid:%d \\n&quot;, getpid()); printf(&quot;abc:%d \\n&quot;, abc); sleep(20); } else if (pid == 0) //子进程空间 { abc++; printf(&quot;child:%d, parent: %d\\n&quot;, getpid(), getppid()); printf(&quot;abc:%d&quot;, abc); } printf(&quot;fork after...\\n&quot;); } 说一说用户态到内核态的转化原理用户态切换到内核态的3种方式 系统调用 这是用户进程主动要求切换到内核态的一种方式，用户进程通过系统调用申请操作系统提供的服务程序完成工作。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的ine 80h中断。 异常 当CPU在执行运行在用户态的程序时，发现了某些事件不可知的异常，这是会触发由当前运行进程切换到处理此。异常的内核相关程序中，也就到了内核态，比如缺页异常。 外围设备的中断 当外围设备完成用户请求的操作之后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条将要执行的指令，转而去执行中断信号的处理程序，如果先执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了有用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。 切换操作从出发方式看，可以在认为存在前述3种不同的类型，但是从最终实际完成由用户态到内核态的切换操作上来说，涉及的关键步骤是完全一样的，没有任何区别，都相当于执行了一个中断响应的过程，因为系统调用实际上最终是中断机制实现的，而异常和中断处理机制基本上是一样的，用户态切换到内核态的步骤主要包括： 从当前进程的描述符中提取其内核栈的ss0及esp0信息； 使用ss0和esp0指向的内核栈将当前进程的cs、eip、eflags、ss、esp信息保存起来，这个过程也完成了由用户栈找到内核栈的切换过程，同时保存了被暂停执行的程序的下一条指令； 将先前由中断向量检索得到的中断处理程序的cs、eip信息装入相应的寄存器，开始执行中断处理程序，这时就转到了内核态的程序执行了。 说一下源码到可执行文件的过程预编译主要处理源代码文件中的以 # 开头的预编译指令。处理规则见下 删除所有的 #define，展开所有的宏定义。 处理所有的条件预编译指令，如 #if、#endif、#ifdef、#elif 和 #else。 处理 #include 预编译指令，将文件内容替换到它的位置，这个过程是递归进行的，文件中包含其他文件。 删除所有的注释，// 和 /**/。 保留所有的 #pragma 编译器指令，编译器需要用到他们，如：#pragma once 是为了防止有文件被重复引用。 添加行号和文件标识，便于编译时编译器产生调试用的行号信息，和编译时产生编译错误或警告是能够显示行号。 编译把预编译之后生成的 xxx.i 或 xxx.ii 文件，进行一系列词法分析、语法分析、语义分析及优化后，生成相应的汇编代码文件。 词法分析：利用类似于“有限状态机”的算法，将源代码程序输入到扫描机中，将其中的字符序列分割成一系列的记号。 语法分析：语法分析器对由扫描器产生的记号，进行语法分析，产生语法树。由语法分析器输出的语法树是一种以表达式为节点的树。 语义分析：语法分析器只是完成了对表达式语法层面的分析，语义分析器则对表达式是否有意义进行判断，其分析的语义是静态语义——在编译期能分期的语义，相对应的动态语义是在运行期才能确定的语义。 优化：源代码级别的一个优化过程。 目标代码生成：由代码生成器将中间代码转换成目标机器代码，生成一系列的代码序列——汇编语言表示。 目标代码优化：目标代码优化器对上述的目标机器代码进行优化：寻找合适的寻址方式、使用位移来替代乘法运算、删除多余的指令等。 汇编将汇编代码转变成机器可以执行的指令（机器码文件）。 汇编器的汇编过程相对于编译器来说更简单，没有复杂的语法，也没有语义，更不需要做指令优化，只是根据汇编指令和机器指令的对照表一一翻译过来，汇编过程有汇编器as完成。经汇编之后，产生目标文件（与可执行文件格式几乎一样）xxx.o（Windows下）、xxx.obj（Linux下）。 链接将不同的源文件产生的目标文件进行链接，从而形成一个可以执行的程序。链接分为静态链接和动态链接： 静态链接函数和数据被编译进一个二进制文件。在使用静态库的情况下，在编译链接可执行文件时，链接器从库中复制这些函数和数据并把它们和应用程序的其它模块组合起来创建最终的可执行文件。 空间浪费：因为每个可执行程序中对所有需要的目标文件都要有一份副本，所以如果多个程序对同一个目标文件都有依赖，会出现同一个目标文件都在内存存在多个副本； 更新困难：每当库函数的代码修改了，这个时候就需要重新进行编译链接形成可执行程序。 运行速度快：但是静态链接的优点就是，在可执行程序中已经具备了所有执行程序所需要的任何东西，在执行的时候运行速度快。 动态链接动态链接的基本思想是把程序按照模块拆分成各个相对独立部分，在程序运行时才将它们链接在一起形成一个完整的程序，而不是像静态链接一样把所有程序模块都链接成一个单独的可执行文件。 共享库：就是即使需要每个程序都依赖同一个库，但是该库不会像静态链接那样在内存中存在多分，副本，而是这多个程序在执行时共享同一份副本； 更新方便：更新时只需要替换原来的目标文件，而无需将所有的程序再重新链接一遍。当程序下一次运行时，新版本的目标文件会被自动加载到内存并且链接起来，程序就完成了升级的目标。 性能损耗：因为把链接推迟到了程序运行时，所以每次执行程序都需要进行链接，所以性能会有一定损失。 说一下微内核与宏内核宏内核除了最基本的进程、线程管理、内存管理外，将文件系统、驱动、网络协议等等都集成在内核里面，例如Linux内核。 优点：效率高。 缺点：稳定性差，开发过程中的bug经常会导致整个系统挂掉。 微内核内核中只有最基本的调度、内存管理。驱动、文件系统等都是用户态的守护进程去实现的。 优点：稳定。驱动等的错误只会导致相应进程死掉，不会导致整个系统都崩溃。 缺点：效率低。典型代表QNX，QNX的文件系统是跑在用户态的进程，称为resmgr的东西，是订阅发布机制，文件系统的错误只会导致这个守护进程挂掉。不过数据吞吐量就比较不乐观了。 说一下僵尸进程正常进程正常情况下，子进程是通过父进程创建的，子进程再创建新的进程。子进程的结束和父进程的运行是一个异步过程，即父进程永远无法预测子进程到底什么时候结束。 当一个进程完成它的工作终止之后，它的父进程需要调用 wait() 或者 waitpid() 系统调用取得子进程的终止状态。 Unix提供了一种机制可以保证只要父进程想知道子进程结束时的状态信息， 就可以得到：在每个进程退出的时候，内核释放该进程所有的资源，包括打开的文件、占用的内存等。但是仍然为其保留一定的信息，直到父进程通过wait / waitpid来取时才释放。 保存信息包括： 进程号the process ID 退出状态the termination status of the process 运行时间the amount of CPU time taken by the process等 孤儿进程一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程（进程号为1）所收养，并由init进程对它们完成状态收集工作。 僵尸进程一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵尸进程。 僵尸进程是一个进程必然会经过的过程：这是每个子进程在结束时都要经过的阶段。 如果子进程在exit()之后，父进程没有来得及处理，这时用ps命令就能看到子进程的状态是“Z”。如果父进程能及时处理，可能用ps命令就来不及看到子进程的僵尸状态，但这并不等于子进程不经过僵尸状态。 如果父进程在子进程结束之前退出，则子进程将由init接管。init将会以父进程的身份对僵尸状态的子进程进行处理。 危害如果进程不调用wait / waitpid的话， 那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程。 外部消灭通过kill发送SIGTERM或者SIGKILL信号消灭产生僵尸进程的进程，它产生的僵死进程就变成了孤儿进程，这些孤儿进程会被init进程接管，init进程会wait()这些孤儿进程，释放它们占用的系统进程表中的资源。 内部解决 子进程退出时向父进程发送SIGCHLD信号，父进程处理SIGCHLD信号。在信号处理函数中调用wait进行处理僵尸进程。 fork两次，原理是将子进程成为孤儿进程，从而其的父进程变为init进程，通过init进程可以处理僵尸进程。 GDB调试用过吗，什么是条件断点GDB调试GDB 是自由软件基金会（Free Software Foundation）的软件工具之一。它的作用是协助程序员找到代码中的错误。如果没有GDB的帮助，程序员要想跟踪代码的执行流程，唯一的办法就是添加大量的语句来产生特定的输出。但这一手段本身就可能会引入新的错误，从而也就无法对那些导致程序崩溃的错误代码进行分析。 GDB的出现减轻了开发人员的负担，他们可以在程序运行的时候单步跟踪自己的代码，或者通过断点暂时中止程序的执行。此外，他们还能够随时察看变量和内存的当前状态，并监视关键的数据结构是如何影响代码运行的。 条件断点条件断点是当满足条件就中断程序运行，命令：break line-or-function if expr。 例如：(gdb)break 666 if testsize==100 介绍一下5种IO模型 阻塞IO：调用者调用了某个函数，等待这个函数返回，期间什么也不做，不停的去检查这个函数有没有返回，必须等这个函数返回才能进行下一步动作。 非阻塞IO：非阻塞等待，每隔一段时间就去检测IO事件是否就绪。没有就绪就可以做其他事。 信号驱动IO：Linux用套接口进行信号驱动IO，安装一个信号处理函数，进程继续运行并不阻塞，当IO时间就绪，进程收到SIGIO信号。然后处理IO事件。 IO复用/多路转接IO：linux用select/poll函数实现IO复用模型，这两个函数也会使进程阻塞，但是和阻塞IO所不同的是这两个函数可以同时阻塞多个IO操作。而且可以同时对多个读操作、写操作的IO函数进行检测。知道有数据可读或可写时，才真正调用IO操作函数。 异步IO：Linux中，可以调用aio_read函数告诉内核描述字缓冲区指针和缓冲区的大小、文件偏移及通知的方式，然后立即返回，当内核将数据拷贝到缓冲区后，再通知应用程序。 说一说异步编程的事件循环事件循环就是不停循环等待时间的发生，然后将这个事件的所有处理器，以及他们订阅这个事件的时间顺序依次依次执行。当这个事件的所有处理器都被执行完毕之后，事件循环就会开始继续等待下一个事件的触发，不断往复。当同时并发地处理多个请求时，以上的概念也是正确的，可以这样理解：在单个的线程中，事件处理器是一个一个按顺序执行的。即如果某个事件绑定了两个处理器，那么第二个处理器会在第一个处理器执行完毕后，才开始执行。在这个事件的所有处理器都执行完毕之前，事件循环不会去检查是否有新的事件触发。在单个线程中，一切都是有顺序地一个一个地执行的。 操作系统为什么要分内核态和用户态为了安全性。 在CPU的一些指令中，有的指令如果用错，将会导致整个系统崩溃。分了内核态和用户态后，当用户需要操作这些指令时候，内核为其提供了API，可以通过系统调用陷入内核，让内核去执行这些操作。 为什么要有page cache，操作系统怎么设计的page cache加快从磁盘读取文件的速率。 page cache中有一部分磁盘文件的缓存，因为从磁盘中读取文件比较慢，所以读取文件先去page cache中去查找，如果命中，则不需要去磁盘中读取，大大加快读取速度。在 Linux 内核中，文件的每个数据块最多只能对应一个 Page Cache 项，它通过两个数据结构来管理这些 Cache项，一个是radix tree，另一个是双向链表。Radix tree 是一种搜索树，Linux内核利用这个数据结构来通过文件内偏移快速定位Cache项。 server端监听端口，但还没有客户端连接进来，此时进程处于什么状态这个需要看服务端的编程模型，如果如上一个问题的回答描述的这样，则处于阻塞状态，如果使用了epoll、select等这样的io复用情况下，处于运行状态。 怎么实现线程池 设置一个生产者消费者队列，作为临界资源； 初始化n个线程，并让其运行起来，加锁去队列取任务运行； 当任务队列为空的时候，所有线程阻塞； 当生产者队列来了一个任务后，先对队列加锁，把任务挂在到队列上，然后使用条件变量去通知阻塞中的一个线程。 Linux下怎么得到一个文件的100到200行sed -n &#39;100,200p&#39; inputfile awk &#39;NR&gt;=100&amp;&amp;NR&lt;=200{print}&#39; inputfile head -200 inputfile|tail -100 说一下linux内核中的Timer定时器机制低精度时钟Linux 2.6.16之前，内核只支持低精度时钟，内核定时器的工作方式： 系统启动后，会读取时钟源设备（RTC、HPET、PIT……），初始化当前系统时间。 内核会根据HZ（系统定时器频率，节拍率）参数值，设置时钟事件设备，启动tick（节拍）中断。HZ表示1秒种产生多少个时钟硬件中断，tick就表示连续两个中断的间隔时间。 设置时钟事件设备后，时钟事件设备会定时产生一个tick中断，触发时钟中断处理函数，更新系统时钟,并检测timer wheel，进行超时事件的处理。 在上面工作方式下，Linux 2.6.16 之前，内核软件定时器采用timer wheel多级时间轮的实现机制，维护操作系统的所有定时事件。timer wheel的触发是基于系统tick周期性中断。 所以说这之前，linux只能支持ms级别的时钟，随着时钟源硬件设备的精度提高和软件高精度计时的需求，有了高精度时钟的内核设计。 高精度时钟Linux 2.6.16 ，内核支持了高精度的时钟，内核采用新的定时器hrtimer，其实现逻辑和Linux 2.6.16 之前定时器逻辑区别： hrtimer采用红黑树进行高精度定时器的管理，而不是时间轮； 高精度时钟定时器不在依赖系统的tick中断，而是基于事件触发。 旧内核的定时器实现依赖于系统定时器硬件定期的tick，基于该tick，内核会扫描timer wheel处理超时事件，会更新jiffies，wall time（墙上时间，现实时间），process的使用时间等等工作。 新的内核不再会直接支持周期性的tick，新内核定时器框架采用了基于事件触发，而不是以前的周期性触发。新内核实现了hrtimer（high resolution timer）：于事件触发。 hrtimer的工作原理： 通过将高精度时钟硬件的下次中断触发时间设置为红黑树中最早到期的Timer的时间，时钟到期后从红黑树中得到下一个 Timer 的到期时间，并设置硬件，如此循环反复。 在高精度时钟模式下，操作系统内核仍然需要周期性的tick中断，以便刷新内核的一些任务。hrtimer是基于事件的，不会周期性出发tick中断，所以为了实现周期性的tick中断（dynamic tick）：系统创建了一个模拟 tick 时钟的特殊 hrtimer，将其超时时间设置为一个tick时长，在超时回来后，完成对应的工作，然后再次设置下一个tick的超时时间，以此达到周期性tick中断的需求。 引入了dynamic tick，是为了能够在使用高精度时钟的同时节约能源，这样会产生tickless 情况下，会跳过一些 tick。 新内核对相关的时间硬件设备进行了统一的封装，定义了主要有下面两个结构： 时钟源设备（closk source device）：抽象那些能够提供计时功能的系统硬件，比如 RTC（Real Time Clock）、TSC（Time Stamp Counter），HPET，ACPI PM-Timer，PIT等。不同时钟源提供的精度不一样，现在pc大都是支持高精度模式（high-resolution mode）也支持低精度模式（low-resolution mode）。 时钟事件设备（clock event device）：系统中可以触发 one-shot（单次）或者周期性中断的设备都可以作为时钟事件设备。 当前内核同时存在新旧timer wheel 和 hrtimer两套timer的实现，内核启动后会进行从低精度模式到高精度时钟模式的切换，hrtimer模拟的tick中断将驱动传统的低精度定时器系统（基于时间轮）和内核进程调度。","categories":[{"name":"面经知识汇总","slug":"面经知识汇总","permalink":"http://yoursite.com/categories/%E9%9D%A2%E7%BB%8F%E7%9F%A5%E8%AF%86%E6%B1%87%E6%80%BB/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://yoursite.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"C++语言基础","slug":"C++语言基础","date":"2020-03-20T17:16:00.000Z","updated":"2020-03-20T17:16:00.000Z","comments":true,"path":"2020/03/21/C++语言基础/","link":"","permalink":"http://yoursite.com/2020/03/21/C++%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/","excerpt":"面试常见的C++语言基础","text":"面试常见的C++语言基础 基本语言C++和C的区别 设计思想上：C++是面向对象的语言，而C是面向过程的结构化编程语言 语法上： C++具有封装、继承和多态三种特性； C++相比C，增加多许多类型安全的功能，比如强制类型转换； C++支持范式编程，比如 模板类、函数模板 等。 C++的多态多态的定义简单来说就是使一条语句有多种状态。 重载实现方式重载是在 同一作用域 内（不管是模块内还是类内，只要是在同一作用域内），具有相同函数名，不同的形参个数或者形参类型。返回值可以相同也可以不同（在函数名、形参个数、形参类型都相同而返回值类型不同的情况下无法构成重载，编译器报错。这个道理很简单，在函数调用的时候是不看返回值类型的）。 实现原理重载是一种静态多态，即在编译的时候确定的。C++实现重载的方式是跟编译器有关，编译过后C++的函数名会发生改变，会带有形参个数、类型以及返回值类型的信息（虽然带有返回值类型但是返回值类型不能区分这个函数），所以编译器能够区分具有不同形参个数或者类型以及相同函数名的函数。插一句，在C语言中编译器编译过后函数名中不会带有形参个数以及类型的信息，因此C语言没有重载的特性。由此带来麻烦的一点是如果想要在C++中调用C语言的库，需要特殊的操作（extern “C”{}）。库中的函数经过C编译器编译的话会生成不带有形参信息的函数名，而用C++的编译器编译过后会生成带有形参信息的函数名，因此将会找不到这个函数。extern “C”{}的作用是使在这个作用域中的语句用C编译器编译，这样就不会出错。这也是一种语言兼容性的问题。 重写实现方式重写是在 不同作用域内（一个在父类一个在子类），函数名、形参个数、形参类型、返回值类型都相同并且父类中带有virtual关键字（换言之子类中带不带virtual都没有关系）**。有一种特殊的情况：函数返回值类型可以不同但是必须是指针或者引用，并且两个虚函数的返回值之间必须要构成父子类关系。这种情况称之为协变，也是一种重写。引入协变的好处是为了避免危险的类型转换。 实现原理重写是一种动态多态，即在运行时确定的。C++实现重写的方式也跟编译器有关，编译器在实例化一个具有虚函数的类时会生成一个vptr指针 （这就是为什么静态函数、友元函数不能声明为虚函数，因为它们不实例化也可以调用，而虚函数必须要实例化，这也是为什么构造函数不能声明为虚函数，因为你要调用虚函数必须得要有vptr指针，而构造函数此时还没有被调用，内存中还不存在vptr指针，逻辑上矛盾了）。vptr指针在类的内存空间中占最低地址的四字节。vptr指针指向的空间称为虚函数表，vptr指针指向其表头，在虚函数表里面按声明顺序存放了虚函数的函数指针，如果在子类中重写了，在子类的内存空间中也会产生一个vptr指针，同时会把父类的虚函数表copy一下当做自己的，然后如果在子类中重新声明了虚函数，会按声明顺序接在父类的虚函数函数指针下。而子类中重写的虚函数则会替换掉虚函数表中原先父类的虚函数函数指针。重点来了，在调用虚函数时，不管调用他的是父类的指针、引用还是子类的指针、引用，他都不管，只看他所指向或者引用的对象的类型（这也称为动态联编），如果是父类的对象，那就调用父类里面的vptr指针然后找到相应的虚函数，如果是子类的对象，那就调用子类里面的vptr指针然后找到相应的虚函数。当然这样子的过程相比静态多态而言，时间和空间上的开销都多了（这也是为什么内联函数为什么不能声明为虚函数，因为这和内联函数加快执行速度的初衷相矛盾）。 重定义实现方式重定义是在 不同作用域内的（一个在父类一个在子类），只要函数名相同，且不构成重写，均称之为重定义 实现原理重定义的实现原理跟继承树中函数的寻找方式有关，他会从当前对象的类作用域内开始查找同名的函数，如果没有找到就一直向上查找直到基类为止。如果找到一个同名的函数就停止。这也就说明他不管函数的形参类型或者个数是不是一样，只要函数名一样，他就认为是找到了，如果这时候形参类型或者个数不一致，编译器就会报错。多重继承的查找，如果在同一层内出现一样的函数声明那么编译器会报错不知道调用哪一个函数，这类问题也叫钻石继承问题。钻石问题的解决方案可以通过虚继承来实现，这样就不会存在多个一样的函数声明。 static关键字的作用 全局静态变量在全局变量前加上关键字static，全局变量就定义成一个全局静态变量。静态存储区，在整个程序运行期间一直存在。初始化：未经初始化的全局静态变量会被自动初始化为 0（自动对象的值是任意的，除非他被显式初始化）；作用域：全局静态变量在声明他的文件之外是不可见的，准确地说是从定义之处开始，到文件结尾。 局部静态变量在局部变量之前加上关键字static，局部变量就成为一个局部静态变量。内存中的位置：静态存储区初始化：未经初始化的局部静态变量会被自动初始化为 0（自动对象的值是任意的，除非他被显式初始化）；作用域：作用域仍为局部作用域，当定义它的函数或者语句块结束的时候，作用域结束。但是当局部静态变量离开作用域后，并没有销毁，而是仍然驻留在内存当中，只不过我们不能再对它进行访问，直到该函数再次被调用，并且值不变； 静态函数在函数返回类型前加static，函数就定义为静态函数。函数的定义和声明在默认情况下都是extern的，但静态函数只是在声明他的文件当中可见，不能被其他文件所用。函数的实现使用static修饰，那么这个函数只可在本cpp内使用，不会同其他cpp中的同名函数引起冲突；warning：不要再头文件中声明static的全局函数，不要在cpp内声明非static的全局函数，如果你要在多个cpp中复用该函数，就把它的声明提到头文件里去，否则cpp内部声明需加上static修饰； 类的静态成员在类中，静态成员可以实现多个对象之间的数据共享，并且使用静态数据成员还不会破坏隐藏的原则，即保证了安全性。因此，静态成员是类的所有对象中共享的成员，而不是某个对象的成员。对多个对象来说，静态数据成员只存储一处，供所有对象共用 类的静态函数静态成员函数和静态数据成员一样，它们都属于类的静态成员，它们都不是对象成员。因此，对静态成员的引用不需要用对象名。在静态成员函数的实现中不能直接引用类中说明的非静态成员，可以引用类中说明的静态成员（这点非常重要）。如果静态成员函数中要引用非静态成员时，可通过对象来引用。从中可看出，调用静态成员函数使用如下格式：&lt;类名&gt;::&lt;静态成员函数名&gt;(&lt;参数表&gt;); 加了static关键字的全局变量只能在本文件中使用。例如在 a.c 中定义了 static int a=10; 那么在 b.c 中用 extern int a 是拿不到a的值的，a的作用域只在 a.c 中。 static定义的静态局部变量分配在 数据段 上，普通的局部变量分配在 栈 上，会因为函数栈帧的释放而被释放掉。 对一个类中成员变量和成员函数来说，加了static关键字，则此变量/函数就没有了 this 指针了，必须通过类名才能访问。 C++中四种cast转换C++中四种类型转换是：static_cast，dynamic_cast，const_cast，reinterpret_cast const_cast用于将const变量转为非const。 static_cast用于各种隐式转换，比如非const转const，void*转指针等，static_cast能用于多态向上转化，如果向下转能成功但是不安全，结果未知。 dynamic_cast用于动态类型转换。只能用于含有虚函数的类，用于类层次间的向上和向下转化。只能转指针或引用。向下转化时，如果是非法的对于指针返回 NULL，对于引用抛异常。要深入了解内部转换的原理。它通过判断在执行到该语句的时候变量的运行时类型和要转换的类型是否相同来判断是否能够进行向下转换。 向上转换：指的是子类向基类的转换。 向下转换：指的是基类向子类的转换。 reinterpret_cast几乎什么都可以转，比如将int转指针，可能会出问题，尽量少用； 为什么不使用C的强制转换？C的强制转换表面上看起来功能强大什么都能转，但是转化不够明确，不能进行错误检查，容易出错。 C++中的四个智能指针 smart pointer：shared_ptr，unique_ptr，weak_ptr，auto_ptrC++里面的四个智能指针：auto_ptr，shared_ptr，weak_ptr，unique_ptr 其中后三个是C++11支持，并且第一个已经被C++11弃用。 为什么要使用智能指针？智能指针的作用是管理一个指针，因为存在以下这种情况：申请的空间在函数结束时忘记释放，造成内存泄漏。使用智能指针可以很大程度上的避免这个问题，因为 智能指针就是一个类，当超出了类的作用域是，类会自动调用析构函数，析构函数会自动释放资源。所以智能指针的作用原理就是在函数结束时自动释放内存空间，不需要手动释放内存空间。 auto_ptr（C++98的方案，C++11已经抛弃）采用所有权模式。 auto_ptr&lt;string&gt; p1 (new string (&quot;I reigned lonely as a cloud.&quot;)); auto_ptr&lt;string&gt; p2; p2 = p1; //auto_ptr不会报错. 此时不会报错，p2剥夺了p1的所有权，但是当程序运行时访问p1将会报错。所以auto_ptr的缺点是：存在潜在的内存崩溃问题！ unique_ptr（替换auto_ptr） unique_ptr实现独占式拥有或严格拥有概念，保证同一时间内只有一个智能指针可以指向该对象。它对于避免资源泄露(例如“以new创建对象后因为发生异常而忘记调用delete”)特别有用。 采用所有权模式，还是上面那个例子 unique_ptr&lt;string&gt; p3 (new string (&quot;auto&quot;)); //#4 unique_ptr&lt;string&gt; p4； //#5 p4 = p3;//此时会报错！！ 编译器认为 p4 = p3 非法，避免了 p3 不再指向有效数据的问题。因此，unique_ptr 比 auto_ptr 更安全。 另外 unique_ptr 还有更聪明的地方：当程序试图将一个 unique_ptr 赋值给另一个时，如果源 unique_ptr 是个临时右值，编译器允许这么做；如果源 unique_ptr 将存在一段时间，编译器将禁止这么做，比如： unique_ptr&lt;string&gt; pu1(new string (&quot;hello world&quot;)); unique_ptr&lt;string&gt; pu2; pu2 = pu1; // #1 not allowed unique_ptr&lt;string&gt; pu3; pu3 = unique_ptr&lt;string&gt;(new string (&quot;You&quot;)); // #2 allowed 其中 #1 留下悬挂的 unique_ptr(pu1)，这可能导致危害。而 #2 不会留下悬挂的 unique_ptr，因为它调用 unique_ptr 的构造函数，该构造函数创建的临时对象在其所有权让给 pu3 后就会被销毁。这种随情况而已的行为表明，unique_ptr 优于允许两种赋值的 auto_ptr。 注：如果确实想执行类似与 #1 的操作，要安全的重用这种指针，可给它赋新值。C++有一个标准库函数 std::move()，让你能够将一个 unique_ptr 赋给另一个。例如： unique_ptr&lt;string&gt; ps1, ps2; ps1 = demo(&quot;hello&quot;); ps2 = move(ps1); ps1 = demo(&quot;alexia&quot;); cout &lt;&lt; *ps2 &lt;&lt; *ps1 &lt;&lt; endl; shared_ptr shared_ptr 实现共享式拥有概念。多个智能指针可以指向相同对象，该对象和其相关资源会在“最后一个引用被销毁”时候释放。从名字share就可以看出了资源可以被多个指针共享，它使用计数机制来表明资源被几个指针共享。可以通过成员函数 use_count() 来查看资源的所有者个数。除了可以通过new来构造，还可以通过传入 auto_ptr，unique_ptr，weak_ptr 来构造。当我们调用 release() 时，当前指针会释放资源所有权，计数减一。当计数等于 0 时，资源会被释放。 shared_ptr 是为了解决 auto_ptr 在对象所有权上的局限性(auto_ptr 是独占的)，在使用引用计数的机制上提供了可以共享所有权的智能指针。 成员函数： use_count 返回引用计数的个数； unique 返回是否是独占所有权（use_count 为 1）； swap 交换两个 shared_ptr 对象(即交换所拥有的对象)； reset 放弃内部对象的所有权或拥有对象的变更，会引起原有对象的引用计数的减少； get 返回内部对象(指针)，由于已经重载了 () 方法， 因此和直接使用对象是一样的，如 shared_ptr&lt;int&gt; sp(new int(1)); sp 与 sp.get() 是等价的。 weak_ptr weak_ptr 是一种不控制对象生命周期的智能指针， 它指向一个 shared_ptr 管理的对象。进行该对象的内存管理的是那个强引用的 shared_ptr。weak_ptr 只是提供了对管理对象的一个访问手段。weak_ptr 设计的目的是为配合 shared_ptr 而引入的一种智能指针来协助 shared_ptr 工作， 它只可以从一个 shared_ptr 或另一个 weak_ptr 对象构造，它的构造和析构不会引起引用记数的增加或减少。weak_ptr 是用来解决 shared_ptr 相互引用时的死锁问题，如果说两个 shared_ptr 相互引用，那么这两个指针的引用计数永远不可能下降为0，资源永远不会释放。它是对对象的一种弱引用，不会增加对象的引用计数，和 shared_ptr 之间可以相互转化，shared_ptr 可以直接赋值给它，它可以通过调用 lock 函数来获得 shared_ptr。 class B; class A { public: shared_ptr&lt;B&gt; pb_; ~A() { cout &lt;&lt; &quot;A delete&quot; &lt;&lt; endl; } }; class B { public: shared_ptr&lt;A&gt; pa_; ~B() { cout &lt;&lt; &quot;B delete&quot; &lt;&lt; endl; } }; void fun() { shared_ptr&lt;B&gt; pb(new B()); shared_ptr&lt;A&gt; pa(new A()); pb-&gt;pa_ = pa; pa-&gt;pb_ = pb; cout &lt;&lt; pb.use_count() &lt;&lt; endl; cout &lt;&lt; pa.use_count() &lt;&lt; endl; } int main() { fun(); return 0; } 可以看到 fun 函数中 pa，pb 之间互相引用，两个资源的引用计数为 2，当要跳出函数时，智能指针 pa，pb 析构时两个资源引用计数会减一，但是两者引用计数还是为 1，导致跳出函数时资源没有被释放（A B 的析构函数没有被调用），如果把其中一个改为 weak_ptr 就可以了，我们把类 A 里面的 shared_ptr pb_; 改为 weak_ptr pb_; 运行结果如下： 1 2 B delete A delete 这样的话，资源 B 的引用开始就只有 1，当 pb 析构时，B 的计数变为 0，B 得到释放，B 释放的同时也会使 A 的计数减一，同时 pa 析构时使 A 的计数减一，那么 A 的计数为 0，A 得到释放。 注意的是我们不能通过 weak_ptr 直接访问对象的方法，比如 B 对象中有一个方法 print()，我们不能这样访问，pa-&gt;pb_-&gt;print(); 英文 pb_ 是一个 weak_ptr，应该先把它转化为 shared_ptr，如：shared_ptr p = pa-&gt;pb_.lock(); p-&gt;print(); 数组和指针的区别 指针 数组 保存数据的地址 保存数据 间接访问数据，首先获得指针的内容，然后将其作为地址，从该地址中提取数据 直接访问数据 通常用于动态的数据结构 通常用于固定数目且数据类型相同的元素 通过 malloc 分配内存，free 释放内存 隐式的分配和删除 通常指向匿名数据，操作匿名函数 自身即为数据名 野指针是什么野指针就是指向一个已删除的对象或者未申请访问受限内存区域的指针。 介绍一下C++中的智能指针智能指针主要用于管理在堆上分配的内存，它将普通的指针封装为一个栈对象。当栈对象的生存周期结束后，会在析构函数中释放掉申请的内存，从而防止内存泄漏。C++11中最常用的智能指针类型为 shared_ptr，它采用引用计数的方法，记录当前内存资源被多少个智能指针引用。该引用计数的内存在堆上分配。当新增一个时引用计数加1，当过期时引用计数减一。只有引用计数为 0 时，智能指针才会自动释放引用的内存资源。对 shared_ptr 进行初始化时不能将一个普通指针直接赋值给智能指针，因为一个是指针，一个是类。可以通过 make_shared 函数或者通过构造函数传入普通指针。并可以通过 get 函数获得普通指针。 回答一下智能指针有没有内存泄露的情况当两个对象相互使用一个 shared_ptr 成员变量指向对方，会造成循环引用，使引用计数失效，从而导致内存泄漏。 智能指针的内存泄漏如何解决为了解决循环引用导致的内存泄漏，引入了 weak_ptr 弱指针，weak_ptr 的构造函数不会修改引用计数的值，从而不会对对象的内存进行管理，其类似一个普通指针，但 不指向引用计数的共享内存，但是其可以检测到所管理的对象是否已经被释放，从而避免非法访问。 C++中的引用和指针定义： 引用：C++是C语言的继承，它可进行过程化程序设计，又可以进行以抽象数据类型为特点的基于对象的程序设计，还可以进行以继承和多态为特点的面向对象的程序设计。引用就是C++对C语言的重要扩充。引用就是某一变量的一个别名，对引用的操作与对变量直接操作完全一样。引用的声明方法：类型标识符 &amp;引用名=目标变量名;引用引入了对象的一个同义词。定义引用的表示方法与定义指针相似，只是用 &amp; 代替了 *。 指针： 指针利用地址，它的值直接指向存在电脑存储器中另一个地方的值。由于通过地址能找到所需的变量单元，可以说，地址指向该变量单元。因此，将地址形象化的称为「指针」。意思是通过它能找到以它为地址的内存单元。 区别： 指针有自己的一块空间，而引用只是一个别名； 使用 sizeof 看一个指针的大小是 4，而引用则是被引用对象的大小； 指针可以被初始化为 NULL，而引用必须被初始化且必须是一个已有对象的引用； 作为参数传递时，指针需要被解引用才可以对对象进行操作，而直接对引用的修改都会改变引用所指向的对象； 可以有const指针，但是没有const引用； 指针在使用中可以指向其它对象，但是引用只能是一个对象的引用，不能 被改变； 指针可以有多级指针（如**p），而引用只有一级； 指针和引用使用++运算符的意义不一样； 如果返回动态内存分配的对象或者内存，必须使用指针，引用可能引起内存泄露。 为什么析构函数必须是虚函数？为什么C++默认的析构函数不是虚函数 考点：虚函数 析构函数将可能会被继承的父类的析构函数设置为虚函数，可以保证当我们new一个子类，然后使用基类指针指向该子类对象，释放基类指针时可以释放掉子类的空间，防止内存泄漏。 C++默认的析构函数不是虚函数是因为虚函数需要额外的虚函数表和虚表指针，占用额外的内存。而对于不会被继承的类来说，其析构函数如果是虚函数，就会浪费内存。因此C++默认的析构函数不是虚函数，而是只有当需要当作父类时，设置为虚函数。 说一下函数指针 定义： 函数指针是指向函数的指针变量。 函数指针本身首先是一个指针变量，该指针变量指向一个具体的函数。这正如用指针变量可指向整型变量、字符型、数组一样，这里是指向函数。 C在编译时，每一个函数都有一个入口地址，该入口地址就是函数指针所指向的地址。有了指向函数的指针变量后，可用该指针变量调用函数，就如同用指针变量可引用其他类型变量一样，在这些概念上是大体一致的。 用途： 调用函数和做函数的参数，比如回调函数。 示例： char *fun(char *p) {...} // 函数fun char *(*pf)(char *p); // 函数指针pf pf = fun; // 函数指针pf指向函数fun pf(p); // 通过函数指针pf调用函数fun 说一下fork函数Fork：创建一个和当前进程映像一样的进程可以通过 fork() 系统调用： #include &lt;sys/types.h&gt; #include &lt;unistd.h&gt; pid_t fork(void); 成功调用 fork() 会创建一个新的进程，它几乎与调用 fork() 的进程一模一样，这两个进程都会继续运行。在子进程中，成功的 fork() 调用会返回 0；在父进程中 fork() 返回子进程的 pid。如果出现错误，fork() 返回一个负值。 最常见的 fork() 用法是创建一个新的进程，然后使用 exec() 载入二进制映像，替换当前进程的映像。这种情况下，派生（fork）了新的进程，而这个子进程会执行一个新的二进制可执行文件的映像。这种「派生加执行」的方式是很常见的。 在早期的Unix系统中，创建进程比较原始。当调用fork时，内核会把所有的内部数据结构复制一份，复制进程的页表项，然后把父进程的地址空间中的内容逐页的复制到子进程的地址空间中。但从内核角度来说，逐页的复制方式是十分耗时的。现代的Unix系统采取了更多的优化，例如Linux，采用了写时复制的方法，而不是对父进程空间进程整体复制。 说一下C++中析构函数的作用析构函数与构造函数对应，当对象结束其生命周期，如对象所在的函数已调用完毕时，系统会自动执行析构函数。析构函数名也应与类名相同，只是在函数名前面加一个位取反符~，例如 ~stud()，以区别于构造函数。它不能带任何参数，也没有返回值（包括void类型）。只能有一个析构函数，不能重载。 如果用户没有编写析构函数，编译系统会自动生成一个缺省的析构函数（即使自定义了析构函数，编译器也总是会为我们合成一个析构函数，并且如果自定义了析构函数，编译器在执行时会先调用自定义的析构函数再调用合成的析构函数），它也不进行任何操作。所以许多简单的类中没有用显式的析构函数。 如果一个类中有指针，且在使用的过程中动态的申请了内存，那么最好显示构造析构函数在销毁类之前，释放掉申请的内存空间，避免内存泄漏。 类析构顺序： 派生类本身的析构函数； 对象成员析构函数； 基类析构函数。 值得一提的是，析构函数和构造函数的调用顺序相反。 说一下静态函数和虚函数的区别静态函数在编译的时候就已经确定运行时机，虚函数在运行的时候动态绑定。虚函数因为用了虚函数表机制，调用的时候会增加一次内存开销。 说一说重载和覆盖 重载：两个函数名相同，但是参数列表不同（个数，类型），返回值类型没有要求，在同一作用域中。 重写：子类继承了父类，父类中的函数是虚函数，在子类中重新定义了这个虚函数，这种情况是重写。 说一说strcpy和strlen strcpy是字符串拷贝函数，原型： char *strcpy(char* dest, const char *src); 从 src 逐字节拷贝到 dest，直到遇到 &#39;\\0&#39; 结束，因为没有指定长度，可能会导致拷贝越界，造成缓冲区溢出漏洞，安全版本是 strncpy 函数。 strlen 函数是计算字符串长度的函数，返回从开始到 &#39;\\0&#39; 之间的字符个数。 说一说你理解的虚函数和多态多态的实现主要分为 静态多态 和 动态多态，静态多态主要是重载，在编译的时候就已经确定；动态多态是用虚函数机制实现的，在运行期间动态绑定。举个例子：一个父类类型的指针指向一个子类对象时候，使用父类的指针去调用子类中重写了的父类中的虚函数的时候，会调用子类重写过后的函数，在父类中声明为加了 virtual 关键字的函数，在子类中重写时候不需要加virtual也是虚函数。虚函数的实现： 在有虚函数的类中，类的最开始部分是一个虚函数表的指针，这个指针指向一个虚函数表，表中放了虚函数的地址，实际的虚函数在代码段(.text)中。当子类继承了父类的时候也会继承其虚函数表，当子类重写父类中虚函数时候，会将其继承到的虚函数表中的地址替换为重新写的函数地址。使用了虚函数，会增加访问内存开销，降低效率。 说一说++i和i++的实现 ++i 实现： int&amp; int::operator++() { *this += 1; return *this; } i++ 实现： const int int::operator++(int) { int oldValue = *this; ++(*this); return oldValue; } 写个函数在main函数执行前先运行有2种方式： 法1 __attribute__((constructor))void before() { printf(&quot;before main\\n&quot;); } 或者 #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; static void before(void) __attribute__((constructor)); static void after(void) __attribute__((destructor)); static void before() { printf(&quot;before main\\n&quot;); } static void after(void) { printf(&quot;after main\\n&quot;); } int main() { printf(&quot;main\\n&quot;); return 0; } 法2 在C++中，也利用全局变量和构造函数的特性，通过全局变量的构造函数在 main() 函数之前执行 class BeforeMain { public: BeforeMain(); }; BeforeMain::BeforeMain() { cout &lt;&lt; &quot;Before main&quot; &lt;&lt; endl; } BeforeMain bM; // 利用全局变量和构造函数的特性，通过全局变量的构造函数执行 有段代码写成了下边这样，如果在只修改一个字符的前提下，使代码输出20个hellofor (int i = 0; i &lt; 20; i--) cout &lt;&lt; &quot;hello&quot; &lt;&lt; endl; 修改后： for (int i = 0; i + 20; i--) cout &lt;&lt; &quot;hello&quot; &lt;&lt; endl; 以下四行代码的区别是什么const char * arr = &quot;123&quot;; char * brr = &quot;123&quot;; const char crr[] = &quot;123&quot;; char drr[] = &quot;123&quot;; //字符串123保存在常量区，const本来是修饰arr指向的值不能通过arr去修改，但是字符串“123”在常量区，本来就不能改变，所以加不加const效果都一样 const char * arr = &quot;123&quot;; //字符串123保存在常量区，这个arr指针指向的是同一个位置，同样不能通过brr去修改&quot;123&quot;的值 char * brr = &quot;123&quot;; //这里123本来是在栈上的，但是编译器可能会做某些优化，将其放到常量区 const char crr[] = &quot;123&quot;; //字符串123保存在栈区，可以通过drr去修改 char drr[] = &quot;123&quot;; 请你来说一下C++里是怎么定义常量的？常量存放在内存的哪个位置对于 局部常量，存放在 栈区；对于 全局常量，编译期一般不分配内存，放在 符号表 中以提高访问效率；字面值常量，比如字符串，放在 常量区。 如果同时定义了两个函数，一个带const，一个不带，会有问题吗当这两个函数作为普通的函数时，编译会报错，无法仅按返回类型区分两个函数；当这两个函数作为类的成员函数时，是没有问题的。 class A { public: void f() { cout&lt;&lt;&quot;non const&quot;&lt;&lt;endl; } void f() const { cout&lt;&lt;&quot; const&quot;&lt;&lt;endl; } }; //微软笔试第二题正是考这个，const 对象调用f() const，非const对象调用 f() C++为什么不可以同时用const和static修饰成员函数C++编译器在实现const的成员函数的时候为了确保该函数不能修改类的实例的状态，会在函数中添加一个隐式的参数const this*。但当一个成员为static的时候，该函数是没有this指针的。也就是说此时const的用法和static是冲突的。 说一说C++函数栈空间的最大值默认是 1M，不过可以调整。 说一说extern”C”C++调用C函数需要extern C，因为C语言没有函数重载。 new/delete 与 malloc/free 的区别是什么首先，new/delete 是C++的关键字，而 malloc/free 是C语言的库函数，后者使用必须指明申请内存空间的大小，对于类类型的对象，后者不会调用构造函数和析构函数。 说说你了解的 RTTI运行时类型检查，在C++层面主要体现在dynamic_cast和typeid，VS中虚函数表的-1位置存放了指向type_info的指针。对于存在虚函数的类型，typeid和dynamic_cast都会去查询type_info。 说说虚函数表具体是怎样实现运行时多态的子类若重写父类虚函数，虚函数表中，该函数的地址会被替换，对于存在虚函数的类的对象，在VS中，对象的对象模型的头部存放指向虚函数表的指针，通过该机制实现多态。 说说C语言是怎么进行函数调用的每一个函数调用都会分配函数栈，在栈内进行函数执行过程。调用前，先把返回地址压栈，然后把当前函数的esp指针压栈。 说一说 selectselect在使用前，先将需要监控的描述符对应的bit位置1，然后将其传给select，当有任何一个事件发生时，select将会返回所有的描述符，需要在应用程序自己遍历去检查哪个描述符上有事件发生，效率很低，并且其不断在内核态和用户态进行描述符的拷贝，开销很大。 说说 fork，wait，exec 函数父进程产生子进程使用fork拷贝出来一个父进程的副本，此时只拷贝了父进程的页表，两个进程都读同一块内存，当有进程写的时候使用写时拷贝机制分配内存，exec函数可以加载一个elf文件去替换父进程，从此父进程和子进程就可以运行不同的程序了。fork从父进程返回子进程的pid，从子进程返回 0。调用了 wait 的父进程将会发生阻塞，直到有子进程状态改变，执行成功返回 0，错误返回 -1。exec执行成功则子进程从新的程序开始运行，无返回值，执行失败返回- 1。 容器和算法说一下 map 和 set 有什么区别，分别又是怎么实现的map 和 set 都是C++的关联容器，其底层实现都是红黑树（RB-Tree）。由于 map 和 set 所开放的各种操作接口，RB-tree 也都提供了，所以几乎所有的 map 和 set 的操作行为，都只是转调 RB-tree 的操作行为。 map 和 set 区别在于： map 中的元素是 key-value（关键字—值） 对：关键字起到索引的作用，值则表示与索引相关联的数据；set 与之相对就是关键字的简单集合，set 中每个元素只包含一个关键字。 set的迭代器是const的，不允许修改元素的值；map允许修改value，但不允许修改key。其原因是因为map和set是根据关键字排序来保证其有序性的，如果允许修改key的话，那么首先需要删除该键，然后调节平衡，再插入修改后的键值，调节平衡，如此一来，严重破坏了map和set的结构，导致iterator失效，不知道应该指向改变前的位置，还是指向改变后的位置。所以STL中将set的迭代器设置成const，不允许修改迭代器的值；而map的迭代器则不允许修改key值，允许修改value值。 map支持下标操作，set不支持下标操作。map可以用key做下标，map的下标运算符 [] 将关键码作为下标去执行查找，如果关键码不存在，则插入一个具有该关键码和mapped_type类型默认值的元素至map中，因此下标运算符 [] 在map应用中需要慎用，const_map不能用，只希望确定某一个关键值是否存在而不希望插入元素时也不应该使用，mapped_type类型没有默认值也不应该使用。如果 find 能解决需要，尽可能用 find。 介绍一下 STL 的 allocatorSTL的分配器用于封装STL容器在内存管理上的底层细节。在C++中，其内存配置和释放如下： new运算分两个阶段： 调用 ::operator new 配置内存； 调用对象构造函数构造对象内容。 delete运算分两个阶段： 调用对象析构函数； 调用 ::operator delete 释放内存。 为了精密分工，STL allocator将两个阶段操作区分开来：内存配置由 alloc::allocate() 负责，内存释放由 alloc::deallocate() 负责；对象构造由 ::construct() 负责，对象析构由 ::destroy() 负责。 同时为了提升内存管理的效率，减少申请小内存造成的内存碎片问题，SGI STL采用了两级配置器，当分配的空间大小超过 128B 时，会使用第一级空间配置器；当分配的空间大小小于128B时，将使用第二级空间配置器。第一级空间配置器直接使用 malloc()、realloc()、free() 函数进行内存空间的分配和释放，而第二级空间配置器采用了 内存池 技术，通过空闲链表来管理内存。 说一说STL迭代器删除元素这个主要考察的是迭代器失效的问题。 对于序列容器 vector、deque 来说，使用 erase(iterator) 后，后边的每个元素的迭代器都会失效，但是后边每个元素都会往前移动一个位置，但是erase会返回下一个有效的迭代器； 对于关联容器map、set 来说，使用了 erase(iterator) 后，当前元素的迭代器失效，但是其结构是红黑树，删除当前元素的，不会影响到下一个元素的迭代器，所以在调用erase之前，记录下一个元素的迭代器即可； 对于 list 来说，它使用了不连续分配的内存，并且它的erase方法也会返回下一个有效的iterator，因此上面两种正确的方法都可以使用。 STL中map数据存放形式红黑树。unordered_map底层结构是哈希表。 讲讲STL有什么基本组成STL主要由以下几部分组成： 容器 迭代器 仿函数 算法 分配器 配接器 他们之间的关系：分配器 给 容器 分配存储空间，算法 通过 迭代器 获取 容器 中的内容，仿函数 可以协助 算法 完成各种操作，配接器 用来套接适配 仿函数。 说说STL中map与unordered_map map映射 map 的所有元素都是 pair，同时拥有键值（key）和实值（value）。pair 的第一元素被视为键值，第二元素被视为实值。所有元素都会根据元素的键值自动被排序。不允许键值重复。 底层实现：红黑树 适用场景：有序键值对 不重复映射 优点：有序性，这是map结构最大的优点，其元素的有序性在很多应用中都会简化很多的操作。红黑树，内部实现一个红黑书使得map的很多操作在 logn 的时间复杂度下就可以实现，因此效率非常的高。 缺点：空间占用率高，因为map内部实现了红黑树，虽然提高了运行效率，但是因为每一个节点都需要额外保存父节点、孩子节点和红/黑性质，使得每一个节点都占用大量的空间。 适用处：对于那些有顺序要求的问题，用map会更高效一些。 unordered_map 优点： 因为内部实现了哈希表，因此其查找速度非常的快。 缺点： 哈希表的建立比较耗费时间 适用处：对于查找问题，unordered_map会更加高效一些，因此遇到查找问题，常会考虑一下用unordered_map。 总结：内存占有率的问题就转化成红黑树 VS hash表，还是unorder_map占用的内存要高。但是unordered_map执行效率要比map高很多对于unordered_map或unordered_set容器，其遍历顺序与创建该容器时输入的顺序不一定相同，因为遍历是按照哈希表从前往后依次遍历的。map和unordered_map的使用：unordered_map的用法和map是一样的，提供了 insert，size，count等操作，并且里面的元素也是以pair类型来存贮的。其底层实现是完全不同的，上方已经解释了，但是就外部使用来说却是一致的。 multimap 多重映射。multimap 的所有元素都是 pair，同时拥有键值（key）和实值（value）。pair 的第一元素被视为键值，第二元素被视为实值。所有元素都会根据元素的键值自动被排序。允许键值重复。 底层实现：红黑树 适用场景：有序键值对 可重复映射。 说一说 vector 和 list 的区别，应用，越详细越好 概念 vector 连续存储的容器，动态数组，在堆上分配空间。 底层实现：数组 两倍容量增长：vector 增加（插入）新元素时，如果未超过当时的容量，则还有剩余空间，那么直接添加到最后（插入指定位置），然后调整迭代器；如果没有剩余空间了，则会重新配置原有元素个数的两倍空间，然后将原空间元素通过复制的方式初始化新空间，再向新空间增加元素，最后析构并释放原空间，之前的迭代器会失效。 性能： 访问：O(1) 插入：在最后插入（空间够）：很快 在最后插入（空间不够）：需要内存申请和释放，以及对之前数据进行拷贝。 在中间插入（空间够）：内存拷贝 在中间插入（空间不够）：需要内存申请和释放，以及对之前数据进行拷贝。 在最后删除：很快 在中间删除：内存拷贝 适用场景：经常随机访问，且不经常对非尾节点进行插入删除。 list 动态链表，在堆上分配空间，每插入一个元数都会分配空间，每删除一个元素都会释放空间。 底层：双向链表 性能： 访问：随机访问性能很差，只能快速访问头尾节点 插入：很快，一般是常数开销 删除：很快，一般是常数开销 适用场景：经常插入删除大量数据 区别 vector底层实现是数组，list是双向链表。 vector支持随机访问，list不支持。 vector是顺序内存，list不是。 vector在中间节点进行插入删除会导致内存拷贝，list不会。 vector一次性分配好内存，不够时才进行2倍扩容；list每次插入新节点都会进行内存申请。 vector随机访问性能好，插入删除性能差；list随机访问性能差，插入删除性能好。 应用 vector拥有一段连续的内存空间，因此支持随机访问，如果需要高效的随即访问，而不在乎插入和删除的效率，使用vector。 list拥有一段不连续的内存空间，如果需要高效的插入和删除，而不关心随机访问，则应使用list。 说一下STL中迭代器的作用，有指针为何还要迭代器 迭代器 Iterator（迭代器）模式又称Cursor（游标）模式，用于提供一种方法顺序访问一个聚合对象中各个元素，而又不需暴露该对象的内部表示。或者这样说可能更容易理解：Iterator模式是运用于聚合对象的一种模式，通过运用该模式，使得我们可以在不知道对象内部表示的情况下，按照一定顺序（由iterator提供的方法）访问聚合对象中的各个元素。 由于Iterator模式的以上特性：与聚合对象耦合，在一定程度上限制了它的广泛运用，一般仅用于底层聚合支持类，如STL的list、vector、stack等容器类及ostream_iterator等扩展iterator。 迭代器和指针的区别 迭代器不是指针，是类模板，表现的像指针。他只是模拟了指针的一些功能，通过重载了指针的一些操作符，-&gt;、*、++、—等。迭代器封装了指针，是一个“可遍历STL（ Standard Template Library）容器内全部或部分元素”的对象， 本质是封装了原生指针，是指针概念的一种提升（lift），提供了比指针更高级的行为，相当于一种智能指针，他可以根据不同类型的数据结构来实现不同的++，—等操作。 迭代器返回的是对象引用而不是对象的值，所以cout只能输出迭代器使用*取值后的值而不能直接输出其自身。 迭代器产生原因 Iterator类的访问方式就是把不同集合类的访问逻辑抽象出来，使得不用暴露集合内部的结构而达到循环遍历集合的效果。 说一说epoll原理调用顺序： int epoll_create(int size); int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); int epoll_wait(int epfd, struct epoll_event *events,int maxevents, int timeout); 首先创建一个 epoll 对象，然后使用 epoll_ctl 对这个对象进行操作，把需要监控的描述添加进去，这些描述如将会以 epoll_event 结构体的形式组成一颗红黑树，接着阻塞在 epoll_wait，进入大循环，当某个fd上有事件发生时，内核将会把其对应的结构体放入到一个链表中，返回有事件发生的链表。 n 个整数的无序数组，找到每个元素后面比它大的第一个数，要求时间复杂度为 O(N)vector&lt;int&gt; findMax(vector&lt;int&gt; num) { if (num.size() == 0) { return num; } vector&lt;int&gt; res(num.size()); stack&lt;int&gt; s; int i = 0; while (i &lt; num.size()) { if (s.empty() || num[s.top()] &gt;= num[i]) { // 保存原数组下标 s.push(i++); } else { res[s.top()] = num[i]; s.pop(); } } while (!s.empty()) { res[s.top()] = INT_MAX; s.pop(); } for (int n : res) { cout &lt;&lt; n &lt;&lt; endl; } return res; } 回答一下STL里 resize 和 reserve 的区别 resize()：改变当前容器内含有元素的数量(size())，eg: vector&lt;int&gt;v; v.resize(len); v的size变为len，如果原来v的size小于len，那么容器新增（len-size）个元素，元素的值为默认为 0。当 v.push_back(3); 之后，则是3是放在了v的末尾，即下标为len，此时容器是size为len+1； reserve()：改变当前容器的最大容量（capacity），它不会生成元素，只是确定这个容器允许放入多少对象。如果reserve(len)的值大于当前的capacity()，那么会重新分配一块能存len个对象的空间，然后把之前v.size()个对象通过copy construtor复制过来，销毁之前的内存。 测试代码： #include &lt;iostream&gt; #include &lt;vector&gt; using namespace std; int main() { vector&lt;int&gt; a; a.reserve(100); a.resize(50); cout &lt;&lt; a.size() &lt;&lt; &quot; &quot; &lt;&lt; a.capacity() &lt;&lt; endl; //50 100 a.resize(150); cout &lt;&lt; a.size() &lt;&lt; &quot; &quot; &lt;&lt; a.capacity() &lt;&lt; endl; //150 150 a.reserve(50); cout &lt;&lt; a.size() &lt;&lt; &quot; &quot; &lt;&lt; a.capacity() &lt;&lt; endl; //150 150 a.resize(50); cout &lt;&lt; a.size() &lt;&lt; &quot; &quot; &lt;&lt; a.capacity() &lt;&lt; endl; //50 150 } 类和数据抽象说一下C++中类成员的访问权限C++通过 public、protected、private 三个关键字来控制成员变量和成员函数的访问权限，它们分别表示公有的、受保护的、私有的，被称为成员访问限定符。在类的内部（定义类的代码内部），无论成员被声明为 public、protected 还是 private，都是可以互相访问的，没有访问权限的限制。在类的外部（定义类的代码之外），只能通过对象访问成员，并且通过对象只能访问 public 属性的成员，不能访问 private、protected 属性的成员。要注意的是，如果未注明访问权限关键字，默认为 private 说一下C++中 struct 和 class 的区别在C++中，可以用 struct 和class定义类，都可以继承。区别在于：struct的默认继承权限和默认访问权限是public，而class的默认继承权限和默认访问权限是private。另外，class还可以定义模板类形参，比如 template &lt;class T, int i&gt;。 C++类内可以定义引用数据成员吗可以，必须通过成员函数初始化列表初始化。 class MyClass { public: MyClass(int &amp;i) : a(1), b(i) //构造函数初始化列表中是初始化工作 { //在这里做的是赋值而非初始化工作 } private: const int a; int &amp;b; }; 面向对象与泛型编程什么是右值引用，跟左值又有什么区别右值引用是C++11中引入的新特性，它实现了转移语义和精确传递。它的主要目的有两个方面： 消除两个对象交互时不必要的对象拷贝，节省运算存储资源，提高效率。 能够更简洁明确地定义泛型函数。 左值和右值的概念： 左值： 能对表达式取地址、或具名对象/变量。一般指表达式结束后依然存在的持久对象。右值： 不能对表达式取地址，或匿名对象。一般指表达式结束就不再存在的临时对象。 右值引用和左值引用的区别： 左值可以寻址，而右值不可以。 左值可以被赋值，右值不可以被赋值，可以用来给左值赋值。 左值可变，右值不可变（仅对基础类型适用，用户自定义类型右值引用可以通过成员函数改变）。 编译与底层说一下一个C++源文件从文本到可执行文件经历的过程对于C++源文件，从文本到可执行文件一般需要四个过程： 预处理阶段： 对源代码文件中文件包含关系（头文件）、预编译语句（宏定义）进行分析和替换，生成预编译文件； 编译阶段： 将经过预处理后的预编译文件转换成特定汇编代码，生成汇编文件； 汇编阶段： 将编译阶段生成的汇编文件转化成机器码，生成可重定位目标文件； 链接阶段： 将多个目标文件及所需要的库连接成最终的可执行目标文件。 include头文件的顺序以及双引号 &quot;&quot; 和尖括号 &lt;&gt; 的区别include头文件的顺序：对于include的头文件来说，如果在文件a.h中声明一个在文件b.h中定义的变量，而不引用b.h，那么要在a.c文件中引用b.h文件，并且要先引用b.h，后引用a.h，否则汇报变量类型未声明错误。 双引号和尖括号的区别：编译器预处理阶段查找头文件的路径不一样。 对于使用双引号包含的头文件，查找头文件路径的顺序为： 当前头文件目录 编译器设置的头文件路径（编译器可使用 -I 显式指定搜索路径） 系统变量CPLUS_INCLUDE_PATH/C_INCLUDE_PATH指定的头文件路径 对于使用尖括号包含的头文件，查找头文件的路径顺序为： 编译器设置的头文件路径（编译器可使用 -I 显式指定搜索路径） 系统变量CPLUS_INCLUDE_PATH/C_INCLUDE_PATH指定的头文件路径。 回答一下malloc的原理，另外brk系统调用和mmap系统调用的作用分别是什么malloc 函数用于 动态分配内存。为了减少内存碎片和系统调用的开销，malloc 其采用 内存池 的方式，先申请大块内存作为堆区，然后将堆区分为多个内存块，以块作为内存管理的基本单位。当用户申请内存时，直接从堆区分配一块合适的空闲块。malloc 采用 隐式链表结构 将堆区分成连续的、大小不一的块，包含已分配块和未分配块；同时 malloc 采用显示链表结构来管理所有的空闲块，即使用一个 双向链表 将空闲块连接起来，每一个空闲块记录了一个连续的、未分配的地址。当进行内存分配时，malloc 会通过隐式链表遍历所有的空闲块，选择满足要求的块进行分配；当进行内存合并时，malloc 采用边界标记法，根据每个块的前后块是否已经分配来决定是否进行块合并。 malloc 在申请内存时，一般会通过 brk 或者 mmap 系统调用进行申请。其中当申请内存 小于128K 时，会使用系统函数 brk 在 堆区 中分配；而当申请内存 大于128K 时，会使用系统函数 mmap 在 映射区 分配。 说一说C++的内存管理是怎样的在C++中，虚拟内存分为 代码段、数据段、BSS段、堆区、文件映射区以及 栈区 六部分。 代码段：包括只读存储区和文本区，其中只读存储区存储字符串常量，文本区存储程序的机器代码； 数据段：存储程序中已初始化的全局变量和静态变量； BSS段：存储未初始化的全局变量和静态变量（局部 + 全局），以及所有被初始化为 0 的全局变量和静态变量； 堆区：调用 new/malloc 函数时在堆区动态分配内存，同时需要调用 delete/free 来手动释放申请的内存； 映射区：存储动态链接库以及调用 mmap 函数进行的文件映射 栈：使用栈空间存储函数的 返回地址、参数、局部变量、返回值。 C++/C的内存分配32bitCPU可寻址4G线性空间，每个进程都有各自独立的4G逻辑地址，其中0~3G是用户态空间，3~4G是内核空间，不同进程相同的逻辑地址会映射到不同的物理地址中。其逻辑地址其划分如下： 各个段说明如下： 3G用户空间和1G内核空间 静态区域： text segment（代码段）：包括只读存储区和文本区，其中只读存储区存储字符串常量，文本区存储程序的机器代码。 data segment（数据段）：存储程序中已初始化的全局变量和静态变量 bss segment：存储未初始化的全局变量和静态变量（局部+全局），以及所有被初始化为0的全局变量和静态变量，对于未初始化的全局变量和静态变量，程序运行main之前时会统一清零。即未初始化的全局变量编译器会初始化为0 动态区域： heap（堆）： 当进程未调用malloc时是没有堆段的，只有调用 malloc 时采用分配一个堆，并且在程序运行过程中可以动态增加堆大小（移动break指针），从低地址向高地址增长。分配小内存时使用该区域。堆的起始地址由 mm_struct 结构体中的 start_brk 标识，结束地址由 brk 标识。 memory mapping segment（映射区）：存储动态链接库等文件映射、申请大内存（malloc 时调用 mmap 函数） stack（栈）：使用栈空间存储函数的返回地址、参数、局部变量、返回值，从高地址向低地址增长。在创建进程时会有一个最大栈大小，Linux可以通过 ulimit 命令指定。 如何判断内存泄漏内存泄漏通常是由于调用了 malloc/new 等内存申请的操作，但是缺少了对应的 free/delete。为了判断内存是否泄露，我们一方面可以使用Linux环境下的内存泄漏检查工具 Valgrind，另一方面我们在写代码时可以添加内存申请和释放的统计功能，统计当前申请和释放的内存是否一致，以此来判断内存是否泄露。 什么时候会发生段错误段错误通常发生在访问非法内存地址的时候，具体来说分为以下几种情况： 使用野指针 试图修改字符串常量的内容 什么是memory leak，也就是内存泄漏内存泄漏（memory leak）是指由于疏忽或错误造成了程序未能释放掉不再使用的内存的情况。内存泄漏并非指内存在物理上的消失，而是应用程序分配某段内存后，由于设计错误，失去了对该段内存的控制，因而造成了内存的浪费。 内存泄漏的分类： 堆内存泄漏（Heap leak）。对内存指的是程序运行中根据需要分配通过 malloc、realloc、new 等从堆中分配的一块内存，再是完成后必须通过调用对应的 free 或者 delete 删掉。如果程序的设计的错误导致这部分内存没有被释放，那么此后这块内存将不会被使用，就会产生Heap Leak。 系统资源泄露（Resource Leak）。主要指程序使用系统分配的资源比如 Bitmap、handle、SOCKET 等没有使用相应的函数释放掉，导致系统资源的浪费，严重可导致系统效能降低，系统运行不稳定。 没有将基类的析构函数定义为虚函数。当基类指针指向子类对象时，如果基类的析构函数不是virtual，那么子类的析构函数将不会被调用，子类的资源没有正确是释放，因此造成内存泄露。 回答一下new和malloc的区别 new 分配内存按照数据类型进行分配，malloc 分配内存按照指定的大小分配； new 返回的是指定对象的指针，而 malloc 返回的是 void*，因此 malloc 的返回值一般都需要进行类型转化； new 不仅分配一段内存，而且会调用构造函数，malloc 不会； new 分配的内存要用 delete 销毁，malloc 要用 free 来销毁；delete 销毁的时候会调用对象的析构函数，而 free 则不会； new 是一个操作符可以重载，malloc 是一个库函数； malloc 分配的内存不够的时候，可以用 realloc 扩容；new 没用这样操作。 realloc扩容的原理？对于这样的操作： char* p = malloc(1024); char* q = realloc(p, 2048); 如果当前连续内存块足够 realloc 的话，只是将 p 所指向的空间扩大，并返回 p 的指针地址。这个时候 q 和 p 指向的地址是一样的。 如果当前连续内存块不够长度，再找一个足够长的地方，分配一块新的内存 q，并将 p 指向的内容copy到 q，返回 q。并将 p 所指向的内存空间删除。 这样也就是说 realloc 有时候会产生一个新的内存地址，有的时候不会。所以在分配完成后。我们需要判断下 p 是否等于 q，并做相应的处理。 new 如果分配失败了会抛出 bad_malloc 的异常，而 malloc 失败了会返回 NULL。 申请数组时 new[] 一次分配所有内存，多次调用构造函数，搭配使用 delete[]，delete[] 多次调用析构函数，销毁数组中的每个对象；而 malloc 则只能 sizeof(int) * n。 共享内存相关APILinux允许不同进程访问同一个逻辑内存，提供了一组API，头文件在 sys/shm.h 中。 新建共享内存 shmget int shmget(key_t key, size_t size, int shmflg); key：共享内存键值，可以理解为共享内存的唯一性标记。 size：共享内存大小。 shmflag：创建进程和其他进程的读写权限标识。 返回值：相应的共享内存标识符，失败返回 -1。 连接共享内存到当前进程的地址空间 shmat void *shmat(int shm_id, const void *shm_addr, int shmflg); shm_id：共享内存标识符。 shm_addr：指定共享内存连接到当前进程的地址，通常为 0，表示由系统来选择。 shmflg：标志位。 返回值：指向共享内存第一个字节的指针，失败返回 -1。 当前进程分离共享内存 shmdt int shmdt(const void *shmaddr); 控制共享内存 shmctl 和信号量的semctl函数类似，控制共享内存。 int shmctl(int shm_id, int command, struct shmid_ds *buf); shm_id：共享内存标识符。 command：有三个值。 IPC_STAT：获取共享内存的状态，把共享内存的shmid_ds结构复制到buf中。 IPC_SET：设置共享内存的状态，把buf复制到共享内存的shmid_ds结构。 IPC_RMID：删除共享内存。 buf：共享内存管理结构体。 设计一下如何采用单线程的方式处理高并发在单线程模型中，可以采用I/O复用来提高单线程处理多个请求的能力，然后再采用事件驱动模型，基于异步回调来处理事件。 说一说C++ STL 的内存优化 二级配置器结构 STL内存管理使用二级内存配置器。 第一级配置器（分配大区块） 第一级配置器以 malloc()，free()，realloc() 等C函数执行实际的内存配置、释放、重新配置等操作，并且能在内存需求不被满足的时候，调用一个指定的函数。 一级空间配置器分配的是大于128字节的空间，如果分配不成功，调用句柄释放一部分内存；如果还不能分配成功，抛出异常。 第二级配置器（避免小区块） 在STL的第二级配置器中多了一些机制，避免太多小区块造成的内存碎片，小额区块带来的不仅是内存碎片，配置时还有额外的负担。区块越小，额外负担所占比例就越大。 分配原则 如果要分配的区块大于128bytes，则移交给第一级配置器处理。 如果要分配的区块小于128bytes，则以 内存池管理（memory pool），又称之次层配置（sub-allocation）：每次配置一大块内存，并维护对应的16个空闲链表（free-list）。下次若有相同大小的内存需求，则直接从free-list中取。如果有小额区块被释放，则由配置器回收到free-list中。 当用户申请的空间小于128字节时，将字节数扩展到8的倍数，然后在自由链表中查找对应大小的子链表； 如果在自由链表查找不到或者块数不够，则向内存池进行申请，一般一次申请20块； 如果内存池空间足够，则取出内存； 如果不够分配20块，则分配最多的块数给自由链表，并且更新每次申请的块数； 如果一块都无法提供，则把剩余的内存挂到自由链表，然后向系统heap申请空间，如果申请失败，则看看自由链表还有没有可用的块，如果也没有，则最后调用一级空间配置器。 二级内存池二级内存池采用了16个空闲链表，这里的16个空闲链表分别管理大小为8、16、24……120、128的数据块。这里空闲链表节点的设计十分巧妙，这里用了一个联合体既可以表示下一个空闲数据块（存在于空闲链表中）的地址，也可以表示已经被用户使用的数据块（不存在空闲链表中）的地址。 空间配置函数 allocate 首先先要检查申请空间的大小，如果大于128字节就调用第一级配置器，小于128字节就检查对应的空闲链表，如果该空闲链表中有可用数据块，则直接拿来用（拿取空闲链表中的第一个可用数据块，然后把该空闲链表的地址设置为该数据块指向的下一个地址），如果没有可用数据块，则调用refill重新填充空间。 空间释放函数 deallocate 首先先要检查释放数据块的大小，如果大于128字节就调用第一级配置器，小于128字节则根据数据块的大小来判断回收后的空间会被插入到哪个空闲链表。 重新填充空闲链表 refill 在用allocate配置空间时，如果空闲链表中没有可用数据块，就会调用refill来重新填充空间，新的空间取自内存池。缺省取20个数据块，如果内存池空间不足，那么能取多少个节点就取多少个。 从内存池取空间给空闲链表用是chunk_alloc的工作，首先根据end_free-start_free来判断内存池中的剩余空间是否足以调出nobjs个大小为size的数据块出去，如果内存连一个数据块的空间都无法供应，需要用malloc取堆中申请内存。 假如山穷水尽，整个系统的堆空间都不够用了，malloc失败，那么chunk_alloc会从空闲链表中找是否有大的数据块，然后将该数据块的空间分给内存池（这个数据块会从链表中去除）。 总结： 1.使用 allocate 向 内存池 请求 size 大小的内存空间，如果需要请求的内存大小 大于128bytes，直接使用 malloc。 2.如果需要的内存大小 小于128bytes，allocate 根据 size 找到最适合的自由链表。 a. 如果链表不为空，返回第一个node，链表头改为第二个node。 b. 如果链表为空，使用 blockAlloc 请求分配node。 x. 如果内存池中有大于一个node的空间，分配尽可能多的node（但是最多20个），将一个node返回，其他的node添加到链表中。 y. 如果内存池只有一个node的空间，直接返回给用户。 z. 如果连一个node都没有，再次向操作系统请求分配内存。 ①分配成功，再次进行b过程。 ②分配失败，循环各个自由链表，寻找空间。 I. 找到空间，再次进行过程b。 II. 找不到空间，抛出异常。 3.用户调用 deallocate 释放内存空间，如果要求释放的内存空间 大于128bytes，直接调用 free。 4.否则按照其大小找到合适的自由链表，并将其插入。 C++11C++11有哪些新特性C++11最常用的新特性如下： auto 关键字： 编译器可以根据初始值自动推导出类型。但是不能用于函数传参以及数组类型的推导。 nullptr 关键字： nullptr 是一种特殊类型的字面值，它可以被转换成任意其它的指针类型；而 NULL 一般被宏定义为 0，在遇到重载时可能会出现问题。 智能指针： C++11新增了 std::shared_ptr、std::weak_ptr 等类型的智能指针，用于解决内存管理的问题。 初始化列表： 使用初始化列表来对类进行初始化。 右值引用： 基于右值引用可以实现移动语义和完美转发，消除两个对象交互时不必要的对象拷贝，节省运算存储资源，提高效率。 atomic 原子操作 用于多线程资源互斥操作。 新增STL容器 array 以及 tuple。 详细介绍一下C++11中的可变参数模板、右值引用和 lambda 这几个新特性 可变参数模板： C++11的可变参数模板，对参数进行了高度泛化，可以表示任意数目、任意类型的参数，其语法为：在 class 或 typename 后面带上省略号。 例如： #include &lt;iostream&gt; using namespace std; template &lt;class... T&gt; void func(T... args) { cout &lt;&lt; &quot;num is &quot; &lt;&lt; sizeof...(args) &lt;&lt; endl; } int main() { func(); //args不含任何参数 func(1); //args包含一个int类型的实参 func(1, 2.0); //args包含一个int一个double类型的实参 return 0; } 其中 T 叫做模板参数包，args 叫做函数参数包。 输出结果如下： num is 0 num is 1 num is 2 省略号作用如下： 声明一个包含0到任意个模板参数的参数包； 在模板定义得右边，可以将参数包展成一个个独立的参数。 C++11可以使用递归函数的方式展开参数包，获得可变参数的每个值。通过递归函数展开参数包，需要提供一个参数包展开的函数和一个递归终止函数。 例如： #include &lt;iostream&gt; using namespace std; // 最终递归函数 void print() { cout &lt;&lt; &quot;empty&quot; &lt;&lt; endl; } // 展开函数 template &lt;class T, class... Args&gt; void print(T head, Args... args) { cout &lt;&lt; head &lt;&lt; &quot;, &quot;; print(args...); } int main() { print(1, 2, 3, 4); return 0; } 输出结果如下： 1, 2, 3, 4, empty 右值引用： C++中，左值通常指可以取地址，有名字的值就是左值，而不能取地址，没有名字的就是右值。而在指C++11中，右值是由两个概念构成，将亡值和纯右值。纯右值是用于识别临时变量和一些不跟对象关联的值，比如 1+3 产生的临时变量值，2、true等，而将亡值通常是指具有转移语义的对象，比如返回右值引用 T&amp;&amp; 的函数返回值等。 C++11中，右值引用就是对一个右值进行引用的类型。由于右值通常不具有名字，所以我们一般只能通过右值表达式获得其引用，比如： T &amp;&amp; a = ReturnRvale(); 假设 ReturnRvalue() 函数返回一个右值，那么上述语句声明了一个名为 a 的右值引用，其值等于 ReturnRvalue() 函数返回的临时变量的值。 基于右值引用可以实现转移语义和完美转发新特性。 移动语义： 对于一个包含指针成员变量的类，由于编译器默认的拷贝构造函数都是浅拷贝，所有我们一般需要通过实现深拷贝的拷贝构造函数，为指针成员分配新的内存并进行内容拷贝，从而避免悬挂指针的问题。 但是如下列代码所示： #include &lt;iostream&gt; using namespace std; class HasPtrMem { public: HasPtrMem() : d(new int(0)) { cout &lt;&lt; &quot;Construct: &quot; &lt;&lt; ++n_cstr &lt;&lt; endl; } HasPtrMem(const HasPtrMem &amp;h) : d(new int(*h.d)) { cout &lt;&lt; &quot;Copy construct: &quot; &lt;&lt; ++n_cptr &lt;&lt; endl; } ~HasPtrMem() { cout &lt;&lt; &quot;Destruct: &quot; &lt;&lt; ++n_dstr &lt;&lt; endl; } int *d; static int n_cstr; static int n_dstr; static int n_cptr; }; int HasPtrMem::n_cstr = 0; int HasPtrMem::n_dstr = 0; int HasPtrMem::n_cptr = 0; HasPtrMem GetTemp() { return HasPtrMem(); } int main() { HasPtrMem a = GetTemp(); return 0; } 当类 HasPtrMem 包含一个成员函数 GetTemp，其返回值类型是 HasPtrMem，如果我们定义了深拷贝的拷贝构造函数，那么在调用该函数时需要调用两次拷贝构造函数。第一次是生成GetTemp函数返回时的临时变量，第二次是将该返回值赋值给main函数中的变量a。与此对应需要调用三次析构函数来释放内存。 而在上述过程中，使用临时变量构造a时会调用拷贝构造函数分配对内存，而临时对象在语句结束后会释放它所使用的堆内存。这样重复申请和释放内存，在申请内存较大时会严重影响性能。因此C++使用移动构造函数，从而保证使用临时对象构造a时不分配内存，从而提高性能。 如下列代码所示，移动构造函数接收一个右值引用作为参数，使用右值引用的参数初始化其指针成员变量。 HasPtrMem(HasPtrMem &amp;&amp;h) : d(h.d) { h.d = nullptr; cout &lt;&lt; &quot;Move construct: &quot; &lt;&lt; ++n_mvtr &lt;&lt; endl; } 其原理就是使用在构造对象a时，使用 h.d 来初始化a，然后将临时对象h的成员变量d指向 nullptr，从而保证临时变量析构时不会释放对内存。 完美转发： 完美转发是指在函数模板中，完全依照模板的参数的类型，将参数传递给函数模板中调用的另一个函数，即传入转发函数的是左值对象，目标函数就能获得左值对象，转发函数是右值对象，目标函数就能获得右值对象，而不产生额外的开销。 因此转发函数和目标函数参数一般采用引用类型，从而避免拷贝的开销。其次，由于目标函数可能需要能够既接受左值引用，又接受右值引用，所以考虑转发也需要兼容这两种类型。 Lambda表达式： Lambda表达式定义一个匿名函数，并且可以捕获一定范围内的变量，其定义如下： [capture](params)mutable-&gt;return-type{statement} 其中， [capture]： 捕获列表，捕获上下文变量以供lambda使用。同时 [] 是lambda运算符，编译器根据该符号来判断接下来代码是否是lambda函数。 (Params)： 参数列表，与普通函数的参数列表一致，如果不需要传递参数，则可以连通括号一起省略。 mutable 是修饰符，默认情况下lambda函数总是一个 const 函数，mutable可以取消其常量性。在使用该修饰符时，参数列表不可省略。 -&gt;return-type： 返回类型是返回值类型。 {statement}： 函数体，内容与普通函数一样，除了可以使用参数之外，还可以使用所捕获的变量。 [](int x, int y) { return x + y; } // 隐式返回类型 [](int &amp;x) { ++x; } // 没有 return 语句 -&gt; Lambda 函数的返回类型是void []() { ++global_x; } // 没有参数，仅访问某个全局变量 [] { ++global_x; } // 与上一个相同，省略了 (操作符重载函数参数) Lambda表达式与普通函数最大的区别就是其可以通过捕获列表访问一些上下文中的数据。其形式如下: [var] 表示值传递方式捕捉变量var。 [=] 表示值传递方式捕捉所有父作用域的变量（包括this）。 [&amp;var] 表示引用传递捕捉变量var。 [&amp;] 表示引用捕捉所有父作用域的变量（包括this）。 [this] 表示值传递方式捕捉当前的this指针。 示例1：0 ~ 4的累加和，结果为 10。 #include &lt;iostream&gt; #include &lt;vector&gt; #include &lt;algorithm&gt; using namespace std; int main() { vector&lt;int&gt; some_list; int total = 0; for (int i = 0; i &lt; 5; ++i) some_list.push_back(i); for_each(begin(some_list), end(some_list), [&amp;total](int x) { total += x; }); cout &lt;&lt; total &lt;&lt; endl; return 0; } 示例2：类内0 ~ 4的累加和，结果为 10。 #include &lt;iostream&gt; #include &lt;vector&gt; #include &lt;algorithm&gt; using namespace std; class Test { public: void test() { vector&lt;int&gt; some_list; int total = 0; int value = 1; for (int i = 0; i &lt; 5; ++i) some_list.push_back(i); for_each(begin(some_list), end(some_list), [&amp;, value, this](int x) { total += x * value * this-&gt;some_func(); }); cout &lt;&lt; total &lt;&lt; endl; } int some_func() { return 1; } }; int main() { Test().test(); return 0; } Lambda的类型被定义为“闭包”的类，其通常用于STL库中，在某些场景下可用于简化仿函数的使用，同时Lambda作为局部函数，也会提高复杂代码的开发加速，轻松在函数内重用代码，无须费心设计接口。","categories":[{"name":"面经知识汇总","slug":"面经知识汇总","permalink":"http://yoursite.com/categories/%E9%9D%A2%E7%BB%8F%E7%9F%A5%E8%AF%86%E6%B1%87%E6%80%BB/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://yoursite.com/tags/C/"}]},{"title":"蓝桥杯校内模拟赛复盘","slug":"蓝桥杯校内模拟赛复盘","date":"2020-03-18T10:22:00.000Z","updated":"2020-03-18T10:22:00.000Z","comments":true,"path":"2020/03/18/蓝桥杯校内模拟赛复盘/","link":"","permalink":"http://yoursite.com/2020/03/18/%E8%93%9D%E6%A1%A5%E6%9D%AF%E6%A0%A1%E5%86%85%E6%A8%A1%E6%8B%9F%E8%B5%9B%E5%A4%8D%E7%9B%98/","excerpt":"2020年3月15日蓝桥杯校内模拟赛，难度较为简单。","text":"2020年3月15日蓝桥杯校内模拟赛，难度较为简单。 填空题本人报的是 C/C++ 类型的比赛，在填空题时为了快速得出结果采用的是 Python。 1. 1200000 有多少个约数？（只计算正约数）思路本题从 $[1, 1200000]$ 遍历即可，结果为 96。 代码 Python 法1（常规做法） res = 0 for i in range(1, 1200001): if 1200000 % i == 0: res += 1 print(res) 法2（列表生成式） print(sum([1200000 % i == 0 for i in range(1, 1200001)])) C++ #include &lt;iostream&gt; using namespace std; int main() { int res = 0; for (int i = 1; i &lt;= 1200000; i++) { if (1200000 % i == 0) { res++; } } cout &lt;&lt; res &lt;&lt; endl; return 0; } 2. 在计算机存储中，15.125GB是多少MB思路根据进制换算 $1GB = 2 ^ {10} MB = 1024MB$，进行简单乘法 $15.125 * 1024 = 15488$。 代码#include &lt;iostream&gt; using namespace std; int main() { cout &lt;&lt; (15.125 * 1024) &lt;&lt; endl; return 0; } 3. 一棵包含有 2019 个结点的树，最多包含多少个叶结点思路在总结点数一定时，完全二叉树中有最多的叶子结点。我在做题时忘了具体的计算公式，是在纸上画图算的，思路是算出每一层的二叉树结点数： 第几层 结点数 1 1 2 2 3 4 4 8 … … 10 512 可看出当层数为 $n$ 时每一层的结点数为 $2 ^ {n -1}$，那么前 $n$ 层的结点总数为 $1 + 2 + 3 + … + 2 ^ {n - 1} = 2 ^ n - 1$，采取快速逼近的思想，要使结点总数最接近 2019，当 $n = 10$ 时结点总数为 1023，与 2019 相差 996，故最后一层有 996 个结点，占用了倒数第2层 498 个结点的子结点位置，使得倒数第2层减少了 498 个叶子结点（倒数第2层总共有 512 个结点）而剩下 14 个叶子结点。所以叶子结点总共有 最后一层 996 + 倒数第2层 14 = 1010 个结点。 后来看到有大佬的博客提到由结点总数推出叶子结点数的公式。 太长不看版叶子结点最多的个数与结点总数的奇偶有关，奇数个则有 $\\frac{n + 1}{2}$个，偶数个则有 $\\frac{n}{2}$ 个。 具体分析： 叶子结点就是出度为 0 的结点，即没有子结点的结点。 假设 $n$ 为完全二叉树的结点总数，$n_0$ 是度为0的结点总数（即叶子结点数），$n_1$ 是度为1的结点总数，$n_2$ 是度为2的结点总数，边数为b。 由二叉树的性质可知：n = n_0 + n_1 + n_2\\tag{1} b = n - 1(二叉树是最小连通图)\\tag{2}联立两式得b = n_0 + n_1 + n_2 - 1另有 b = n_1 + 2n_2则有 n_0 + n_1 + n_2 - 1 = n_1 + 2n_2即 n_2 = n_0 - 1\\tag{3} 将上述 (1) (3) 把 $n_2$ 消去可得：n = 2n_0 + n_1 - 1 由于完全二叉树中度为1的结点数 $n_1$ 只有两种可能 0 或 1：当 $n_1 = 0$ 时 n_0 = \\frac{n + 1}{2}\\tag{4}当 $n_1 = 1$ 时 n_0 = \\frac{n}{2}\\tag{5} 完全二叉树中除去最后一层的结点总数有 $(2 ^ n - 1)$ 个，为奇数，根据完全二叉树的结点总数 $n = 2019$ 可以知道最后一层结点数为偶数（奇数 - 奇数 = 偶数），故度为1的结点数 $n_1 = 0$，利用公式 (4) 求出叶子结点数 $n_0 = \\frac{n + 1}{2} = \\frac{2019 + 1}{2}= 1010$。 代码#include &lt;iostream&gt; using namespace std; int main() { int n = 2019; if (n % 2 == 1) //若结点总数为奇数，则n1 = 0 { cout &lt;&lt; (n + 1) / 2 &lt;&lt; endl; } else //若结点总数为偶数，则n1 = 1 { cout &lt;&lt; n / 2 &lt;&lt; endl; } return 0; } 4. 在 1 至 2019 中，有多少个数的数位中包含数字 9思路本题从 $[1, 2019]$ 遍历即可，结果为 544。 代码 Python 法1（常规做法） res = 0 for num in range(1, 2020): # 在循环体内修改循环变量不会影响循环条件中的循环变量 while num != 0: if num % 10 == 9: res += 1 break else: num //= 10 print(res) 法2（列表生成式） print(sum([&#39;9&#39; in str(num) for num in range(1, 2020)])) C++ #include &lt;iostream&gt; #include &lt;string&gt; using namespace std; int main() { int res = 0; for (int num = 1; num &lt;= 2019; num++) { string s = to_string(num); if (s.find(&#39;9&#39;) != -1) { res++; } } cout &lt;&lt; res &lt;&lt; endl; return 0; } 编程题5. 给定一个数列，请问数列中有多少个元素可能是递增三元组的中心 问题描述： 在数列 $a[1], a[2], …, a[n]$ 中，如果对于下标 $i, j, k$ 满足 $0 &lt; i &lt; j &lt; k &lt; n + 1$ 且 $a[i] &lt; a[j] &lt; a[k]$，则称 $a[i], a[j], a[k]$ 为一组递增三元组，$a[j]$ 为递增三元组的中心。 输入格式： 输入的第一行包含一个整数 n。第二行包含 n 个整数 a[1], a[2], …, a[n]，相邻的整数间用空格分隔，表示给定的数列。输出格式： 输出一行包含一个整数，表示答案。 样例输入：51 2 5 3 5样例输出：2样例说明： a[2] 和 a[4] 可能是三元组的中心。 评测用例规模与约定： 对于 50% 的评测用例，2 &lt;= n &lt;= 100，0 &lt;= 数列中的数 &lt;= 1000。对于 所有 评测用例，2 &lt;= n &lt;= 1000，0 &lt;= 数列中的数 &lt;= 10000。 思路1三层循环暴力遍历，时间复杂度为 $O(n ^ 3)$，在实际评测时可能会超时。 #include &lt;iostream&gt; #include &lt;set&gt; using namespace std; int main() { int n; cin &gt;&gt; n; int a[n]; for (int i = 0; i &lt; n; i++) { cin &gt;&gt; a[i]; } set&lt;int&gt; s; for (int i = 0; i &lt; n - 2; i++) { for (int j = i + 1; j &lt; n - 1; j++) { for (int k = j + 1; k &lt; n; k++) { if (a[i] &lt; a[j] &amp;&amp; a[j] &lt; a[k]) { /* 注意，对于[1, 2, 2, 3]之类有重复连续元素的特殊数组 此处如果是s.insert(a[j])，则结果会偏小 */ s.insert(j); break; // 提前结束内层循环，节省时间 } } } } cout &lt;&lt; s.size() &lt;&lt; endl; return 0; } 思路2正序遍历一次数组，max 数组记录满足 a[i] &lt; a[j](i &lt; j) 的下标元素 j；逆序遍历一次数组，min 数组记录满足 a[j] &lt; a[k](j &lt; k) 的下标元素 j，最后求 max 数组和 min 数组的交集数目。时间复杂度为 $O(n)$。 #include &lt;iostream&gt; using namespace std; int main() { int n; cin &gt;&gt; n; int a[n]; bool max[n] = {false}, min[n] = {false}; for (int i = 0; i &lt; n; i++) { cin &gt;&gt; a[i]; } int bottom = a[0]; for (int i = 1; i &lt; n - 1; i++) { if (a[i] &gt; bottom) { max[i] = true; } else if (a[i] &lt; bottom) { bottom = a[i]; } } int top = a[n - 1]; int res = 0; for (int i = n - 2; i &gt;= 1; i--) { if (a[i] &lt; top) { min[i] = true; } else if (a[i] &gt; top) { top = a[i]; } } for (int i = 1; i &lt; n - 1; i++) { if (max[i] &amp;&amp; min[i]) { res++; } } cout &lt;&lt; res &lt;&lt; endl; return 0; } 而在逆序遍历时其实已经可以直接进行比较，去掉 min 数组以及省去最后一次遍历过程，节省时间。 #include &lt;iostream&gt; using namespace std; int main() { int n; cin &gt;&gt; n; int a[n]; bool max[n] = {false}; for (int i = 0; i &lt; n; i++) { cin &gt;&gt; a[i]; } int bottom = a[0]; for (int i = 1; i &lt; n - 1; i++) { if (a[i] &gt; bottom) { max[i] = true; } else if (a[i] &lt; bottom) { bottom = a[i]; } } int top = a[n - 1]; int res = 0; for (int i = n - 2; i &gt;= 1; i--) { if (a[i] &lt; top &amp;&amp; max[i]) { res++; } else if (a[i] &gt; top) { top = a[i]; } } cout &lt;&lt; res &lt;&lt; endl; return 0; } 6. 给定正整数 n，请问在整数 1 至 n 中有多少个数位递增的数 问题描述： 一个正整数如果任何一个数位不大于右边相邻的数位，则称为一个数位递增的数，例如1135是一个数位递增的数，而1024不是一个数位递增的数。 输入格式： 输入的第一行包含一个整数 n。输出格式： 输出一行包含一个整数，表示答案。 样例输入： 30样例输出： 26 评测用例规模与约定： 对于 40% 的评测用例，1 &lt;= n &lt;= 1000。对于 80% 的评测用例，1 &lt;= n &lt;= 100000。对于 所有 评测用例，1 &lt;= n &lt;= 1000000。 思路本题从 $[1, n]$ 遍历即可。 代码#include &lt;iostream&gt; using namespace std; int main() { int n; cin &gt;&gt; n; int res = 0; for (int i = 1; i &lt;= n; i++) { int tmp = i, max = 9; while (tmp) { if (tmp % 10 &lt;= max) { max = tmp % 10; } else { break; } tmp /= 10; } // 当tmp归零时说明该数已完全遍历 if (tmp == 0) { res++; } } cout &lt;&lt; res &lt;&lt; endl; return 0; } 7. 特殊单词问题描述： 小明对类似于 hello 这种单词非常感兴趣，这种单词可以正好分为四段，第一段由一个或多个辅音字母组成，第二段由一个或多个元音字母组成，第三段由一个或多个辅音字母组成，第四段由一个或多个元音字母组成。给定一个单词，请判断这个单词是否也是这种单词，如果是请输出 yes，否则请输出 no。（元音字母包括 a, e, i, o, u，共五个，其他均为辅音字母。） 输入格式： 输入一行，包含一个单词，单词中只包含小写英文字母。输出格式： 输出答案，或者为yes，或者为no。 样例输入： lanqiao样例输出： yes 样例输入： world样例输出： no 评测用例规模与约定： 对于 所有 评测用例，单词中的字母个数不超过 100。 思路因为状态只有 空 -&gt; 辅音 -&gt; 元音 -&gt; 辅音 -&gt; 元音 五种状态，状态空间并不大，所以可以由 0 到 4列举出来。 代码#include &lt;iostream&gt; #include &lt;string&gt; using namespace std; // 判断是否是元音 bool isVowel(char ch) { return ch == &#39;a&#39; || ch == &#39;e&#39; || ch == &#39;i&#39; || ch == &#39;o&#39; || ch == &#39;u&#39;; } int main() { string word; cin &gt;&gt; word; int state = 0; for (int i = 0; i &lt; word.size(); i++) { if (state == 0) { if (!isVowel(word[i])) { state = 1; } else { break; } } else if (state == 1) { if (isVowel(word[i])) { state = 2; } } else if (state == 2) { if (!isVowel(word[i])) { state = 3; } } else if (state == 3) { if (isVowel(word[i])) { state = 4; } } else if (state == 4) { if (!isVowel(word[i])) { state = 5; break; // 已超过题目要求，继续遍历无意义，可直接退出循环 } } } cout &lt;&lt; ((state == 4) ? &quot;yes&quot; : &quot;no&quot;) &lt;&lt; endl; return 0; } 延伸思考原题是单词中辅音和元音状态转换 4 次，倘若改成转换 n 次，则不能一一列举，需要根据奇偶状态进行判断，将状态抽象出来。 抽象出函数如下： bool isMatch(string word, int n) { if (n &lt;= 0) { return false; } int state = 0; for (int i = 0; i &lt; word.size(); i++) { /* 注意，空状态state = 0和元音状态 state % 2 == 0是有区别的 空状态只能接辅音，而元音状态辅音元音都能接 */ if (state == 0) { if (!isVowel(word[i])) { state++; } else { break; } } else if (state &gt; n) { break; } else { // 如果当前状态与下一个字母类型相反状态才变化 if ((state % 2 == 1 &amp;&amp; isVowel(word[i])) || (state % 2 == 0 &amp;&amp; !isVowel(word[i]))) { state++; } } } return state == n; } 8. 神奇序列问题描述： 小明想知道，满足以下条件的正整数序列的数量： 第一项为 n； 第二项不超过 n； 从第三项开始，每一项小于前两项的差的绝对值。 请计算，对于给定的 n，有多少种满足条件的序列。 输入格式： 输入一行包含一个整数 n。输出格式： 输出一个整数，表示答案。答案可能很大，请输出答案除以 10000 的余数。 样例输入： 4样例输出： 7样例说明：以下是满足条件的序列：4 14 1 14 1 24 24 2 14 34 4 评测用例规模与约定： 对于 20% 的评测用例，1 &lt;= n &lt;= 5；对于 50% 的评测用例，1 &lt;= n &lt;= 10；对于 80% 的评测用例，1 &lt;= n &lt;= 100；对于 所有 评测用例，1 &lt;= n &lt;= 1000。 思路1对于层层深入，我首先采用的是深度优先遍历（DFS）的算法，思路非常简单。 #include &lt;iostream&gt; #include &lt;cmath&gt; using namespace std; int res = 0; void DFS(int first, int second) { for (int i = 1; i &lt; abs(first - second); i++) { res = (res + 1) % 10000; DFS(second, i); } } int main() { int n; cin &gt;&gt; n; for (int second = 1; second &lt;= n; second++) { res++; DFS(n, second); } cout &lt;&lt; res &lt;&lt; endl; return 0; } 分析对于思路1的算法，在 n 取到 30 时，耗费时间就已经是肉眼可见的慢了，对于 n 上限为 1000 的测试用例，这样的效率显然是无法接受的。 分析后猜想低效原因主要有两个，一个是调用 DFS 层数太深、次数太多，二是在前一部分搜索过的内容可能之后还会多次搜索（比如对于 131 来说，13 和 31 本质是一样的，但是前后搜索了两次）冗余程度较高。 从上面的分析可以联想到斐波那契数列（Fibonacci sequence），这两道题目有很高的相似性，想通了提高斐波那契数列时间效率对于本题或许就能迎刃而解。 斐波那契数列的定义如下： fib(x)=\\left\\{ \\begin{aligned} 1, \\quad & x = 1 & or && x = 2\\\\ fib(x - 1) + fib(x - 2), \\quad & {x \\ge 2}\\\\ \\end{aligned} \\right.最直接的算法依然是 DFS。 int Fibonacci(int n) { return (n == 1 || n == 2) ? 1 : Fibonacci(n - 1) + Fibonacci(n - 2); } Fibonacci(40) = 102334155，这个数字已经很大了，计算速度也非常慢。 此时可以进行优化，将已经搜索过的数字保存起来。保存数字最直接想到用数组，但是 Fibonacci(n) 只与前两项有关，故用两个常量保存即可。 int Fibonacci(int n) { if (n == 1 || n == 2) { return 1; } int a = 1, b = 1; for (int i = 3; i &lt;= n; i++) { // 实现a = b, b = a + b b += a; a = b - a; } return b; } 思路2回到本题中来，设置二维数组v，v[first][second] 表示本位置前两个数为 first 和 second 时的序列数量。将搜索过的内容记录下来，后续需要时只需要调用即可。当 n = 1000 时得到结果比思路一要快得多。 #include &lt;iostream&gt; #include &lt;vector&gt; #include &lt;cmath&gt; using namespace std; int DFS(vector&lt;vector&lt;int&gt; &gt; &amp;v, int first, int second) { int tmp = abs(first - second); if (tmp &lt;= 1) { return 0; } if (v[first][second] != 0) { return v[first][second]; } else { int res = 0; for (int i = 1; i &lt; tmp; i++) { res = (res + 1 + DFS(v, second, i)) % 10000; } v[first][second] = v[second][first] = res; return res; } } int main() { int n; cin &gt;&gt; n; vector&lt;vector&lt;int&gt; &gt; v(n + 1, vector&lt;int&gt;(n + 1, 0)); int res = 0; for (int i = 1; i &lt;= n; i++) { res = (res + 1 + DFS(v, n, i)) % 10000; } cout &lt;&lt; res &lt;&lt; endl; return 0; } 9. 草地延伸问题描述： 小明有一块空地，他将这块空地划分为 n 行 m 列的小块，每行和每列的长度都为 1。小明选了其中的一些小块空地，种上了草，其他小块仍然保持是空地。这些草长得很快，每个月，草都会向外长出一些，如果一个小块种了草，则它将向自己的上、下、左、右四小块空地扩展，这四小块空地都将变为有草的小块。请告诉小明，k 个月后空地上哪些地方有草。 输入格式： 输入的第一行包含两个整数 n, m。接下来 n 行，每行包含 m 个字母，表示初始的空地状态，字母之间没有空格。如果为小数点，表示为空地，如果字母为 g，表示种了草。接下来包含一个整数 k。输出格式： 输出 n 行，每行包含 m 个字母，表示 k 个月后空地的状态。如果为小数点，表示为空地，如果字母为 g，表示长了草。 样例输入：4 5.g……....g..…..2样例输出：gggg.gggg.ggggg.ggg. 评测用例规模与约定：对于 30% 的评测用例，2 &lt;= n, m &lt;= 20。对于 70% 的评测用例，2 &lt;= n, m &lt;= 100。对于 所有 评测用例，2 &lt;= n, m &lt;= 1000，1 &lt;= k &lt;= 1000。 思路广度优先遍历（BFS）一圈圈向外延展即可。 代码#include &lt;iostream&gt; #include &lt;string&gt; #include &lt;vector&gt; using namespace std; int main() { int n, m; cin &gt;&gt; n &gt;&gt; m; char grass[n][m]; vector&lt;pair&lt;int, int&gt;&gt; v; for (int i = 0; i &lt; n; i++) { string s; cin &gt;&gt; s; for (int j = 0; j &lt; m; j++) { grass[i][j] = s[j]; if (s[j] == &#39;g&#39;) { v.push_back(make_pair(i, j)); } } } int k; cin &gt;&gt; k; // 当到达截止时间或无草可长时停止循环 for (int time = 0; time &lt; k &amp;&amp; !v.empty(); time++) { vector&lt;pair&lt;int, int&gt;&gt; next; for (vector&lt;pair&lt;int, int&gt;&gt;::iterator it = v.begin(); it != v.end(); it++) { int i = it-&gt;first, j = it-&gt;second; if (i &gt;= 1 &amp;&amp; grass[i - 1][j] != &#39;g&#39;) { next.push_back(make_pair(i - 1, j)); } if (i &lt;= n - 2 &amp;&amp; grass[i + 1][j] != &#39;g&#39;) { next.push_back(make_pair(i + 1, j)); } if (j &gt;= 1 &amp;&amp; grass[i][j - 1] != &#39;g&#39;) { next.push_back(make_pair(i, j - 1)); } if (j &lt;= m - 2 &amp;&amp; grass[i][j + 1] != &#39;g&#39;) { next.push_back(make_pair(i, j + 1)); } } for (vector&lt;pair&lt;int, int&gt;&gt;::iterator it = next.begin(); it != next.end(); it++) { grass[it-&gt;first][it-&gt;second] = &#39;g&#39;; } v = next; // 更新最外圈位置 } for (int i = 0; i &lt; n; i++) { for (int j = 0; j &lt; m; j++) { cout &lt;&lt; grass[i][j]; } cout &lt;&lt; endl; } return 0; } 10. 好看晚会问题描述： 小明要组织一台晚会，总共准备了 n 个节目。然后晚会的时间有限，他只能最终选择其中的 m 个节目。这 n 个节目是按照小明设想的顺序给定的，顺序不能改变。小明发现，观众对于晚上的喜欢程度与前几个节目的好看程度有非常大的关系，他希望选出的第一个节目尽可能好看，在此前提下希望第二个节目尽可能好看，依次类推。小明给每个节目定义了一个好看值，请你帮助小明选择出 m 个节目，满足他的要求。 输入格式： 输入的第一行包含两个整数 n, m ，表示节目的数量和要选择的数量。第二行包含 n 个整数，依次为每个节目的好看值。输出格式： 输出一行包含 m 个整数，为选出的节目的好看值。 样例输入：5 33 1 2 5 4样例输出：3 5 4样例说明： 选择了第1, 4, 5个节目。 评测用例规模与约定： 对于 30% 的评测用例，1 &lt;= n &lt;= 20；对于 60% 的评测用例，1 &lt;= n &lt;= 100；对于 所有 评测用例，1 &lt;= n &lt;= 100000，0 &lt;= 节目的好看值 &lt;= 100000。 思路题目并不难，先将 n 个节目按好看程度排序，再将最好看的 m 个节目里按序号排序，输出前 m 个节目好看程度即可。 代码#include &lt;iostream&gt; #include &lt;algorithm&gt; using namespace std; struct node { int number, look; // 按好看程度排序函数 bool operator&lt;(const node &amp;y) const { if (look == y.look) return number &lt;= y.number; return look &gt; y.look; } }; // 最好看的m个节目里按序号排序函数 bool cmp(const node &amp;x, const node &amp;y) { return x.number &lt; y.number; } int main() { int n, m; cin &gt;&gt; n &gt;&gt; m; node a[n]; for (int i = 0; i &lt; n; i++) { int look; cin &gt;&gt; look; a[i].number = i + 1; a[i].look = look; } sort(a, a + n); // 按好看程度排序 sort(a, a + m, cmp); // 最好看的m个节目里按序号排序 for (int i = 0; i &lt; m; i++) { cout &lt;&lt; a[i].look &lt;&lt; &quot; &quot;; } return 0; }","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"http://yoursite.com/categories/Algorithm/"}],"tags":[{"name":"蓝桥杯","slug":"蓝桥杯","permalink":"http://yoursite.com/tags/%E8%93%9D%E6%A1%A5%E6%9D%AF/"}]}],"categories":[{"name":"面经知识汇总","slug":"面经知识汇总","permalink":"http://yoursite.com/categories/%E9%9D%A2%E7%BB%8F%E7%9F%A5%E8%AF%86%E6%B1%87%E6%80%BB/"},{"name":"Algorithm","slug":"Algorithm","permalink":"http://yoursite.com/categories/Algorithm/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://yoursite.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"计算机网络","slug":"计算机网络","permalink":"http://yoursite.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"排序","slug":"排序","permalink":"http://yoursite.com/tags/%E6%8E%92%E5%BA%8F/"},{"name":"操作系统","slug":"操作系统","permalink":"http://yoursite.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"C++","slug":"C","permalink":"http://yoursite.com/tags/C/"},{"name":"蓝桥杯","slug":"蓝桥杯","permalink":"http://yoursite.com/tags/%E8%93%9D%E6%A1%A5%E6%9D%AF/"}]}