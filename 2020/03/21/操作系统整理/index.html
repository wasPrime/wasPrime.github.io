<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="wasPrime&#39;s Blog">
  <meta name="author" content="wasPrime">
  <meta name="keywords" content="wasPrime, keywords">
  <title>操作系统整理 - wasPrime</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/5.12.1/css/all.min.css" />
<link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />
<link  rel="stylesheet" href="https://cdn.staticfile.org/mdbootstrap/4.13.0/css/mdb.min.css" />
<link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/3.0.1/github-markdown.min.css" />

<link rel="stylesheet" href="//at.alicdn.com/t/font_1067060_qzomjdt8bmp.css">



  <link  rel="stylesheet" href="/lib/prettify/github-v2.min.css" />

<link  rel="stylesheet" href="/css/main.css" />


  <link defer rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />


<!-- 自定义样式保持在最底部 -->


<meta name="generator" content="Hexo 4.2.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>wasPrime</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">首页</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">归档</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">分类</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">标签</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">关于</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask rgba-black-light flex-center">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              
                <p class="mt-3 post-meta">
                  <i class="fas fa-calendar-alt" aria-hidden="true"></i>
                  2020 年 03 月 21 日 下午
                </p>
              

              <p class="mt-1">
                
                  
                  <span class="post-meta">
                    <i class="far fa-chart-bar"></i>
                    24.4k 字
                  </span>
                

                
                  
                  <span class="post-meta">
                      <i class="far fa-clock"></i>
                      85 分钟
                  </span>
                

                
                  <!-- 不蒜子统计文章PV -->
                  
                  <span id="busuanzi_container_page_pv" class="post-meta" style="display: none">
                    <i class="far fa-eye" aria-hidden="true"></i>
                    <span id="busuanzi_value_page_pv"></span> 次
                  </span>
                
              </p>
            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5 z-depth-3" id="board">
          <div class="post-content mx-auto" id="post">
            
              <p
                class="note note-warning">本文最后更新于：2020 年 03 月 21 日 下午</p>
            
            <div class="markdown-body">
              <blockquote>
<p>面试常见的操作系统考点</p>
</blockquote>
<a id="more"></a>
<h2 id="说一下进程与线程的概念，以及为什么要有进程线程，其中有什么区别，他们各自又是怎么同步的"><a href="#说一下进程与线程的概念，以及为什么要有进程线程，其中有什么区别，他们各自又是怎么同步的" class="headerlink" title="说一下进程与线程的概念，以及为什么要有进程线程，其中有什么区别，他们各自又是怎么同步的"></a>说一下进程与线程的概念，以及为什么要有进程线程，其中有什么区别，他们各自又是怎么同步的</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><ul>
<li><p><code>进程</code> 是对运行时程序的 <code>封装</code>，<strong>是系统进行资源调度和分配的的基本单位</strong>，实现了操作系统的并发；</p>
</li>
<li><p><code>线程</code> 是进程的子任务，是<strong>CPU调度和分派的基本单位</strong>，用于保证程序的实时性，实现进程内部的并发；线程是 <strong>操作系统可识别的最小执行和调度单位</strong>。每个线程都独自占用一个虚拟处理器：独自的寄存器组，指令计数器和处理器状态。每个线程完成不同的任务，但是共享同一地址空间（也就是同样的动态内存，映射文件，目标代码等等），打开的文件队列和其他内核资源。</p>
</li>
</ul>
<h3 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h3><ol>
<li><p>一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。线程依赖于进程而存在。</p>
</li>
<li><p>进程在执行过程中拥有独立的内存单元，而多个线程共享进程的内存。（资源分配给进程，同一进程的所有线程共享该进程的所有资源。<strong>同一进程中的多个线程共享代码段（代码和常量），数据段（全局变量和静态变量），扩展段（堆存储）。</strong> 但是每个线程拥有自己的栈段，栈段又叫运行时段，用来存放所有局部变量和临时变量。）</p>
</li>
<li><p><strong>进程是资源分配的最小单位，线程是CPU调度的最小单位；</strong></p>
</li>
<li><p><code>系统开销</code>：由于在创建或撤消进程时，系统都要为之分配或回收资源，如内存空间、I／O设备等。因此，操作系统所付出的开销将显著地大于在创建或撤消线程时的开销。类似地，在进行进程切换时，涉及到整个当前进程CPU环境的保存以及新被调度运行的进程的CPU环境的设置。而线程切换只须保存和设置少量寄存器的内容，并不涉及存储器管理方面的操作。可见，进程切换的开销也远大于线程切换的开销。</p>
</li>
<li><p><code>通信</code>：由于同一进程中的多个线程具有相同的地址空间，致使它们之间的同步和通信的实现，也变得比较容易。进程间通信IPC，线程间可以直接读写进程数据段（如全局变量）来进行通信——需要进程同步和互斥手段的辅助，以保证数据的一致性。在有的系统中，线程的切换、同步和通信都无须操作系统内核的干预。</p>
</li>
<li><p>进程编程调试简单可靠性高，但是创建销毁开销大；线程正相反，开销小，切换速度快，但是编程调试相对复杂。</p>
</li>
<li><p>进程间不会相互影响；线程一个线程挂掉将导致整个进程挂掉</p>
</li>
<li><p>进程适应于多核、多机分布；线程适用于多核。</p>
</li>
</ol>
<h3 id="进程间通信的方式"><a href="#进程间通信的方式" class="headerlink" title="进程间通信的方式"></a>进程间通信的方式</h3><p>进程间通信主要包括 <code>管道</code>、<code>系统IPC（包括消息队列、信号量、信号、共享内存等）</code>、以及 <code>套接字socket</code>。</p>
<ol>
<li><p><strong>管道</strong></p>
<p> <code>管道</code> 主要包括 <code>无名管道</code> 和 <code>命名管道</code>：管道可用于具有亲缘关系的父子进程间的通信，有名管道除了具有管道所具有的功能外，它还允许无亲缘关系进程间的通信。</p>
<ol>
<li><p><strong>普通管道PIPE</strong></p>
<ol>
<li><p>它是 <code>半双工</code> 的（即数据只能在一个方向上流动），具有固定的读端和写端；</p>
</li>
<li><p>它只能用于具有亲缘关系的进程之间的通信（也是父子进程或者兄弟进程之间）；</p>
</li>
<li><p>它可以看成是一种特殊的文件，对于它的读写也可以使用普通的read、write等函数。但是它不是普通的文件，并不属于其他任何文件系统，并且只存在于内存中。</p>
</li>
</ol>
</li>
<li><p><strong>命名管道FIFO</strong></p>
<ol>
<li><p>FIFO可以在无关的进程之间交换数据</p>
</li>
<li><p>FIFO有路径名与之相关联，它以一种特殊设备文件形式存在于文件系统中。</p>
</li>
</ol>
</li>
</ol>
</li>
<li><p><strong>系统IPC</strong></p>
<ol>
<li><p><strong>消息队列</strong></p>
<p>  <code>消息队列</code>，是消息的链接表，存放在内核中。一个消息队列由一个标识符（即队列ID）来标记。（消息队列克服了信号传递信息少，管道只能承载无格式字节流以及缓冲区大小受限等特点）具有写权限得进程可以按照一定得规则向消息队列中添加新信息；对消息队列有读权限得进程则可以从消息队列中读取信息；</p>
<p>  <strong>特点：</strong></p>
<ol>
<li><p>消息队列是面向记录的，其中的消息具有特定的格式以及特定的优先级。</p>
</li>
<li><p>消息队列独立于发送与接收进程。进程终止时，消息队列及其内容并不会被删除。</p>
</li>
<li><p>消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取。</p>
</li>
</ol>
</li>
<li><p><strong>信号量semaphore</strong></p>
<p>  <code>信号量（semaphore）</code>与已经介绍过的 <code>IPC</code> 结构不同，它是一个计数器，可以用来控制多个进程对共享资源的访问。信号量用于实现进程间的互斥与同步，而不是用于存储进程间通信数据。</p>
<p>  <strong>特点：</strong></p>
<ol>
<li><p>信号量用于进程间同步，若要在进程间传递数据需要结合共享内存。</p>
</li>
<li><p>信号量基于操作系统的 PV 操作，程序对信号量的操作都是原子操作。</p>
</li>
<li><p>每次对信号量的 PV 操作不仅限于对信号量值加 1 或减 1，而且可以加减任意正整数。</p>
</li>
<li><p>支持信号量组。</p>
</li>
</ol>
</li>
<li><p><strong>信号signal</strong></p>
<p>  <code>信号</code>是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。</p>
</li>
<li><p><strong>共享内存（Shared Memory）</strong></p>
<p>  它使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据得更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等</p>
<p>  <strong>特点：</strong></p>
<ol>
<li><p>共享内存是最快的一种IPC，因为进程是直接对内存进行存取；</p>
</li>
<li><p>因为多个进程可以同时操作，所以需要进行同步；</p>
</li>
<li><p>信号量+共享内存通常结合在一起使用，信号量用来同步对共享内存的访问。</p>
</li>
</ol>
</li>
</ol>
</li>
<li><p><strong>套接字socket</strong></p>
<p><code>socket</code> 也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同主机之间的进程通信。</p>
</li>
</ol>
<h3 id="线程间通信的方式"><a href="#线程间通信的方式" class="headerlink" title="线程间通信的方式"></a>线程间通信的方式</h3><ol>
<li><p><code>临界区</code>：通过多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问；</p>
</li>
<li><p><code>互斥量Synchronized/Lock</code>：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问</p>
</li>
<li><p><code>信号量Semaphore</code>：为控制具有有限数量的用户资源而设计的，它允许多个线程在同一时刻去访问同一个资源，但一般需要限制同一时刻访问此资源的最大线程数目。</p>
</li>
<li><p><code>事件（信号），Wait/Notify</code>：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作</p>
</li>
</ol>
<h2 id="说一说Linux虚拟地址空间"><a href="#说一说Linux虚拟地址空间" class="headerlink" title="说一说Linux虚拟地址空间"></a>说一说Linux虚拟地址空间</h2><p>为了防止不同进程同一时刻在物理内存中运行而对物理内存的争夺和践踏，采用了虚拟内存。<br>虚拟内存技术使得不同进程在运行过程中，它所看到的是自己独自占有了当前系统的4G内存。所有进程共享同一物理内存，每个进程只把自己目前需要的虚拟内存空间映射并存储到物理内存上。 事实上，在每个进程创建加载时，内核只是为进程「创建」了虚拟内存的布局，具体就是初始化进程控制表中内存相关的链表，实际上并不立即就把虚拟内存对应位置的程序数据和代码（比如 <code>.text</code>、<code>.data</code> 段）拷贝到物理内存中，只是建立好虚拟内存和磁盘文件之间的映射就好（叫做存储器映射），等到运行到对应的程序时，才会通过缺页异常，来拷贝数据。还有进程运行过程中，要动态分配内存，比如 <code>malloc</code> 时，也只是分配了虚拟内存，即为这块虚拟内存对应的页表项做相应设置，当进程真正访问到此数据时，才引发缺页异常。</p>
<p>请求分页系统、请求分段系统和请求段页式系统都是针对虚拟内存的，通过请求实现内存与外存的信息置换。</p>
<ul>
<li><p><strong>虚拟内存的好处：</strong></p>
<ol>
<li><p>扩大地址空间；</p>
</li>
<li><p><code>内存保护</code>：每个进程运行在各自的虚拟内存地址空间，互相不能干扰对方。虚存还对特定的内存地址提供写保护，可以防止代码或数据被恶意篡改。</p>
</li>
<li><p><code>公平内存分配</code>：采用了虚存之后，每个进程都相当于有同样大小的虚存空间。</p>
</li>
<li><p>当进程通信时，可采用虚存共享的方式实现。</p>
</li>
<li><p>当不同的进程使用同样的代码时，比如库文件中的代码，物理内存中可以只存储一份这样的代码，不同的进程只需要把自己的虚拟内存映射过去就可以了，节省内存。</p>
</li>
<li><p>虚拟内存很适合在多道程序设计系统中使用，许多程序的片段同时保存在内存中。当一个程序等待它的一部分读入内存时，可以把CPU交给另一个进程使用。在内存中可以保留多个进程，系统并发度提高。</p>
</li>
<li><p>在程序需要分配连续的内存空间的时候，只需要在虚拟内存空间分配连续空间，而不需要实际物理内存的连续空间，可以利用碎片。</p>
</li>
</ol>
</li>
<li><p><strong>虚拟内存的代价：</strong></p>
<ol>
<li><p>虚存的管理需要建立很多数据结构，这些数据结构要占用额外的内存。</p>
</li>
<li><p>虚拟地址到物理地址的转换，增加了指令的执行时间。</p>
</li>
<li><p>页面的换入换出需要磁盘I/O，这是很耗时的。</p>
</li>
<li><p>如果一页中只有一部分数据，会浪费内存。</p>
</li>
</ol>
</li>
</ul>
<h2 id="说一说操作系统中的程序的内存结构"><a href="#说一说操作系统中的程序的内存结构" class="headerlink" title="说一说操作系统中的程序的内存结构"></a>说一说操作系统中的程序的内存结构</h2><p>一个程序本质上都是由 <code>BSS段</code>、<code>data段</code>、<code>text段</code> 三个组成的。可以看到一个可执行程序在存储（没有调入内存）时分为代码段、数据区和未初始化数据区三部分。</p>
<p><img src="/2020/03/21/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%95%B4%E7%90%86/内存结构.png" srcset="/img/loading.gif" alt="内存结构"></p>
<p><strong>BSS段（未初始化数据区）：</strong> 通常用来存放程序中未初始化的全局变量和静态变量的一块内存区域。BSS段属于静态分配，程序结束后静态变量资源由系统自动释放。</p>
<p><strong>数据段：</strong> 存放程序中已初始化的全局变量的一块内存区域。数据段也属于静态内存分配</p>
<p><strong>代码段：</strong> 存放程序执行代码的一块内存区域。这部分区域的大小在程序运行前就已经确定，并且内存区域属于只读。在代码段中，也有可能包含一些只读的常数变量</p>
<blockquote>
<p>text段和data段在编译时已经分配了空间，而BSS段并不占用可执行文件的大小，它是由链接器来获取内存的。</p>
<p>BSS段（未进行初始化的数据）的内容并不存放在磁盘上的程序文件中。其原因是内核在程序开始运行前将它们设置为0。需要存放在程序文件中的只有正文段和初始化数据段。</p>
<p>data段（已经初始化的数据）则为数据分配空间，数据保存到目标文件中。</p>
<p>数据段包含经过初始化的全局变量以及它们的值。BSS段的大小从可执行文件中得到，然后链接器得到这个大小的内存块，紧跟在数据段的后面。当这个内存进入程序的地址空间后全部清零。包含数据段和BSS段的整个区段此时通常称为数据区。</p>
</blockquote>
<p>可执行程序在运行时又多出两个区域：栈区和堆区。</p>
<p><strong>栈区：</strong> 由编译器自动释放，存放函数的参数值、局部变量等。每当一个函数被调用时，该函数的返回类型和一些调用的信息被存放到栈中。然后这个被调用的函数再为他的自动变量和临时变量在栈上分配空间。每调用一个函数一个新的栈就会被使用。栈区是从高地址位向低地址位增长的，是一块连续的内存区域，最大容量是由系统预先定义好的，申请的栈空间超过这个界限时会提示溢出，用户能从栈中获取的空间较小。</p>
<p><strong>堆区：</strong> 用于动态分配内存，位于BSS和栈中间的地址区域。由程序员申请分配和释放。堆是从低地址位向高地址位增长，采用链式存储结构。频繁的malloc/free造成内存空间的不连续，产生碎片。当申请堆空间时库函数是按照一定的算法搜索可用的足够大的空间。因此堆的效率比栈要低的多。</p>
<h2 id="A-a-new-A-a-gt-i-10-在内核中的内存分配上发生了什么"><a href="#A-a-new-A-a-gt-i-10-在内核中的内存分配上发生了什么" class="headerlink" title="A* a = new A; a-&gt;i = 10; 在内核中的内存分配上发生了什么"></a><code>A* a = new A; a-&gt;i = 10;</code> 在内核中的内存分配上发生了什么</h2><ol>
<li><p><code>A *a</code>：a是一个局部变量，类型为指针，故而操作系统在程序栈区开辟4/8字节的空间（0x000m），分配给指针a。</p>
</li>
<li><p><code>new A</code>：通过new动态的在堆区申请类A大小的空间（0x000n）。</p>
</li>
<li><p><code>a = new A</code>：将指针a的内存区域填入栈中类A申请到的地址的地址。即*(0x000m) = 0x000n。</p>
</li>
<li><p><code>a-&gt;i</code>：先找到指针a的地址0x000m，通过a的值0x000n和i在类a中偏移offset，得到a-&gt;i的地址0x000n + offset，进行 <code>*(0x000n + offset) = 10</code> 的赋值操作，即内存0x000n + offset的值是10。</p>
</li>
</ol>
<h2 id="说一说操作系统中的缺页中断"><a href="#说一说操作系统中的缺页中断" class="headerlink" title="说一说操作系统中的缺页中断"></a>说一说操作系统中的缺页中断</h2><p><code>malloc()</code> 和 <code>mmap()</code> 等内存分配函数，在分配时只是建立了进程虚拟地址空间，并没有分配虚拟内存对应的物理内存。当进程访问这些没有建立映射关系的虚拟内存时，处理器自动触发一个缺页异常。</p>
<p>缺页中断：在请求分页系统中，可以通过查询页表中的状态位来确定所要访问的页面是否存在于内存中。每当所要访问的页面不在内存是，会产生一次缺页中断，此时操作系统会根据页表中的外存地址在外存中找到所缺的一页，将其调入内存。</p>
<p>缺页本身是一种中断，与一般的中断一样，需要经过4个处理步骤：</p>
<ol>
<li><p>保护CPU现场；</p>
</li>
<li><p>分析中断原因；</p>
</li>
<li><p>转入缺页中断处理程序进行处理；</p>
</li>
<li><p>恢复CPU现场，继续执行。</p>
</li>
</ol>
<p>但是缺页中断是由于所要访问的页面不存在于内存时，由硬件所产生的一种特殊的中断，因此，与一般的中断存在 <strong>区别</strong>：</p>
<ol>
<li><p>在指令执行期间产生和处理缺页中断信号；</p>
</li>
<li><p>一条指令在执行期间，可能产生多次缺页中断；</p>
</li>
<li><p>缺页中断返回是，执行产生中断的一条指令，而一般的中断返回是，执行下一条指令。</p>
</li>
</ol>
<h2 id="回答一下-fork-和-vfork-的区别"><a href="#回答一下-fork-和-vfork-的区别" class="headerlink" title="回答一下 fork 和 vfork 的区别"></a>回答一下 <code>fork</code> 和 <code>vfork</code> 的区别</h2><h3 id="fork的基础知识"><a href="#fork的基础知识" class="headerlink" title="fork的基础知识"></a>fork的基础知识</h3><p>fork：创建一个和当前进程映像一样的进程可以通过 <code>fork()</code> 系统调用：</p>
<pre><code class="lang-C">#include &lt;sys/types.h&gt;
#include &lt;unistd.h&gt;
pid_t fork(void);
</code></pre>
<p>成功调用 <code>fork()</code> 会创建一个新的进程，它几乎与调用 <code>fork()</code> 的进程一模一样，这两个进程都会继续运行。在子进程中，成功的 <code>fork()</code> 调用会返回0。在父进程中 <code>fork()</code> 返回子进程的pid。如果出现错误，<code>fork()</code> 返回一个负值。</p>
<p>最常见的 <code>fork()</code> 用法是创建一个新的进程，然后使用 <code>exec()</code> 载入二进制映像，替换当前进程的映像。这种情况下，派生（fork）了新的进程，而这个子进程会执行一个新的二进制可执行文件的映像。这种“派生加执行”的方式是很常见的。</p>
<p>在早期的Unix系统中，创建进程比较原始。当调用fork时，内核会把所有的内部数据结构复制一份，复制进程的页表项，然后把父进程的地址空间中的内容逐页的复制到子进程的地址空间中。但从内核角度来说，逐页的复制方式是十分耗时的。现代的Unix系统采取了更多的优化，例如Linux，采用了写时复制的方法，而不是对父进程空间进程整体复制。</p>
<h3 id="vfork的基础知识"><a href="#vfork的基础知识" class="headerlink" title="vfork的基础知识"></a>vfork的基础知识</h3><p>在实现写时复制之前，Unix的设计者们就一直很关注在fork后立刻执行exec所造成的地址空间的浪费。BSD的开发者们在3.0的BSD系统中引入了 <code>vfork( )</code> 系统调用。</p>
<pre><code class="lang-C">#include &lt;sys/types.h&gt;
#include &lt;unistd.h&gt;
pid_t vfork(void);
</code></pre>
<p>除了子进程必须要立刻执行一次对exec的系统调用，或者调用 <code>_exit()</code> 退出，对 <code>vfork()</code> 的成功调用所产生的结果和 <code>fork()</code> 是一样的。 <code>vfork()</code> 会挂起父进程直到子进程终止或者运行了一个新的可执行文件的映像。通过这样的方式，<code>vfork()</code> 避免了地址空间的按页复制。在这个过程中，父进程和子进程共享相同的地址空间和页表项。实际上 <code>vfork()</code> 只完成了一件事：复制内部的内核数据结构。因此，子进程也就不能修改地址空间中的任何内存。</p>
<p><code>vfork()</code> 是一个历史遗留产物，Linux本不应该实现它。需要注意的是，即使增加了写时复制，<code>vfork()</code> 也要比 <code>fork()</code> 快，因为它没有进行页表项的复制。然而，写时复制的出现减少了对于替换 <code>fork()</code> 争论。实际上，直到2.2.0内核，<code>vfork()</code> 只是一个封装过的 <code>fork()</code>。因为对 <code>vfork()</code> 的需求要小于 <code>fork()</code>，所以 <code>vfork()</code> 的这种实现方式是可行的。</p>
<blockquote>
<p>补充知识点：<strong>写时复制</strong></p>
<p>Linux采用了写时复制的方法，以减少fork时对父进程空间进程整体复制带来的开销。</p>
<p>写时复制是一种采取了惰性优化方法来避免复制时的系统开销。它的前提很简单：如果有多个进程要读取它们自己的那部门资源的副本，那么复制是不必要的。每个进程只要保存一个指向这个资源的指针就可以了。只要没有进程要去修改自己的“副本”，就存在着这样的幻觉：每个进程好像独占那个资源。从而就避免了复制带来的负担。如果一个进程要修改自己的那份资源“副本”，那么就会复制那份资源，并把复制的那份提供给进程。不过其中的复制对进程来说是透明的。这个进程就可以修改复制后的资源了，同时其他的进程仍然共享那份没有修改过的资源。所以这就是名称的由来：在写入时进行复制。</p>
<p>写时复制的主要好处在于：如果进程从来就不需要修改资源，则不需要进行复制。惰性算法的好处就在于它们尽量推迟代价高昂的操作，直到必要的时刻才会去执行。</p>
<p>在使用虚拟内存的情况下，写时复制（Copy-On-Write）是以页为基础进行的。所以，只要进程不修改它全部的地址空间，那么就不必复制整个地址空间。在fork( )调用结束后，父进程和子进程都相信它们有一个自己的地址空间，但实际上它们共享父进程的原始页，接下来这些页又可以被其他的父进程或子进程共享。</p>
<p>写时复制在内核中的实现非常简单。与内核页相关的数据结构可以被标记为只读和写时复制。如果有进程试图修改一个页，就会产生一个缺页中断。内核处理缺页中断的方式就是对该页进行一次透明复制。这时会清除页面的COW属性，表示着它不再被共享。</p>
<p>现代的计算机系统结构中都在内存管理单元（MMU）提供了硬件级别的写时复制支持，所以实现是很容易的。</p>
<p>在调用 <code>fork()</code> 时，写时复制是有很大优势的。因为大量的fork之后都会跟着执行exec，那么复制整个父进程地址空间中的内容到子进程的地址空间完全是在浪费时间：如果子进程立刻执行一个新的二进制可执行文件的映像，它先前的地址空间就会被交换出去。写时复制可以对这种情况进行优化。</p>
</blockquote>
<h3 id="fork和vfork的区别"><a href="#fork和vfork的区别" class="headerlink" title="fork和vfork的区别"></a>fork和vfork的区别</h3><ol>
<li><p><code>fork()</code> 的子进程拷贝父进程的数据段和代码段；<code>vfork()</code> 的子进程与父进程共享数据段</p>
</li>
<li><p><code>fork()</code> 的父子进程的执行次序不确定；<code>vfork()</code> 保证子进程先运行，在调用exec或exit之前与父进程数据是共享的，在它调用exec或exit之后父进程才可能被调度运行。</p>
</li>
<li><p><code>vfork()</code> 保证子进程先运行，在它调用exec或exit之后父进程才可能被调度运行。如果在调用这两个函数之前子进程依赖于父进程的进一步动作，则会导致死锁。</p>
</li>
<li><p>当需要改变共享数据段中变量的值，则拷贝父进程。</p>
</li>
</ol>
<h2 id="如何修改文件最大句柄数"><a href="#如何修改文件最大句柄数" class="headerlink" title="如何修改文件最大句柄数"></a>如何修改文件最大句柄数</h2><p>linux默认最大文件句柄数是1024个，在linux服务器文件并发量比较大的情况下，系统会报”too many open files”的错误。故在linux服务器高并发调优时，往往需要预先调优Linux参数，修改Linux最大文件句柄数。</p>
<p>有两种方法：</p>
<ol>
<li><p><code>ulimit -n &lt;可以同时打开的文件数&gt;</code><br>  将当前进程的最大句柄数修改为指定的参数（注：该方法只针对当前进程有效，重新打开一个shell或者重新开启一个进程，参数还是之前的值）</p>
<p>  首先用ulimit -a查询Linux相关的参数，如下所示：</p>
<blockquote>
<p>core file size          (blocks, -c) 0<br>data seg size           (kbytes, -d) unlimited<br>scheduling priority             (-e) 0<br>file size               (blocks, -f) unlimited<br>pending signals                 (-i) 94739<br>max locked memory       (kbytes, -l) 64<br>max memory size         (kbytes, -m) unlimited<br>open files                      (-n) 1024<br>pipe size            (512 bytes, -p) 8<br>POSIX message queues     (bytes, -q) 819200<br>real-time priority              (-r) 0<br>stack size              (kbytes, -s) 8192<br>cpu time               (seconds, -t) unlimited<br>max user processes              (-u) 94739<br>virtual memory          (kbytes, -v) unlimited<br>file locks                      (-x) unlimited</p>
</blockquote>
<p>  其中，open files就是最大文件句柄数，默认是1024个。</p>
<p>  修改Linux最大文件句柄数：<code>ulimit -n 2048</code>，将最大句柄数修改为2048个。</p>
</li>
<li><p>对所有进程都有效的方法，修改Linux系统参数<br>  <code>vi /etc/security/limits.conf</code> 添加</p>
<pre><code class="lang-vim">  soft nofile 65536
  hard nofile 65536
</code></pre>
<p>  将最大句柄数改为65536，修改以后保存，注销当前用户，重新登录，修改后的参数就生效了。</p>
</li>
</ol>
<h2 id="说一说并发-concurrency-和并行-parallelism"><a href="#说一说并发-concurrency-和并行-parallelism" class="headerlink" title="说一说并发(concurrency)和并行(parallelism)"></a>说一说并发(concurrency)和并行(parallelism)</h2><p>并发（concurrency）：指宏观上看起来两个程序在同时运行，比如说在单核CPU上的多任务。但是从微观上看两个程序的指令是交织着运行的，你的指令之间穿插着我的指令，我的指令之间穿插着你的，在单个周期内只运行了一个指令。这种并发并不能提高计算机的性能，只能提高效率。</p>
<p>并行（parallelism）：指严格物理意义上的同时运行，比如多核CPU，两个程序分别运行在两个核上，两者之间互不影响，单个周期内每个程序都运行了自己的指令，也就是运行了两条指令。这样说来并行的确提高了计算机的效率。所以现在的CPU都是往多核方面发展。</p>
<h2 id="MySQL的端口号是多少，如何修改这个端口号"><a href="#MySQL的端口号是多少，如何修改这个端口号" class="headerlink" title="MySQL的端口号是多少，如何修改这个端口号"></a>MySQL的端口号是多少，如何修改这个端口号</h2><h3 id="查看端口号"><a href="#查看端口号" class="headerlink" title="查看端口号"></a>查看端口号</h3><p>使用命令 <code>show global variables like &#39;port&#39;;</code> 查看端口号 ，MySQL的默认端口是3306。（补充：sqlserver默认端口号为：1433；oracle默认端口号为：1521；DB2默认端口号为：5000；PostgreSQL默认端口号为：5432）</p>
<h3 id="修改端口号"><a href="#修改端口号" class="headerlink" title="修改端口号"></a>修改端口号</h3><p>编辑 <code>/etc/my.cnf</code> 文件，早期版本有可能是 <code>my.conf</code> 文件名，增加端口参数，并且设定端口，注意该端口未被使用，保存退出。</p>
<h2 id="说一说操作系统中的页表寻址"><a href="#说一说操作系统中的页表寻址" class="headerlink" title="说一说操作系统中的页表寻址"></a>说一说操作系统中的页表寻址</h2><p>页式内存管理，内存分成固定长度的一个个页片。操作系统为每一个进程维护了一个从虚拟地址到物理地址的映射关系的数据结构，叫页表，页表的内容就是该进程的虚拟地址到物理地址的一个映射。页表中的每一项都记录了这个页的基地址。通过页表，由逻辑地址的高位部分先找到逻辑地址对应的页基地址，再由页基地址偏移一定长度就得到最后的物理地址，偏移的长度由逻辑地址的低位部分决定。一般情况下，这个过程都可以由硬件完成，所以效率还是比较高的。<strong>页式内存管理的优点就是比较灵活，内存管理以较小的页为单位，方便内存换入换出和扩充地址空间。</strong></p>
<h3 id="Linux最初的两级页表机制"><a href="#Linux最初的两级页表机制" class="headerlink" title="Linux最初的两级页表机制"></a>Linux最初的两级页表机制</h3><p>两级分页机制将32位的虚拟空间分成三段，低12位表示页内偏移，高20位分成两段分别表示两级页表的偏移。</p>
<ul>
<li><p>PGD(Page Global Directory)：最高10位，全局页目录表索引</p>
</li>
<li><p>PTE(Page Table Entry)：中间10位，页表入口索引</p>
</li>
</ul>
<p>当在进行地址转换时，结合在CR3寄存器中存放的页目录(page directory，PGD)的这一页的物理地址，再加上从虚拟地址中抽出高10位叫做页目录表项(内核也称这为PGD)的部分作为偏移，即定位到可以描述该地址的PGD；从该PGD中可以获取可以描述该地址的页表的物理地址，再加上从虚拟地址中抽取中间10位作为偏移，即定位到可以描述该地址的PTE；在这个PTE中即可获取该地址对应的页的物理地址，加上从虚拟地址中抽取的最后12位，即形成该页的页内偏移，即可最终完成从虚拟地址到物理地址的转换。从上述过程中，可以看出，对虚拟地址的分级解析过程，实际上就是不断深入页表层次，逐渐定位到最终地址的过程，所以这一过程被叫做page table walk。</p>
<h3 id="Linux的三级页表机制"><a href="#Linux的三级页表机制" class="headerlink" title="Linux的三级页表机制"></a>Linux的三级页表机制</h3><p>当x86引入物理地址扩展(Pisycal Addrress Extension，PAE)后，可以支持大于4G的物理内存(32位），但虚拟地址依然是32位，原先的页表项不适用，它实际多4bytes被扩充到8bytes，这意味着，每一页现在能存放的PTE数目从1024变成512了(4k/8)。相应地，页表层级发生了变化，Linux新增加了一个层级，叫做页中间目录(page middle directory，PMD)，变成：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">字段</th>
<th style="text-align:center">描述</th>
<th style="text-align:center">位数</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">cr3</td>
<td style="text-align:center">指向一个PDPT</td>
<td style="text-align:center">crs寄存器存储</td>
</tr>
<tr>
<td style="text-align:center">PGD</td>
<td style="text-align:center">指向PDPT中4个项中的一个</td>
<td style="text-align:center">位31~30</td>
</tr>
<tr>
<td style="text-align:center">PMD</td>
<td style="text-align:center">指向页目录中512项中的一个</td>
<td style="text-align:center">位29~21</td>
</tr>
<tr>
<td style="text-align:center">PTE</td>
<td style="text-align:center">指向页表中512项中的一个</td>
<td style="text-align:center">位20~12</td>
</tr>
<tr>
<td style="text-align:center">page offset</td>
<td style="text-align:center">4KB页中的偏移</td>
<td style="text-align:center">位11~0</td>
</tr>
</tbody>
</table>
</div>
<p>现在就同时存在2级页表和3级页表，在代码管理上肯定不方便。巧妙的是，Linux采取了一种抽象方法：所有架构全部使用3级页表：即PGD -&gt; PMD -&gt; PTE。那只使用2级页表(如非PAE的x86)怎么办？</p>
<p>办法是针对使用2级页表的架构，把PMD抽象掉，即虚设一个PMD表项。这样在page table walk过程中，PGD本直接指向PTE的，现在不了，指向一个虚拟的PMD，然后再由PMD指向PTE。这种抽象保持了代码结构的统一。</p>
<h3 id="Linux的四级页表机制"><a href="#Linux的四级页表机制" class="headerlink" title="Linux的四级页表机制"></a>Linux的四级页表机制</h3><p>硬件在发展，3级页表很快又捉襟见肘了，原因是64位CPU出现了，比如x86_64，它的硬件是实实在在支持4级页表的。它支持48位的虚拟地址空间。如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">字段</th>
<th style="text-align:center">描述</th>
<th style="text-align:center">位数</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">PML4</td>
<td style="text-align:center">指向一个PDPT</td>
<td style="text-align:center">位47~39</td>
</tr>
<tr>
<td style="text-align:center">PGD</td>
<td style="text-align:center">指向PDPT中4个项中的一个</td>
<td style="text-align:center">位38~30</td>
</tr>
<tr>
<td style="text-align:center">PMD</td>
<td style="text-align:center">指向页目录中512项中的一个</td>
<td style="text-align:center">位29~21</td>
</tr>
<tr>
<td style="text-align:center">PTE</td>
<td style="text-align:center">指向页表中512项中的一个</td>
<td style="text-align:center">位20~12</td>
</tr>
<tr>
<td style="text-align:center">page offset</td>
<td style="text-align:center">4KB页中的偏移</td>
<td style="text-align:center">位11~0</td>
</tr>
</tbody>
</table>
</div>
<p>Linux内核针为使用原来的3级列表(PGD-&gt;PMD-&gt;PTE)，做了折衷。即采用一个唯一的，共享的顶级层次，叫PML4。这个PML4没有编码在地址中，这样就能套用原来的3级列表方案了。不过代价就是，由于只有唯一的PML4，寻址空间被局限在 $(2^{39}=)$ 512G，而本来PML4段有9位，可以支持512个PML4表项的。现在为了使用3级列表方案，只能限制使用一个，512G的空间很快就又不够用了，解决方案呼之欲出。</p>
<p>在2004年10月，当时的X86_64架构代码的维护者Andi Kleen提交了一个叫做4 level page tables for Linux的PATCH系列，为Linux内核带来了4级页表的支持。在他的解决方案中，不出意料地，按照x86_64规范，新增了一个PML4的层级，在这种解决方案中，x86_64拥一个有512条目的PML4，512条目的PGD，512条目的PMD，512条目的PTE。对于仍使用3级目录的架构来说，它们依然拥有一个虚拟的PML4，相关的代码会在编译时被优化掉。 这样，就把Linux内核的3级列表扩充为4级列表。这系列PATCH工作得不错，不久被纳入Andrew Morton的-mm树接受测试。不出意外的话，它将在v2.6.11版本中释出。但是，另一个知名开发者Nick Piggin提出了一些看法，他认为Andi的Patch很不错，不过他认为最好还是把PGD作为第一级目录，把新增加的层次放在中间，并给出了他自己的Patch：alternate 4-level page tables patches。Andi更想保持自己的PATCH，他认为Nick不过是玩了改名的游戏，而且他的PATCH经过测试很稳定，快被合并到主线了，不宜再折腾。不过Linus却表达了对Nick Piggin的支持，理由是Nick的做法conceptually least intrusive。毕竟作为Linux的扛把子，稳定对于Linus来说意义重大。最终，不意外地，最后Nick Piggin的PATCH在v2.6.11版本中被合并入主线。在这种方案中，4级页表分别是：PGD -&gt; PUD -&gt; PMD -&gt; PTE。</p>
<h2 id="说一说有了进程，为什么还要有线程"><a href="#说一说有了进程，为什么还要有线程" class="headerlink" title="说一说有了进程，为什么还要有线程"></a>说一说有了进程，为什么还要有线程</h2><p>线程产生的原因：</p>
<p>进程可以使多个程序能并发执行，以提高资源的利用率和系统的吞吐量；但是其具有一些缺点：</p>
<p>进程在同一时间只能干一件事</p>
<p>进程在执行的过程中如果阻塞，整个进程就会挂起，即使进程中有些工作不依赖于等待的资源，仍然不会执行。</p>
<p>因此，操作系统引入了比进程粒度更小的线程，<strong>作为并发执行的基本单位</strong>，从而减少程序在并发执行时所付出的时空开销，提高并发性。和进程相比，线程的优势如下：</p>
<ul>
<li><p>从 <strong>资源</strong> 上来讲，线程是一种非常”节俭”的多任务操作方式。在Linux系统下，启动一个新的进程必须分配给它独立的地址空间，建立众多的数据表来维护它的代码段、堆栈段和数据段，这是一种”昂贵”的多任务工作方式。</p>
</li>
<li><p>从 <strong>切换效率</strong> 上来讲，运行于一个进程中的多个线程，它们之间使用相同的地址空间，而且线程间彼此切换所需时间也远远小于进程间切换所需要的时间。据统计，一个进程的开销大约是一个线程开销的30倍左右。</p>
</li>
<li><p>从 <strong>通信机制</strong> 上来讲，线程间方便的通信机制。对不同进程来说，它们具有独立的数据空间，要进行数据的传递只能通过进程间通信的方式进行，这种方式不仅费时，而且很不方便。线程则不然，由于同一进城下的线程之间贡献数据空间，所以一个线程的数据可以直接为其他线程所用，这不仅快捷，而且方便。</p>
</li>
</ul>
<p>除以上优点外，多线程程序作为一种多任务、并发的工作方式，还有如下优点：</p>
<ol>
<li><p>使多CPU系统更加有效。操作系统会保证当线程数不大于CPU数目时，不同的线程运行于不同的CPU上。</p>
</li>
<li><p>改善程序结构。一个既长又复杂的进程可以考虑分为多个线程，成为几个独立或半独立的运行部分，这样的程序才会利于理解和修改。</p>
</li>
</ol>
<h2 id="单核机器上写多线程程序，是否需要考虑加锁，为什么"><a href="#单核机器上写多线程程序，是否需要考虑加锁，为什么" class="headerlink" title="单核机器上写多线程程序，是否需要考虑加锁，为什么"></a>单核机器上写多线程程序，是否需要考虑加锁，为什么</h2><p>在单核机器上写多线程程序，仍然需要线程锁。</p>
<p>因为线程锁通常用来实现线程的同步和通信。在单核机器上的多线程程序，仍然存在线程同步的问题。因为在抢占式操作系统中，通常为每个线程分配一个时间片，当某个线程时间片耗尽时，操作系统会将其挂起，然后运行另一个线程。如果这两个线程共享某些数据，<strong>不使用线程锁的前提下，可能会导致共享数据修改引起冲突。</strong></p>
<h2 id="线程需要保存哪些上下文，SP、PC、EAX这些寄存器是干嘛用的"><a href="#线程需要保存哪些上下文，SP、PC、EAX这些寄存器是干嘛用的" class="headerlink" title="线程需要保存哪些上下文，SP、PC、EAX这些寄存器是干嘛用的"></a>线程需要保存哪些上下文，SP、PC、EAX这些寄存器是干嘛用的</h2><p>线程在切换的过程中需要保存当前线程Id、线程状态、堆栈、寄存器状态等信息。其中寄存器主要包括SP、PC、EAX等寄存器，其主要功能如下：</p>
<ul>
<li>SP:堆栈指针，指向当前栈的栈顶地址</li>
<li>PC:程序计数器，存储下一条将要执行的指令</li>
<li>EAX:累加寄存器，用于加法乘法的缺省寄存器</li>
</ul>
<h2 id="线程间的同步方式，最好说出具体的系统调用"><a href="#线程间的同步方式，最好说出具体的系统调用" class="headerlink" title="线程间的同步方式，最好说出具体的系统调用"></a>线程间的同步方式，最好说出具体的系统调用</h2><ul>
<li><p><strong>信号量</strong></p>
<p>   信号量是一种特殊的变量，可用于线程同步。它只取自然数值，并且只支持两种操作：</p>
<p>   <strong>P(SV)：</strong> 如果信号量SV大于0，将它减一；如果SV值为0，则挂起该线程。<br>   <strong>V(SV)：</strong> 如果有其他进程因为等待SV而挂起，则唤醒，然后将SV+1；否则直接将SV+1。</p>
<p>   其系统调用为：</p>
<p>   <code>sem_wait(sem_t *sem)</code>：以原子操作的方式将信号量减1，如果信号量值为0，则sem_wait将被阻塞，直到这个信号量具有非0值。<br>   <code>sem_post(sem_t *sem)</code>：以原子操作将信号量值+1。当信号量大于0时，其他正在调用sem_wait等待信号量的线程将被唤醒。</p>
</li>
<li><p><strong>互斥量</strong></p>
<p>   互斥量又称互斥锁，主要用于线程互斥，不能保证按序访问，可以和条件锁一起实现同步。当进入临界区时，需要获得互斥锁并且加锁；当离开临界区时，需要对互斥锁解锁，以唤醒其他等待该互斥锁的线程。其主要的系统调用如下：</p>
<p>   <code>pthread_mutex_init</code>：初始化互斥锁<br>   <code>pthread_mutex_destroy</code>：销毁互斥锁<br>   <code>pthread_mutex_lock</code>：以原子操作的方式给一个互斥锁加锁，如果目标互斥锁已经被上锁，pthread_mutex_lock调用将阻塞，直到该互斥锁的占有者将其解锁。<br>   <code>pthread_mutex_unlock</code>：以一个原子操作的方式给一个互斥锁解锁。</p>
</li>
<li><p><strong>条件变量</strong></p>
<p>   条件变量，又称条件锁，用于在线程之间同步共享数据的值。条件变量提供一种线程间通信机制：当某个共享数据达到某个值时，唤醒等待这个共享数据的一个/多个线程。即，当某个共享变量等于某个值时，调用 signal/broadcast。此时操作共享变量时需要加锁。其主要的系统调用如下：</p>
<p>   <code>pthread_cond_init</code>：初始化条件变量<br>   <code>pthread_cond_destroy</code>：销毁条件变量<br>   <code>pthread_cond_signal</code>：唤醒一个等待目标条件变量的线程。哪个线程被唤醒取决于调度策略和优先级。<br>   <code>pthread_cond_wait</code>：等待目标条件变量。需要一个加锁的互斥锁确保操作的原子性。该函数中在进入wait状态前首先进行解锁，然后接收到信号后会再加锁，保证该线程对共享资源正确访问。</p>
</li>
</ul>
<h2 id="说一下多线程和多进程的不同"><a href="#说一下多线程和多进程的不同" class="headerlink" title="说一下多线程和多进程的不同"></a>说一下多线程和多进程的不同</h2><p><strong>进程是资源分配的最小单位，而线程时CPU调度的最小单位。</strong></p>
<p>多线程之间共享同一个进程的地址空间，<strong>线程间通信简单，同步复杂</strong>，线程创建、销毁和切换简单，速度快，占用内存少，适用于多核分布式系统，但是线程间会相互影响，一个线程意外终止会导致同一个进程的其他线程也终止，程序可靠性弱。</p>
<p>而多进程间拥有各自独立的运行地址空间，进程间不会相互影响，程序可靠性强，但是进程创建、销毁和切换复杂，速度慢，占用内存多，<strong>进程间通信复杂，但是同步简单</strong>，适用于多核、多机分布。</p>
<h2 id="游戏服务器应该为每个用户开辟一个线程还是一个进程，为什么"><a href="#游戏服务器应该为每个用户开辟一个线程还是一个进程，为什么" class="headerlink" title="游戏服务器应该为每个用户开辟一个线程还是一个进程，为什么"></a>游戏服务器应该为每个用户开辟一个线程还是一个进程，为什么</h2><p>游戏服务器应该为每个用户开辟一个进程。</p>
<p>因为同一进程间的线程会相互影响，一个线程死掉会影响其他线程，从而导致进程崩溃。因此为了保证不同用户之间不会相互影响，应该为每个用户开辟一个进程。</p>
<h2 id="说一说OS缺页置换算法"><a href="#说一说OS缺页置换算法" class="headerlink" title="说一说OS缺页置换算法"></a>说一说OS缺页置换算法</h2><p>当访问一个内存中不存在的页，并且内存已满，则需要从内存中调出一个页或将数据送至磁盘对换区，替换一个页，这种现象叫做缺页置换。</p>
<p>当前操作系统最常采用的缺页置换算法如下：</p>
<h3 id="先进先出（FIFO）算法"><a href="#先进先出（FIFO）算法" class="headerlink" title="先进先出（FIFO）算法"></a>先进先出（FIFO）算法</h3><p>置换最先调入内存的页面，即置换在内存中驻留时间最久的页面。按照进入内存的先后次序排列成队列，从队尾进入，从队首删除。</p>
<ul>
<li><p>思想：最近刚访问的，将来访问的可能性比较大。</p>
</li>
<li><p>实现：使用一个队列，新加入的页面放入队尾，每次淘汰队首的页面，即最先进入的数据，最先被淘汰。</p>
</li>
<li><p>弊端：无法体现页面冷热信息。</p>
</li>
</ul>
<h3 id="最不经常访问淘汰（LFU）算法"><a href="#最不经常访问淘汰（LFU）算法" class="headerlink" title="最不经常访问淘汰（LFU）算法"></a>最不经常访问淘汰（LFU）算法</h3><ul>
<li><p>思想：如果数据过去被访问多次，那么将来被访问的频率也更高。</p>
</li>
<li><p>实现：每个数据块一个引用计数，所有数据块按照引用计数排序，具有相同引用计数的数据块则按照时间排序。每次淘汰队尾数据块。</p>
</li>
<li><p>开销：排序开销。</p>
</li>
<li><p>弊端：缓存颠簸。</p>
</li>
</ul>
<h3 id="最近最少使用（LRU）算法"><a href="#最近最少使用（LRU）算法" class="headerlink" title="最近最少使用（LRU）算法"></a>最近最少使用（LRU）算法</h3><p>置换最近一段时间以来最长时间未访问过的页面。根据程序局部性原理，刚被访问的页面，可能马上又要被访问；而较长时间内没有被访问的页面，可能最近不会被访问。</p>
<ul>
<li><p>思想：如果数据最近被访问过，那么将来被访问的几率也更高。</p>
</li>
<li><p>实现：使用一个栈，新页面或者命中的页面则将该页面移动到栈底，每次替换栈顶的缓存页面。</p>
</li>
<li><p>优点：LRU算法对热点数据命中率是很高的。</p>
</li>
<li><p>缺陷：</p>
<ul>
<li><p>缓存颠簸，当缓存（1，2，3）满了，之后数据访问（0，3，2，1，0，3，2，1。。。）。</p>
</li>
<li><p>缓存污染，突然大量偶发性的数据访问，会让内存中存放大量冷数据。</p>
</li>
</ul>
</li>
</ul>
<h2 id="说一下多进程和多线程的使用场景"><a href="#说一下多进程和多线程的使用场景" class="headerlink" title="说一下多进程和多线程的使用场景"></a>说一下多进程和多线程的使用场景</h2><ul>
<li><p>多进程模型的优势是CPU，适用于CPU密集型。同时，多进程模型也适用于多机分布式场景中，易于多机扩展。</p>
</li>
<li><p>多线程模型主要优势为线程间切换代价较小，因此适用于I/O密集型的工作场景，因此I/O密集型的工作场景经常会由于I/O阻塞导致频繁的切换线程。同时，多线程模型也适用于单机多核分布式场景。</p>
</li>
</ul>
<h2 id="说一说死锁发生的条件以及如何解决死锁"><a href="#说一说死锁发生的条件以及如何解决死锁" class="headerlink" title="说一说死锁发生的条件以及如何解决死锁"></a>说一说死锁发生的条件以及如何解决死锁</h2><p>死锁是指两个或两个以上进程在执行过程中，因争夺资源而造成的下相互等待的现象。</p>
<h3 id="死锁发生的四个必要条件"><a href="#死锁发生的四个必要条件" class="headerlink" title="死锁发生的四个必要条件"></a>死锁发生的四个必要条件</h3><h4 id="互斥条件"><a href="#互斥条件" class="headerlink" title="互斥条件"></a>互斥条件</h4><p>一个资源一段时间内只能由一个进程占用。</p>
<h4 id="请求和保持（占用并等待）条件"><a href="#请求和保持（占用并等待）条件" class="headerlink" title="请求和保持（占用并等待）条件"></a>请求和保持（占用并等待）条件</h4><p>进程获得一定的资源后，又对其他资源发出请求，但是该资源可能被其他进程占有，此时请求阻塞，但该进程不会释放自己已经占有的资源。</p>
<h4 id="不可剥夺条件"><a href="#不可剥夺条件" class="headerlink" title="不可剥夺条件"></a>不可剥夺条件</h4><p>进程已获得的资源，在未完成使用之前，不可被剥夺，只能在使用后自己释放。</p>
<h4 id="环路等待条件"><a href="#环路等待条件" class="headerlink" title="环路等待条件"></a>环路等待条件</h4><p>进程发生死锁后，必然存在一个进程-资源之间的环形链。</p>
<h3 id="解决死锁的方法即破坏上述四个条件之一"><a href="#解决死锁的方法即破坏上述四个条件之一" class="headerlink" title="解决死锁的方法即破坏上述四个条件之一"></a>解决死锁的方法即破坏上述四个条件之一</h3><p>主要方法如下：</p>
<ul>
<li><p>资源一次性分配，从而剥夺请求和保持条件；</p>
</li>
<li><p>可剥夺资源：即当进程新的资源未得到满足时，释放已占有的资源，从而破坏不可剥夺的条件；</p>
</li>
<li><p>有序资源分配法：系统给每类资源赋予一个序号，每个进程按编号递增的请求资源，释放则相反，从而破坏环路等待的条件。</p>
</li>
</ul>
<blockquote>
<ul>
<li>死锁检测<ul>
<li>银行家算法：如果系统现存的各种资源可以满足申请者的最大需求量，就满足。</li>
</ul>
</li>
<li>死锁排除<ol>
<li>资源剥夺</li>
<li>撤销进程</li>
<li>进程回退</li>
</ol>
</li>
</ul>
</blockquote>
<h2 id="虚拟内存和物理内存怎么对应"><a href="#虚拟内存和物理内存怎么对应" class="headerlink" title="虚拟内存和物理内存怎么对应"></a>虚拟内存和物理内存怎么对应</h2><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><h4 id="物理地址（physical-address）"><a href="#物理地址（physical-address）" class="headerlink" title="物理地址（physical address）"></a>物理地址（physical address）</h4><p>用于内存芯片级的单元寻址，与处理器和CPU连接的地址总线相对应。</p>
<p>虽然可以直接把物理地址理解成插在机器上那根内存本身，把内存看成一个从0字节一直到最大空量逐字节的编号的大数组，然后把这个数组叫做物理地址，但是事实上，这只是一个硬件提供给软件的抽象，内存的寻址方式并不是这样。所以，说它是“与地址总线相对应”，是更贴切一些，不过抛开对物理内存寻址方式的考虑，直接把物理地址与物理的内存一一对应，也是可以接受的。也许错误的理解更利于形而上的抽象。</p>
<h4 id="虚拟地址-virtual-memory"><a href="#虚拟地址-virtual-memory" class="headerlink" title="虚拟地址(virtual memory)"></a>虚拟地址(virtual memory)</h4><p>这是对整个内存（不要与机器上插那条对上号）的抽象描述。它是相对于物理内存来讲的，可以直接理解成“不直实的”，“假的”内存，例如，一个0x08000000内存地址，它并不对就物理地址上那个大数组中0x08000000 - 1那个地址元素；</p>
<p>之所以是这样，是因为现代操作系统都提供了一种内存管理的抽象，即虚拟内存（virtual memory）。进程使用虚拟内存中的地址，由操作系统协助相关硬件，把它“转换”成真正的物理地址。这个“转换”，是所有问题讨论的关键。</p>
<p>有了这样的抽象，一个程序，就可以使用比真实物理地址大得多的地址空间。甚至多个进程可以使用相同的地址。不奇怪，因为转换后的物理地址并非相同的。</p>
<blockquote>
<p>可以把连接后的程序反编译看一下，发现连接器已经为程序分配了一个地址，例如，要调用某个函数A，代码不是call A，而是call 0x0811111111 ，也就是说，函数A的地址已经被定下来了。没有这样的“转换”，没有虚拟地址的概念，这样做是根本行不通的。</p>
</blockquote>
<h3 id="地址转换"><a href="#地址转换" class="headerlink" title="地址转换"></a>地址转换</h3><h4 id="第一步：CPU段式管理中——逻辑地址转线性地址"><a href="#第一步：CPU段式管理中——逻辑地址转线性地址" class="headerlink" title="第一步：CPU段式管理中——逻辑地址转线性地址"></a>第一步：CPU段式管理中——逻辑地址转线性地址</h4><p>CPU要利用其段式内存管理单元，先将一个逻辑地址转换成一个线程地址。</p>
<p>一个逻辑地址由两部分组成，<strong>[段标识符:段内偏移量]</strong>。</p>
<p>段标识符是由一个16位长的字段组成，称为段选择符。其中前13位是一个索引号。后面3位包含一些硬件细节，如图：</p>
<p><img src="/2020/03/21/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%95%B4%E7%90%86/段选择符.png" srcset="/img/loading.gif" alt="段选择符"></p>
<p>通过段标识符中的索引号从GDT或者LDT找到该段的段描述符，段描述符中的base字段是段的起始地址</p>
<p>段描述符：Base字段，它描述了一个段的开始位置的线性地址。</p>
<p>一些全局的段描述符，就放在全局段描述符表(GDT)中，一些局部的，例如每个进程自己的，就放在所谓的局部段描述符表(LDT)中。</p>
<p>GDT在内存中的地址和大小存放在CPU的GDTR控制寄存器中，而LDT则在LDTR寄存器中。</p>
<p>段起始地址 + 段内偏移量 = 线性地址</p>
<p><img src="/2020/03/21/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%95%B4%E7%90%86/数据段、代码段、系统段描述符.png" srcset="/img/loading.gif" alt="操作系统整理/数据段、代码段、系统段描述符"></p>
<p>首先，给定一个完整的逻辑地址 <strong>[段选择符:段内偏移地址]</strong>，</p>
<ol>
<li><p>看段选择符的T1 = 0还是1，知道当前要转换是GDT中的段，还是LDT中的段，再根据相应寄存器，得到其地址和大小。我们就有了一个数组了。</p>
</li>
<li><p>拿出段选择符中前13位，可以在这个数组中，查找到对应的段描述符，这样，它了Base，即基地址就知道了。</p>
</li>
<li><p>把Base + offset，就是要转换的线性地址了。</p>
</li>
</ol>
<p><img src="/2020/03/21/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%95%B4%E7%90%86/地址转换过程.png" srcset="/img/loading.gif" alt="地址转换过程"></p>
<h4 id="第二步：页式管理——线性地址转物理地址"><a href="#第二步：页式管理——线性地址转物理地址" class="headerlink" title="第二步：页式管理——线性地址转物理地址"></a>第二步：页式管理——线性地址转物理地址</h4><p>再利用其页式内存管理单元，转换为最终物理地址。</p>
<h5 id="linux假的段式管理"><a href="#linux假的段式管理" class="headerlink" title="linux假的段式管理"></a>linux假的段式管理</h5><p>Intel要求两次转换，这样虽说是兼容了，但是却是很冗余，但是这是Intel硬件的要求。</p>
<p>其它某些硬件平台，没有二次转换的概念，Linux也需要提供一个高层抽象，来提供一个统一的界面。</p>
<p>所以，Linux的段式管理，事实上只是“哄骗”了一下硬件而已。</p>
<p>按照Intel的本意，全局的用GDT，每个进程自己的用LDT——不过Linux则对所有的进程都使用了相同的段来对指令和数据寻址。即用户数据段，用户代码段，对应的，内核中的是内核数据段和内核代码段。</p>
<p>在Linux下，逻辑地址与线性地址总是一致的，即逻辑地址的偏移量字段的值与线性地址的值总是相同的。</p>
<h5 id="linux页式管理"><a href="#linux页式管理" class="headerlink" title="linux页式管理"></a>linux页式管理</h5><p>CPU的页式内存管理单元，负责把一个线性地址，最终翻译为一个物理地址。</p>
<p>线性地址被分为以固定长度为单位的组，称为页（page），例如一个32位的机器，线性地址最大可为4G，可以用4KB为一个页来划分，这页，整个线性地址就被划分为一个total_page[$2^{20}$]的大数组，共有2的20个次方个页。</p>
<p>另一类“页”，我们称之为物理页，或者是页框、页桢的。是分页单元把所有的物理内存也划分为固定长度的管理单位，它的长度一般与内存页是一一对应的。</p>
<p><img src="/2020/03/21/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%95%B4%E7%90%86/二级页表.png" srcset="/img/loading.gif" alt="二级页表"></p>
<p>每个进程都有自己的页目录，当进程处于运行态的时候，其页目录地址存放在cr3寄存器中。</p>
<p>每一个32位的线性地址被划分为三部份：<strong>[页目录索引(10位):页表索引(10位):页内偏移(12位)]</strong></p>
<p>依据以下步骤进行转换：</p>
<p>从cr3中取出进程的页目录地址（操作系统负责在调度进程的时候，把这个地址装入对应寄存器）；</p>
<p>根据线性地址前十位，在数组中，找到对应的索引项，因为引入了二级管理模式，页目录中的项，不再是页的地址，而是一个页表的地址。（又引入了一个数组），页的地址被放到页表中去了。</p>
<p>根据线性地址的中间十位，在页表（也是数组）中找到页的起始地址；</p>
<p>将页的起始地址与线性地址中最后12位相加。</p>
<h6 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h6><p>内存节约：如果一级页表中的一个页表条目为空，那么那所指的二级页表就根本不会存在。这表现出一种巨大的潜在节约，因为对于一个典型的程序，4GB虚拟地址空间的大部份都会是未分配的；</p>
<p><img src="/2020/03/21/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%95%B4%E7%90%86/四级页表.png" srcset="/img/loading.gif" alt="四级页表"></p>
<p>32位，PGD = 10bit，PUD = PMD = 0，table = 10bit，offset = 12bit</p>
<p>64位，PUD和PMD ≠ 0</p>
<h2 id="说一说操作系统中的结构体对齐，字节对齐"><a href="#说一说操作系统中的结构体对齐，字节对齐" class="headerlink" title="说一说操作系统中的结构体对齐，字节对齐"></a>说一说操作系统中的结构体对齐，字节对齐</h2><h3 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h3><ol>
<li><p>平台原因（移植原因）：不是所有的硬件平台都能访问任意地址上的任意数据的；某些硬件平台只能在某些地址处取某些特定类型的数据，否则抛出硬件异常。</p>
</li>
<li><p>性能原因：数据结构（尤其是栈）应该尽可能地在自然边界上对齐。原因在于，为了访问未对齐的内存，处理器需要作两次内存访问；而对齐的内存访问仅需要一次访问。</p>
</li>
</ol>
<h3 id="规则"><a href="#规则" class="headerlink" title="规则"></a>规则</h3><ol>
<li><p>数据成员对齐规则：结构（struct）（或联合（union））的数据成员，第一个数据成员放在offset为0的地方，以后每个数据成员的对齐按照 <code>#pragma pack</code> 指定的数值和这个数据成员自身长度中，比较小的那个进行。</p>
</li>
<li><p>结构（或联合）的整体对齐规则：在数据成员完成各自对齐之后，结构（或联合）本身也要进行对齐，对齐将按照 <code>#pragma pack</code> 指定的数值和结构（或联合）最大数据成员长度中，比较小的那个进行。</p>
</li>
<li><p>结构体作为成员：如果一个结构里有某些结构体成员，则结构体成员要从其内部最大元素大小的整数倍地址开始存储。</p>
</li>
</ol>
<h3 id="定义结构体对齐"><a href="#定义结构体对齐" class="headerlink" title="定义结构体对齐"></a>定义结构体对齐</h3><p>可以通过预编译命令 <code>#pragma pack(n), n = 1, 2, 4, 8, 16</code> 来改变这一系数，其中的n就是指定的“对齐系数”。</p>
<h3 id="举例"><a href="#举例" class="headerlink" title="举例"></a>举例</h3><pre><code class="lang-C++">#pragma pack(2)
struct AA
{
    int a;   //长度4 &gt; 2 按2对齐；偏移量为0；存放位置区间[0,3]
    char b;  //长度1 &lt; 2 按1对齐；偏移量为4；存放位置区间[4]
    short c; //长度2 = 2 按2对齐；偏移量要提升到2的倍数6；存放位置区间[6,7]
    char d;  //长度1 &lt; 2 按1对齐；偏移量为8；存放位置区间[8]；共九个字节
};
#pragma pack()
</code></pre>
<h2 id="互斥锁（mutex）机制，以及互斥锁和读写锁的区别"><a href="#互斥锁（mutex）机制，以及互斥锁和读写锁的区别" class="headerlink" title="互斥锁（mutex）机制，以及互斥锁和读写锁的区别"></a>互斥锁（mutex）机制，以及互斥锁和读写锁的区别</h2><h3 id="概念-1"><a href="#概念-1" class="headerlink" title="概念"></a>概念</h3><h4 id="互斥锁mutex"><a href="#互斥锁mutex" class="headerlink" title="互斥锁mutex"></a>互斥锁mutex</h4><p>用于保证在任何时刻，都只能有一个线程访问该对象。当获取锁操作失败时，线程会进入睡眠，等待锁释放时被唤醒。</p>
<h4 id="读写锁rwlock"><a href="#读写锁rwlock" class="headerlink" title="读写锁rwlock"></a>读写锁rwlock</h4><p>分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作。但是同一时刻只能有一个线程可以获得写锁。其它获取写锁失败的线程都会进入睡眠状态，直到写锁释放时被唤醒。 注意：写锁会阻塞其它读写锁。当有一个线程获得写锁在写时，读锁也不能被其它线程获取；写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）。适用于读取数据的频率远远大于写数据的频率的场合。</p>
<h3 id="互斥锁和读写锁的区别"><a href="#互斥锁和读写锁的区别" class="headerlink" title="互斥锁和读写锁的区别"></a>互斥锁和读写锁的区别</h3><ul>
<li><p>读写锁区分读者和写者，而互斥锁不区分；</p>
</li>
<li><p>互斥锁同一时间只允许一个线程访问该对象，无论读写；读写锁同一时间内只允许一个写者，但是允许多个读者同时读对象。</p>
</li>
</ul>
<h3 id="Linux的4种锁机制"><a href="#Linux的4种锁机制" class="headerlink" title="Linux的4种锁机制"></a>Linux的4种锁机制</h3><h4 id="互斥锁mutex-1"><a href="#互斥锁mutex-1" class="headerlink" title="互斥锁mutex"></a>互斥锁mutex</h4><p>用于保证在任何时刻，都只能有一个线程访问该对象。当获取锁操作失败时，线程会进入睡眠，等待锁释放时被唤醒。</p>
<h4 id="读写锁rwlock-1"><a href="#读写锁rwlock-1" class="headerlink" title="读写锁rwlock"></a>读写锁rwlock</h4><p>分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作。但是同一时刻只能有一个线程可以获得写锁。其它获取写锁失败的线程都会进入睡眠状态，直到写锁释放时被唤醒。 注意：写锁会阻塞其它读写锁。当有一个线程获得写锁在写时，读锁也不能被其它线程获取；写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）。适用于读取数据的频率远远大于写数据的频率的场合。</p>
<h4 id="自旋锁spinlock"><a href="#自旋锁spinlock" class="headerlink" title="自旋锁spinlock"></a>自旋锁spinlock</h4><p>在任何时刻同样只能有一个线程访问对象。但是当获取锁操作失败时，不会进入睡眠，而是会在原地自旋，直到锁被释放。这样节省了线程从睡眠状态到被唤醒期间的消耗，在加锁时间短暂的环境下会极大的提高效率。但如果加锁时间过长，则会非常浪费CPU资源。</p>
<h4 id="RCU（read-copy-update）"><a href="#RCU（read-copy-update）" class="headerlink" title="RCU（read-copy-update）"></a>RCU（read-copy-update）</h4><p>在修改数据时，首先需要读取数据，然后生成一个副本，对副本进行修改。修改完成后，再将老数据update成新的数据。使用RCU时，读者几乎不需要同步开销，既不需要获得锁，也不使用原子指令，不会导致锁竞争，因此就不用考虑死锁问题了。而对于写者的同步开销较大，它需要复制被修改的数据，还必须使用锁机制同步并行其它写者的修改操作。在有大量读操作，少量写操作的情况下效率非常高。</p>
<h2 id="说一说进程状态转换图，动态就绪，静态就绪，动态阻塞，静态阻塞"><a href="#说一说进程状态转换图，动态就绪，静态就绪，动态阻塞，静态阻塞" class="headerlink" title="说一说进程状态转换图，动态就绪，静态就绪，动态阻塞，静态阻塞"></a>说一说进程状态转换图，动态就绪，静态就绪，动态阻塞，静态阻塞</h2><h3 id="进程的5种基本状态"><a href="#进程的5种基本状态" class="headerlink" title="进程的5种基本状态"></a>进程的5种基本状态</h3><p><img src="/2020/03/21/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%95%B4%E7%90%86/进程状态转换图.png" srcset="/img/loading.gif" alt="进程状态转换图"></p>
<ol>
<li><p>创建状态：进程正在被创建；</p>
</li>
<li><p>就绪状态：进程被加入到就绪队列中等待CPU调度运行；</p>
</li>
<li><p>执行状态：进程正在被运行；</p>
</li>
<li><p>等待阻塞状态：进程因为某种原因，比如等待I/O，等待设备，而暂时不能运行；</p>
</li>
<li><p>终止状态：进程运行完毕。</p>
</li>
</ol>
<h3 id="交换技术"><a href="#交换技术" class="headerlink" title="交换技术"></a>交换技术</h3><p>当多个进程竞争内存资源时，会造成内存资源紧张，并且，如果此时没有就绪进程，处理机会空闲，I/0速度比处理机速度慢得多，可能出现全部进程阻塞等待I/O。</p>
<p>针对以上问题，提出了两种解决方法：</p>
<ul>
<li><p>交换技术：换出一部分进程到外存，腾出内存空间。</p>
</li>
<li><p>虚拟存储技术：每个进程只能装入一部分程序和数据。</p>
</li>
</ul>
<p>在交换技术上，将内存暂时不能运行的进程，或者暂时不用的数据和程序，换出到外存，来腾出足够的内存空间，把已经具备运行条件的进程，或进程所需的数据和程序换入到内存。</p>
<p>从而出现了进程的挂起状态：进程被交换到外存，进程状态就成为了挂起状态。</p>
<h3 id="活动阻塞，静止阻塞，活动就绪，静止就绪"><a href="#活动阻塞，静止阻塞，活动就绪，静止就绪" class="headerlink" title="活动阻塞，静止阻塞，活动就绪，静止就绪"></a>活动阻塞，静止阻塞，活动就绪，静止就绪</h3><ul>
<li><p>活动阻塞：进程在内存，但是由于某种原因被阻塞了。</p>
</li>
<li><p>静止阻塞：进程在外存，同时被某种原因阻塞了。</p>
</li>
<li><p>活动就绪：进程在内存，处于就绪状态，只要给CPU和调度就可以直接运行。</p>
</li>
<li><p>静止就绪：进程在外存，处于就绪状态，只要调度到内存，给CPU和调度就可以运行。</p>
</li>
</ul>
<p>从而出现了：</p>
<p>活动就绪 ——  静止就绪（内存不够，调到外存）</p>
<p>活动阻塞 ——  静止阻塞（内存不够，调到外存）</p>
<p>执行     ——  静止就绪（时间片用完）</p>
<h2 id="给你一个类，里面有static、virtual之类的，来说一说这个类的内存分布"><a href="#给你一个类，里面有static、virtual之类的，来说一说这个类的内存分布" class="headerlink" title="给你一个类，里面有static、virtual之类的，来说一说这个类的内存分布"></a>给你一个类，里面有static、virtual之类的，来说一说这个类的内存分布</h2><h3 id="static修饰符"><a href="#static修饰符" class="headerlink" title="static修饰符"></a>static修饰符</h3><h4 id="static修饰成员变量"><a href="#static修饰成员变量" class="headerlink" title="static修饰成员变量"></a>static修饰成员变量</h4><p>对于非静态数据成员，每个类对象都有自己的拷贝。而静态数据成员被当做是类的成员，无论这个类被定义了多少个，静态数据成员都只有一份拷贝，为该类型的所有对象所共享（包括其派生类）。所以，静态数据成员的值对每个对象都是一样的，它的值可以更新。</p>
<p>因为静态数据成员在全局数据区分配内存，属于本类的所有对象共享，所以它不属于特定的类对象，在没有产生类对象前就可以使用。</p>
<h4 id="static修饰成员函数"><a href="#static修饰成员函数" class="headerlink" title="static修饰成员函数"></a>static修饰成员函数</h4><p><strong>与普通的成员函数相比，静态成员函数由于不是与任何的对象相联系，因此它不具有this指针。从这个意义上来说，它无法访问属于类对象的非静态数据成员，也无法访问非静态成员函数，只能调用其他的静态成员函数。</strong></p>
<p>static修饰的成员函数，在代码区分配内存。</p>
<h3 id="C-继承和虚函数"><a href="#C-继承和虚函数" class="headerlink" title="C++继承和虚函数"></a>C++继承和虚函数</h3><p>C++多态分为静态多态和动态多态。静态多态是通过重载和模板技术实现，在编译的时候确定。动态多态通过虚函数和继承关系来实现，执行动态绑定，在运行的时候确定。</p>
<p>动态多态实现有几个条件：</p>
<ol>
<li><p>虚函数；</p>
</li>
<li><p>一个基类的指针或引用指向派生类的对象；</p>
</li>
</ol>
<p>基类指针在调用成员函数（虚函数）时，就会去查找该对象的虚函数表。虚函数表的地址在每个对象的首地址。查找该虚函数表中该函数的指针进行调用。</p>
<p>每个对象中保存的只是一个虚函数表的指针，C++内部为每一个类维持一个虚函数表，该类的对象的都指向这同一个虚函数表。</p>
<p>虚函数表中为什么就能准确查找相应的函数指针呢？因为在类设计的时候，虚函数表直接从基类也继承过来，如果覆盖了其中的某个虚函数，那么虚函数表的指针就会被替换，因此可以根据指针准确找到该调用哪个函数。</p>
<h3 id="virtual修饰符"><a href="#virtual修饰符" class="headerlink" title="virtual修饰符"></a>virtual修饰符</h3><p><strong>如果一个类是局部变量则该类数据存储在栈区，如果一个类是通过new/malloc动态申请的，则该类数据存储在堆区。</strong></p>
<p>如果该类是virutal继承而来的子类，则该类的虚函数表指针和该类其他成员一起存储。虚函数表指针指向只读数据段中的类虚函数表，虚函数表中存放着一个个函数指针，函数指针指向代码段中的具体函数。</p>
<p>如果类中成员是virtual属性，会隐藏父类对应的属性。</p>
<p><img src="/2020/03/21/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%95%B4%E7%90%86/栈区堆区.png" srcset="/img/loading.gif" alt="栈区堆区"></p>
<h2 id="回答一下软链接和硬链接区别"><a href="#回答一下软链接和硬链接区别" class="headerlink" title="回答一下软链接和硬链接区别"></a>回答一下软链接和硬链接区别</h2><p>为了解决文件共享问题，Linux引入了软链接和硬链接。除了为Linux解决文件共享使用，还带来了隐藏文件路径、增加权限安全及节省存储等好处。</p>
<ul>
<li>若1个inode号对应多个文件名，则为硬链接，即硬链接就是同一个文件使用了不同的 <strong>别名</strong>，使用 <code>ln</code> 创建。</li>
<li>若文件用户数据块中存放的内容是另一个文件的路径名指向，则该文件是软连接。软连接是一个普通文件，<strong>有自己独立的inode</strong>，但是其数据块内容比较特殊。</li>
</ul>
<h2 id="什么是大端小端以及如何判断大端小端"><a href="#什么是大端小端以及如何判断大端小端" class="headerlink" title="什么是大端小端以及如何判断大端小端"></a>什么是大端小端以及如何判断大端小端</h2><p>大端是指低字节存储在高地址；小端存储是指低字节存储在低地址。</p>
<p>我们可以根据联合体来判断该系统是大端还是小端。因为联合体变量总是从低地址存储。</p>
<p><img src="/2020/03/21/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%95%B4%E7%90%86/测试大端小端.png" srcset="/img/loading.gif" alt="测试大端小端"></p>
<h2 id="静态变量什么时候初始化"><a href="#静态变量什么时候初始化" class="headerlink" title="静态变量什么时候初始化"></a>静态变量什么时候初始化</h2><p>静态变量存储在虚拟地址空间的数据段和BSS段。</p>
<p>C语言中其在代码执行之前初始化，属于编译期初始化。</p>
<p>而C++中由于引入对象，对象生成必须调用构造函数，因此C++规定全局或局部静态对象当且仅当对象首次用到时进行构造。</p>
<h2 id="说一说用户态和内核态区别"><a href="#说一说用户态和内核态区别" class="headerlink" title="说一说用户态和内核态区别"></a>说一说用户态和内核态区别</h2><p>用户态和内核态是操作系统的两种运行级别，<strong>两者最大的区别就是特权级不同</strong>。用户态拥有最低的特权级，内核态拥有较高的特权级。运行在用户态的程序不能直接访问操作系统内核数据结构和程序。</p>
<p>内核态和用户态之间的转换方式主要包括：系统调用、异常和中断。</p>
<h2 id="如何设计server，使得能够接收多个客户端的请求"><a href="#如何设计server，使得能够接收多个客户端的请求" class="headerlink" title="如何设计server，使得能够接收多个客户端的请求"></a>如何设计server，使得能够接收多个客户端的请求</h2><p>多线程，线程池，IO复用</p>
<h2 id="死循环-来连接时新建线程的方法效率有点低，怎么改进"><a href="#死循环-来连接时新建线程的方法效率有点低，怎么改进" class="headerlink" title="死循环+来连接时新建线程的方法效率有点低，怎么改进"></a>死循环+来连接时新建线程的方法效率有点低，怎么改进</h2><p>提前创建好一个线程池，用生产者消费者模型，创建一个任务队列，队列作为临界资源，有了新连接，就挂在到任务队列上，队列为空所有线程睡眠。</p>
<p>改进死循环：使用select epoll这样的技术。</p>
<h2 id="怎么唤醒被阻塞的socket线程"><a href="#怎么唤醒被阻塞的socket线程" class="headerlink" title="怎么唤醒被阻塞的socket线程"></a>怎么唤醒被阻塞的socket线程</h2><p>给阻塞时候缺少的资源。</p>
<h2 id="怎样确定当前线程是繁忙还是阻塞"><a href="#怎样确定当前线程是繁忙还是阻塞" class="headerlink" title="怎样确定当前线程是繁忙还是阻塞"></a>怎样确定当前线程是繁忙还是阻塞</h2><p>使用ps命令查看。</p>
<h2 id="请问就绪状态的进程在等待什么"><a href="#请问就绪状态的进程在等待什么" class="headerlink" title="请问就绪状态的进程在等待什么"></a>请问就绪状态的进程在等待什么</h2><p>被调度使用cpu的运行权。</p>
<h2 id="说一说多线程的同步，锁的机制"><a href="#说一说多线程的同步，锁的机制" class="headerlink" title="说一说多线程的同步，锁的机制"></a>说一说多线程的同步，锁的机制</h2><p>同步的时候用一个互斥量，在访问共享资源前对互斥量进行加锁，在访问完成后释放互斥量上的锁。对互斥量进行加锁以后，任何其他试图再次对互斥量加锁的线程将会被阻塞直到当前线程释放该互斥锁。如果释放互斥锁时有多个线程阻塞，所有在该互斥锁上的阻塞线程都会变成可运行状态，第一个变为运行状态的线程可以对互斥量加锁，其他线程将会看到互斥锁依然被锁住，只能回去再次等待它重新变为可用。在这种方式下，每次只有一个线程可以向前执行。</p>
<h2 id="两个进程访问临界区资源，会不会出现都获得自旋锁的情况"><a href="#两个进程访问临界区资源，会不会出现都获得自旋锁的情况" class="headerlink" title="两个进程访问临界区资源，会不会出现都获得自旋锁的情况"></a>两个进程访问临界区资源，会不会出现都获得自旋锁的情况</h2><p>单核cpu，并且开了抢占可以造成这种情况。</p>
<h2 id="说一说内存溢出和内存泄漏"><a href="#说一说内存溢出和内存泄漏" class="headerlink" title="说一说内存溢出和内存泄漏"></a>说一说内存溢出和内存泄漏</h2><h3 id="内存溢出"><a href="#内存溢出" class="headerlink" title="内存溢出"></a>内存溢出</h3><p>指程序申请内存时，没有足够的内存供申请者使用。内存溢出就是你要的内存空间超过了系统实际分配给你的空间，此时系统相当于没法满足你的需求，就会报内存溢出的错误。</p>
<h4 id="内存溢出原因"><a href="#内存溢出原因" class="headerlink" title="内存溢出原因"></a>内存溢出原因</h4><ul>
<li><p>内存中加载的数据量过于庞大，如一次从数据库取出过多数据；</p>
</li>
<li><p>集合类中有对对象的引用，使用完后未清空，使得不能回收；</p>
</li>
<li><p>代码中存在死循环或循环产生过多重复的对象实体；</p>
</li>
<li><p>使用的第三方软件中的BUG；</p>
</li>
<li><p>启动参数内存值设定的过小。</p>
</li>
</ul>
<h3 id="内存泄漏"><a href="#内存泄漏" class="headerlink" title="内存泄漏"></a>内存泄漏</h3><p>内存泄漏是指由于疏忽或错误造成了程序未能释放掉不再使用的内存的情况。内存泄漏并非指内存在物理上的消失，而是应用程序分配某段内存后，由于设计错误，失去了对该段内存的控制，因而造成了内存的浪费。</p>
<h4 id="内存泄漏的分类"><a href="#内存泄漏的分类" class="headerlink" title="内存泄漏的分类"></a>内存泄漏的分类</h4><ol>
<li><p>堆内存泄漏（Heap leak）。对内存指的是程序运行中根据需要分配通过malloc、realloc、new等从堆中分配的一块内存，再是完成后必须通过调用对应的free或者delete删掉。如果程序的设计的错误导致这部分内存没有被释放，那么此后这块内存将不会被使用，就会产生Heap Leak。</p>
</li>
<li><p>系统资源泄露（Resource Leak）。主要指程序使用系统分配的资源比如Bitmap、handle、socket等没有使用相应的函数释放掉，导致系统资源的浪费，严重可导致系统效能降低，系统运行不稳定。</p>
</li>
<li><p>没有将基类的析构函数定义为虚函数。当基类指针指向子类对象时，如果基类的析构函数不是virtual，那么子类的析构函数将不会被调用，子类的资源没有正确是释放，因此造成内存泄露。</p>
</li>
</ol>
<h2 id="常用线程模型"><a href="#常用线程模型" class="headerlink" title="常用线程模型"></a>常用线程模型</h2><h3 id="Future模型"><a href="#Future模型" class="headerlink" title="Future模型"></a>Future模型</h3><p>该模型通常在使用的时候需要结合Callable接口配合使用。</p>
<p>Future是把结果放在将来获取，当前主线程并不急于获取处理结果。允许子线程先进行处理一段时间，处理结束之后就把结果保存下来，当主线程需要使用的时候再向子线程索取。</p>
<p>Callable是类似于Runnable的接口，其中call方法类似于run方法，所不同的是run方法不能抛出受检异常没有返回值，而call方法则可以抛出受检异常并可设置返回值。两者的方法体都是线程执行体。</p>
<h3 id="fork-amp-join模型"><a href="#fork-amp-join模型" class="headerlink" title="fork&amp;join模型"></a>fork&amp;join模型</h3><p>该模型包含递归思想和回溯思想，递归用来拆分任务，回溯用合并结果。可以用来处理一些可以进行拆分的大任务。其主要是把一个大任务逐级拆分为多个子任务，然后分别在子线程中执行，当每个子线程执行结束之后逐级回溯，返回结果进行汇总合并，最终得出想要的结果。</p>
<p>这里模拟一个摘苹果的场景：有100棵苹果树，每棵苹果树有10个苹果，现在要把他们摘下来。为了节约时间，规定每个线程最多只能摘10棵苹树以便于节约时间。各个线程摘完之后汇总计算总苹果树。</p>
<h3 id="actor模型"><a href="#actor模型" class="headerlink" title="actor模型"></a>actor模型</h3><p>actor模型属于一种基于消息传递机制并行任务处理思想，它以消息的形式来进行线程间数据传输，避免了全局变量的使用，进而避免了数据同步错误的隐患。actor在接受到消息之后可以自己进行处理，也可以继续传递（分发）给其它actor进行处理。在使用actor模型的时候需要使用第三方Akka提供的框架。</p>
<h3 id="生产者消费者模型"><a href="#生产者消费者模型" class="headerlink" title="生产者消费者模型"></a>生产者消费者模型</h3><p>生产者消费者模型都比较熟悉，其核心是使用一个缓存来保存任务。开启一个/多个线程来生产任务，然后再开启一个/多个来从缓存中取出任务进行处理。这样的好处是任务的生成和处理分隔开，生产者不需要处理任务，只负责向生成任务然后保存到缓存。而消费者只需要从缓存中取出任务进行处理。使用的时候可以根据任务的生成情况和处理情况开启不同的线程来处理。比如，生成的任务速度较快，那么就可以灵活的多开启几个消费者线程进行处理，这样就可以避免任务的处理响应缓慢的问题。</p>
<h3 id="master-worker模型"><a href="#master-worker模型" class="headerlink" title="master-worker模型"></a>master-worker模型</h3><p>master-worker模型类似于任务分发策略，开启一个master线程接收任务，然后在master中根据任务的具体情况进行分发给其它worker子线程，然后由子线程处理任务。如需返回结果，则worker处理结束之后把处理结果返回给master。</p>
<h2 id="说一说协程"><a href="#说一说协程" class="headerlink" title="说一说协程"></a>说一说协程</h2><h3 id="概念-2"><a href="#概念-2" class="headerlink" title="概念"></a>概念</h3><p>协程，又称微线程，纤程，英文名Coroutine。协程看上去也是子程序，但执行过程中，在子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行。</p>
<p>例如：</p>
<pre><code class="lang-Python">def A():
    print(&#39;1&#39;)
    print(&#39;2&#39;)
    print(&#39;3&#39;)
def B():
    print(&#39;x&#39;)
    print(&#39;y&#39;)
    print(&#39;z&#39;)
</code></pre>
<p>由协程运行结果可能是12x3yz。在执行A的过程中，可以随时中断，去执行B，B也可能在执行过程中中断再去执行A。但协程的特点在于是一个线程执行。</p>
<h3 id="协程和线程区别"><a href="#协程和线程区别" class="headerlink" title="协程和线程区别"></a>协程和线程区别</h3><p>那和多线程比，协程最大的优势就是协程极高的执行效率。</p>
<p>因为子程序切换不是线程切换，而是由程序自身控制，因此，<strong>没有线程切换的开销</strong>，和多线程比，线程数量越多，协程的性能优势就越明显。</p>
<p>第二大优势就是 <strong>不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突</strong>，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。</p>
<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p>在协程上利用多核CPU呢——多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。</p>
<p>Python对协程的支持还非常有限，用在generator中的yield可以一定程度上实现协程。虽然支持不完全，但已经可以发挥相当大的威力了。</p>
<h2 id="系统调用是什么，你用过哪些系统调用"><a href="#系统调用是什么，你用过哪些系统调用" class="headerlink" title="系统调用是什么，你用过哪些系统调用"></a>系统调用是什么，你用过哪些系统调用</h2><h3 id="概念-3"><a href="#概念-3" class="headerlink" title="概念"></a>概念</h3><p>在计算机中，系统调用（英语：system call），又称为系统呼叫，指运行在使用者空间的程序向操作系统内核请求需要更高权限运行的服务。系统调用提供了用户程序与操作系统之间的接口（即系统调用是用户程序和内核交互的接口）。</p>
<p>操作系统中的状态分为管态（内核态）和目态（用户态）。大多数系统交互式操作需求在内核态执行。如设备IO操作或者进程间通信。特权指令：一类只能在核心态下运行而不能在用户态下运行的特殊指令。不同的操作系统特权指令会有所差异，但是一般来说主要是和硬件相关的一些指令。用户程序只在用户态下运行，有时需要访问系统核心功能，这时通过系统调用接口使用系统调用。</p>
<p>应用程序有时会需要一些危险的、权限很高的指令，如果把这些权限放心地交给用户程序是很危险的（比如一个进程可能修改另一个进程的内存区，导致其不能运行），但是又不能完全不给这些权限。于是有了系统调用，危险的指令被包装成系统调用，用户程序只能调用而无权自己运行那些危险的指令。另外，计算机硬件的资源是有限的，为了更好的管理这些资源，所有的资源都由操作系统控制，进程只能向操作系统请求这些资源。操作系统是这些资源的唯一入口，这个入口就是系统调用。</p>
<h3 id="系统调用举例"><a href="#系统调用举例" class="headerlink" title="系统调用举例"></a>系统调用举例</h3><p>对文件进行写操作，程序向打开的文件写入字符串“hello world”，open和write都是系统调用。如下：</p>
<pre><code class="lang-C++">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;errno.h&gt;
#include &lt;unistd.h&gt;
#include &lt;sys/types.h&gt;
#include &lt;sys/stat.h&gt;
#include &lt;fcntl.h&gt;
int main(int argc, char *argv[])
{
    if (argc &lt; 2)
        return 0;
    //用读写追加方式打开一个已经存在的文件
    int fd = open(argv[1], O_RDWR | O_APPEND);
    if (fd == -1)
    {
        printf(&quot;error is %s\n&quot;, strerror(errno));
    }
    else
    {
        //打印文件描述符号
        printf(&quot;success fd = %d\n&quot;, fd);
        char buf[100];
        memset(buf, 0, sizeof(buf));
        strcpy(buf, &quot;hello world\n&quot;);
        write(fd, buf, strlen(buf));
        close(fd);
    }
    return 0;
}
</code></pre>
<p>还有写数据write，创建进程fork，vfork等都是系统调用。</p>
<h2 id="手写一下fork调用示例"><a href="#手写一下fork调用示例" class="headerlink" title="手写一下fork调用示例"></a>手写一下fork调用示例</h2><h3 id="概念-4"><a href="#概念-4" class="headerlink" title="概念"></a>概念</h3><p>fork：创建一个和当前进程映像一样的进程可以通过 <code>fork()</code> 系统调用：</p>
<p>成功调用 <code>fork()</code> 会创建一个新的进程，它几乎与调用 <code>fork()</code> 的进程一模一样，这两个进程都会继续运行。在子进程中，成功的 <code>fork()</code> 调用会返回0。在父进程中 <code>fork()</code> 返回子进程的pid。如果出现错误，<code>fork()</code> 返回一个负值。</p>
<p>最常见的 <code>fork()</code> 用法是创建一个新的进程，然后使用exec()载入二进制映像，替换当前进程的映像。这种情况下，派生（fork）了新的进程，而这个子进程会执行一个新的二进制可执行文件的映像。这种“派生加执行”的方式是很常见的。</p>
<p>在早期的Unix系统中，创建进程比较原始。当调用fork时，内核会把所有的内部数据结构复制一份，复制进程的页表项，然后把父进程的地址空间中的内容逐页的复制到子进程的地址空间中。但从内核角度来说，逐页的复制方式是十分耗时的。现代的Unix系统采取了更多的优化，例如Linux，采用了写时复制的方法，而不是对父进程空间进程整体复制。</p>
<h3 id="fork实例"><a href="#fork实例" class="headerlink" title="fork实例"></a>fork实例</h3><pre><code class="lang-C++">int main(void)
{
    pid_t pid;
    signal(SIGCHLD, SIG_IGN);
    printf(&quot;before fork pid:%d\n&quot;, getpid());
    int abc = 10;
    pid = fork();
    if (pid == -1) //错误返回
    {
        perror(&quot;tile&quot;);
        return -1;
    }
    if (pid &gt; 0) //父进程空间
    {
        abc++;
        printf(&quot;parent:pid:%d \n&quot;, getpid());
        printf(&quot;abc:%d \n&quot;, abc);
        sleep(20);
    }
    else if (pid == 0) //子进程空间
    {
        abc++;
        printf(&quot;child:%d, parent: %d\n&quot;, getpid(), getppid());
        printf(&quot;abc:%d&quot;, abc);
    }
    printf(&quot;fork after...\n&quot;);
}
</code></pre>
<h2 id="说一说用户态到内核态的转化原理"><a href="#说一说用户态到内核态的转化原理" class="headerlink" title="说一说用户态到内核态的转化原理"></a>说一说用户态到内核态的转化原理</h2><h3 id="用户态切换到内核态的3种方式"><a href="#用户态切换到内核态的3种方式" class="headerlink" title="用户态切换到内核态的3种方式"></a>用户态切换到内核态的3种方式</h3><ol>
<li><p>系统调用</p>
<p>  这是用户进程主动要求切换到内核态的一种方式，用户进程通过系统调用申请操作系统提供的服务程序完成工作。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的ine 80h中断。</p>
</li>
<li><p>异常</p>
<p>  当CPU在执行运行在用户态的程序时，发现了某些事件不可知的异常，这是会触发由当前运行进程切换到处理此。异常的内核相关程序中，也就到了内核态，比如缺页异常。</p>
</li>
<li><p>外围设备的中断</p>
<p>  当外围设备完成用户请求的操作之后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条将要执行的指令，转而去执行中断信号的处理程序，如果先执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了有用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。</p>
</li>
</ol>
<h3 id="切换操作"><a href="#切换操作" class="headerlink" title="切换操作"></a>切换操作</h3><p>从出发方式看，可以在认为存在前述3种不同的类型，但是从最终实际完成由用户态到内核态的切换操作上来说，涉及的关键步骤是完全一样的，没有任何区别，都相当于执行了一个中断响应的过程，因为系统调用实际上最终是中断机制实现的，而异常和中断处理机制基本上是一样的，用户态切换到内核态的步骤主要包括：</p>
<ol>
<li><p>从当前进程的描述符中提取其内核栈的ss0及esp0信息；</p>
</li>
<li><p>使用ss0和esp0指向的内核栈将当前进程的cs、eip、eflags、ss、esp信息保存起来，这个过程也完成了由用户栈找到内核栈的切换过程，同时保存了被暂停执行的程序的下一条指令；</p>
</li>
<li><p>将先前由中断向量检索得到的中断处理程序的cs、eip信息装入相应的寄存器，开始执行中断处理程序，这时就转到了内核态的程序执行了。</p>
</li>
</ol>
<h2 id="说一下源码到可执行文件的过程"><a href="#说一下源码到可执行文件的过程" class="headerlink" title="说一下源码到可执行文件的过程"></a>说一下源码到可执行文件的过程</h2><h3 id="预编译"><a href="#预编译" class="headerlink" title="预编译"></a>预编译</h3><p>主要处理源代码文件中的以 <code>#</code> 开头的预编译指令。处理规则见下</p>
<ol>
<li><p>删除所有的 <code>#define</code>，展开所有的宏定义。</p>
</li>
<li><p>处理所有的条件预编译指令，如 <code>#if</code>、<code>#endif</code>、<code>#ifdef</code>、<code>#elif</code> 和 <code>#else</code>。</p>
</li>
<li><p>处理 <code>#include</code> 预编译指令，将文件内容替换到它的位置，这个过程是递归进行的，文件中包含其他文件。</p>
</li>
<li><p>删除所有的注释，<code>//</code> 和 <code>/**/</code>。</p>
</li>
<li><p>保留所有的 <code>#pragma</code> 编译器指令，编译器需要用到他们，如：<code>#pragma once</code> 是为了防止有文件被重复引用。</p>
</li>
<li><p>添加行号和文件标识，便于编译时编译器产生调试用的行号信息，和编译时产生编译错误或警告是能够显示行号。</p>
</li>
</ol>
<h3 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h3><p>把预编译之后生成的 <code>xxx.i</code> 或 <code>xxx.ii</code> 文件，进行一系列词法分析、语法分析、语义分析及优化后，生成相应的汇编代码文件。</p>
<ol>
<li><p>词法分析：利用类似于“有限状态机”的算法，将源代码程序输入到扫描机中，将其中的字符序列分割成一系列的记号。</p>
</li>
<li><p>语法分析：语法分析器对由扫描器产生的记号，进行语法分析，产生语法树。由语法分析器输出的语法树是一种以表达式为节点的树。</p>
</li>
<li><p>语义分析：语法分析器只是完成了对表达式语法层面的分析，语义分析器则对表达式是否有意义进行判断，其分析的语义是静态语义——在编译期能分期的语义，相对应的动态语义是在运行期才能确定的语义。</p>
</li>
<li><p>优化：源代码级别的一个优化过程。</p>
</li>
<li><p>目标代码生成：由代码生成器将中间代码转换成目标机器代码，生成一系列的代码序列——汇编语言表示。</p>
</li>
<li><p>目标代码优化：目标代码优化器对上述的目标机器代码进行优化：寻找合适的寻址方式、使用位移来替代乘法运算、删除多余的指令等。</p>
</li>
</ol>
<h3 id="汇编"><a href="#汇编" class="headerlink" title="汇编"></a>汇编</h3><p>将汇编代码转变成机器可以执行的指令（机器码文件）。 汇编器的汇编过程相对于编译器来说更简单，没有复杂的语法，也没有语义，更不需要做指令优化，只是根据汇编指令和机器指令的对照表一一翻译过来，汇编过程有汇编器as完成。经汇编之后，产生目标文件（与可执行文件格式几乎一样）<code>xxx.o（Windows下）</code>、<code>xxx.obj（Linux下）</code>。</p>
<h3 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h3><p>将不同的源文件产生的目标文件进行链接，从而形成一个可以执行的程序。链接分为静态链接和动态链接：</p>
<h4 id="静态链接"><a href="#静态链接" class="headerlink" title="静态链接"></a>静态链接</h4><p>函数和数据被编译进一个二进制文件。在使用静态库的情况下，在编译链接可执行文件时，链接器从库中复制这些函数和数据并把它们和应用程序的其它模块组合起来创建最终的可执行文件。</p>
<p>空间浪费：因为每个可执行程序中对所有需要的目标文件都要有一份副本，所以如果多个程序对同一个目标文件都有依赖，会出现同一个目标文件都在内存存在多个副本；</p>
<p>更新困难：每当库函数的代码修改了，这个时候就需要重新进行编译链接形成可执行程序。</p>
<p>运行速度快：但是静态链接的优点就是，在可执行程序中已经具备了所有执行程序所需要的任何东西，在执行的时候运行速度快。</p>
<h4 id="动态链接"><a href="#动态链接" class="headerlink" title="动态链接"></a>动态链接</h4><p>动态链接的基本思想是把程序按照模块拆分成各个相对独立部分，在程序运行时才将它们链接在一起形成一个完整的程序，而不是像静态链接一样把所有程序模块都链接成一个单独的可执行文件。</p>
<p>共享库：就是即使需要每个程序都依赖同一个库，但是该库不会像静态链接那样在内存中存在多分，副本，而是这多个程序在执行时共享同一份副本；</p>
<p>更新方便：更新时只需要替换原来的目标文件，而无需将所有的程序再重新链接一遍。当程序下一次运行时，新版本的目标文件会被自动加载到内存并且链接起来，程序就完成了升级的目标。</p>
<p>性能损耗：因为把链接推迟到了程序运行时，所以每次执行程序都需要进行链接，所以性能会有一定损失。</p>
<h2 id="说一下微内核与宏内核"><a href="#说一下微内核与宏内核" class="headerlink" title="说一下微内核与宏内核"></a>说一下微内核与宏内核</h2><h3 id="宏内核"><a href="#宏内核" class="headerlink" title="宏内核"></a>宏内核</h3><p>除了最基本的进程、线程管理、内存管理外，将文件系统、驱动、网络协议等等都集成在内核里面，例如Linux内核。</p>
<ul>
<li>优点：效率高。</li>
<li>缺点：稳定性差，开发过程中的bug经常会导致整个系统挂掉。</li>
</ul>
<h3 id="微内核"><a href="#微内核" class="headerlink" title="微内核"></a>微内核</h3><p>内核中只有最基本的调度、内存管理。驱动、文件系统等都是用户态的守护进程去实现的。</p>
<ul>
<li>优点：稳定。驱动等的错误只会导致相应进程死掉，不会导致整个系统都崩溃。</li>
<li>缺点：效率低。典型代表QNX，QNX的文件系统是跑在用户态的进程，称为resmgr的东西，是订阅发布机制，文件系统的错误只会导致这个守护进程挂掉。不过数据吞吐量就比较不乐观了。</li>
</ul>
<h2 id="说一下僵尸进程"><a href="#说一下僵尸进程" class="headerlink" title="说一下僵尸进程"></a>说一下僵尸进程</h2><h3 id="正常进程"><a href="#正常进程" class="headerlink" title="正常进程"></a>正常进程</h3><p>正常情况下，子进程是通过父进程创建的，子进程再创建新的进程。子进程的结束和父进程的运行是一个异步过程，即父进程永远无法预测子进程到底什么时候结束。 当一个进程完成它的工作终止之后，它的父进程需要调用 <code>wait()</code> 或者 <code>waitpid()</code> 系统调用取得子进程的终止状态。</p>
<p>Unix提供了一种机制可以保证只要父进程想知道子进程结束时的状态信息， 就可以得到：在每个进程退出的时候，内核释放该进程所有的资源，包括打开的文件、占用的内存等。但是仍然为其保留一定的信息，直到父进程通过wait / waitpid来取时才释放。</p>
<p>保存信息包括：</p>
<ol>
<li><p>进程号the process ID</p>
</li>
<li><p>退出状态the termination status of the process</p>
</li>
<li><p>运行时间the amount of CPU time taken by the process等</p>
</li>
</ol>
<h3 id="孤儿进程"><a href="#孤儿进程" class="headerlink" title="孤儿进程"></a>孤儿进程</h3><p>一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程（进程号为1）所收养，并由init进程对它们完成状态收集工作。</p>
<h3 id="僵尸进程"><a href="#僵尸进程" class="headerlink" title="僵尸进程"></a>僵尸进程</h3><p>一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵尸进程。</p>
<p>僵尸进程是一个进程必然会经过的过程：这是每个子进程在结束时都要经过的阶段。</p>
<p>如果子进程在exit()之后，父进程没有来得及处理，这时用ps命令就能看到子进程的状态是“Z”。如果父进程能及时处理，可能用ps命令就来不及看到子进程的僵尸状态，但这并不等于子进程不经过僵尸状态。</p>
<p>如果父进程在子进程结束之前退出，则子进程将由init接管。init将会以父进程的身份对僵尸状态的子进程进行处理。</p>
<h4 id="危害"><a href="#危害" class="headerlink" title="危害"></a>危害</h4><p>如果进程不调用wait / waitpid的话， 那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程。</p>
<h4 id="外部消灭"><a href="#外部消灭" class="headerlink" title="外部消灭"></a>外部消灭</h4><p>通过kill发送SIGTERM或者SIGKILL信号消灭产生僵尸进程的进程，它产生的僵死进程就变成了孤儿进程，这些孤儿进程会被init进程接管，init进程会wait()这些孤儿进程，释放它们占用的系统进程表中的资源。</p>
<h4 id="内部解决"><a href="#内部解决" class="headerlink" title="内部解决"></a>内部解决</h4><ol>
<li><p>子进程退出时向父进程发送SIGCHLD信号，父进程处理SIGCHLD信号。在信号处理函数中调用wait进行处理僵尸进程。</p>
</li>
<li><p>fork两次，原理是将子进程成为孤儿进程，从而其的父进程变为init进程，通过init进程可以处理僵尸进程。</p>
</li>
</ol>
<h2 id="GDB调试用过吗，什么是条件断点"><a href="#GDB调试用过吗，什么是条件断点" class="headerlink" title="GDB调试用过吗，什么是条件断点"></a>GDB调试用过吗，什么是条件断点</h2><h3 id="GDB调试"><a href="#GDB调试" class="headerlink" title="GDB调试"></a>GDB调试</h3><p>GDB 是自由软件基金会（Free Software Foundation）的软件工具之一。它的作用是协助程序员找到代码中的错误。如果没有GDB的帮助，程序员要想跟踪代码的执行流程，唯一的办法就是添加大量的语句来产生特定的输出。但这一手段本身就可能会引入新的错误，从而也就无法对那些导致程序崩溃的错误代码进行分析。</p>
<p>GDB的出现减轻了开发人员的负担，他们可以在程序运行的时候单步跟踪自己的代码，或者通过断点暂时中止程序的执行。此外，他们还能够随时察看变量和内存的当前状态，并监视关键的数据结构是如何影响代码运行的。</p>
<h3 id="条件断点"><a href="#条件断点" class="headerlink" title="条件断点"></a>条件断点</h3><p>条件断点是当满足条件就中断程序运行，命令：break line-or-function if expr。</p>
<p>例如：(gdb)break 666 if testsize==100</p>
<h2 id="介绍一下5种IO模型"><a href="#介绍一下5种IO模型" class="headerlink" title="介绍一下5种IO模型"></a>介绍一下5种IO模型</h2><ol>
<li><p>阻塞IO：调用者调用了某个函数，等待这个函数返回，期间什么也不做，不停的去检查这个函数有没有返回，必须等这个函数返回才能进行下一步动作。</p>
</li>
<li><p>非阻塞IO：非阻塞等待，每隔一段时间就去检测IO事件是否就绪。没有就绪就可以做其他事。</p>
</li>
<li><p>信号驱动IO：Linux用套接口进行信号驱动IO，安装一个信号处理函数，进程继续运行并不阻塞，当IO时间就绪，进程收到SIGIO信号。然后处理IO事件。</p>
</li>
<li><p>IO复用/多路转接IO：linux用select/poll函数实现IO复用模型，这两个函数也会使进程阻塞，但是和阻塞IO所不同的是这两个函数可以同时阻塞多个IO操作。而且可以同时对多个读操作、写操作的IO函数进行检测。知道有数据可读或可写时，才真正调用IO操作函数。</p>
</li>
<li><p>异步IO：Linux中，可以调用aio_read函数告诉内核描述字缓冲区指针和缓冲区的大小、文件偏移及通知的方式，然后立即返回，当内核将数据拷贝到缓冲区后，再通知应用程序。</p>
</li>
</ol>
<h2 id="说一说异步编程的事件循环"><a href="#说一说异步编程的事件循环" class="headerlink" title="说一说异步编程的事件循环"></a>说一说异步编程的事件循环</h2><p>事件循环就是不停循环等待时间的发生，然后将这个事件的所有处理器，以及他们订阅这个事件的时间顺序依次依次执行。当这个事件的所有处理器都被执行完毕之后，事件循环就会开始继续等待下一个事件的触发，不断往复。当同时并发地处理多个请求时，以上的概念也是正确的，可以这样理解：在单个的线程中，事件处理器是一个一个按顺序执行的。即如果某个事件绑定了两个处理器，那么第二个处理器会在第一个处理器执行完毕后，才开始执行。在这个事件的所有处理器都执行完毕之前，事件循环不会去检查是否有新的事件触发。在单个线程中，一切都是有顺序地一个一个地执行的。</p>
<h2 id="操作系统为什么要分内核态和用户态"><a href="#操作系统为什么要分内核态和用户态" class="headerlink" title="操作系统为什么要分内核态和用户态"></a>操作系统为什么要分内核态和用户态</h2><p>为了安全性。</p>
<p>在CPU的一些指令中，有的指令如果用错，将会导致整个系统崩溃。分了内核态和用户态后，当用户需要操作这些指令时候，内核为其提供了API，可以通过系统调用陷入内核，让内核去执行这些操作。</p>
<h2 id="为什么要有page-cache，操作系统怎么设计的page-cache"><a href="#为什么要有page-cache，操作系统怎么设计的page-cache" class="headerlink" title="为什么要有page cache，操作系统怎么设计的page cache"></a>为什么要有page cache，操作系统怎么设计的page cache</h2><p>加快从磁盘读取文件的速率。</p>
<p>page cache中有一部分磁盘文件的缓存，因为从磁盘中读取文件比较慢，所以读取文件先去page cache中去查找，如果命中，则不需要去磁盘中读取，大大加快读取速度。在 Linux 内核中，文件的每个数据块最多只能对应一个 Page Cache 项，它通过两个数据结构来管理这些 Cache<br>项，一个是radix tree，另一个是双向链表。Radix tree 是一种搜索树，Linux内核利用这个数据结构来通过文件内偏移快速定位Cache项。</p>
<h2 id="server端监听端口，但还没有客户端连接进来，此时进程处于什么状态"><a href="#server端监听端口，但还没有客户端连接进来，此时进程处于什么状态" class="headerlink" title="server端监听端口，但还没有客户端连接进来，此时进程处于什么状态"></a>server端监听端口，但还没有客户端连接进来，此时进程处于什么状态</h2><p>这个需要看服务端的编程模型，如果如上一个问题的回答描述的这样，则处于阻塞状态，如果使用了epoll、select等这样的io复用情况下，处于运行状态。</p>
<h2 id="怎么实现线程池"><a href="#怎么实现线程池" class="headerlink" title="怎么实现线程池"></a>怎么实现线程池</h2><ol>
<li>设置一个生产者消费者队列，作为临界资源；</li>
<li>初始化n个线程，并让其运行起来，加锁去队列取任务运行；</li>
<li>当任务队列为空的时候，所有线程阻塞；</li>
<li>当生产者队列来了一个任务后，先对队列加锁，把任务挂在到队列上，然后使用条件变量去通知阻塞中的一个线程。</li>
</ol>
<h2 id="Linux下怎么得到一个文件的100到200行"><a href="#Linux下怎么得到一个文件的100到200行" class="headerlink" title="Linux下怎么得到一个文件的100到200行"></a>Linux下怎么得到一个文件的100到200行</h2><pre><code class="lang-shell">sed -n &#39;100,200p&#39; inputfile
awk &#39;NR&gt;=100&amp;&amp;NR&lt;=200{print}&#39; inputfile
head -200 inputfile|tail -100
</code></pre>
<h2 id="说一下linux内核中的Timer定时器机制"><a href="#说一下linux内核中的Timer定时器机制" class="headerlink" title="说一下linux内核中的Timer定时器机制"></a>说一下linux内核中的Timer定时器机制</h2><h3 id="低精度时钟"><a href="#低精度时钟" class="headerlink" title="低精度时钟"></a>低精度时钟</h3><p>Linux 2.6.16之前，内核只支持低精度时钟，内核定时器的工作方式：</p>
<ol>
<li><p>系统启动后，会读取时钟源设备（RTC、HPET、PIT……），初始化当前系统时间。</p>
</li>
<li><p>内核会根据HZ（系统定时器频率，节拍率）参数值，设置时钟事件设备，启动tick（节拍）中断。HZ表示1秒种产生多少个时钟硬件中断，tick就表示连续两个中断的间隔时间。</p>
</li>
<li><p>设置时钟事件设备后，时钟事件设备会定时产生一个tick中断，触发时钟中断处理函数，更新系统时钟,并检测timer wheel，进行超时事件的处理。</p>
</li>
</ol>
<p>在上面工作方式下，Linux 2.6.16 之前，内核软件定时器采用timer wheel多级时间轮的实现机制，维护操作系统的所有定时事件。timer wheel的触发是基于系统tick周期性中断。</p>
<p>所以说这之前，linux只能支持ms级别的时钟，随着时钟源硬件设备的精度提高和软件高精度计时的需求，有了高精度时钟的内核设计。</p>
<h3 id="高精度时钟"><a href="#高精度时钟" class="headerlink" title="高精度时钟"></a>高精度时钟</h3><p>Linux 2.6.16 ，内核支持了高精度的时钟，内核采用新的定时器hrtimer，其实现逻辑和Linux 2.6.16 之前定时器逻辑区别：</p>
<p>hrtimer采用红黑树进行高精度定时器的管理，而不是时间轮；</p>
<p>高精度时钟定时器不在依赖系统的tick中断，而是基于事件触发。</p>
<p>旧内核的定时器实现依赖于系统定时器硬件定期的tick，基于该tick，内核会扫描timer wheel处理超时事件，会更新jiffies，wall time（墙上时间，现实时间），process的使用时间等等工作。</p>
<p>新的内核不再会直接支持周期性的tick，新内核定时器框架采用了基于事件触发，而不是以前的周期性触发。新内核实现了hrtimer（high resolution timer）：于事件触发。</p>
<p>hrtimer的工作原理：</p>
<p>通过将高精度时钟硬件的下次中断触发时间设置为红黑树中最早到期的Timer的时间，时钟到期后从红黑树中得到下一个 Timer 的到期时间，并设置硬件，如此循环反复。</p>
<p>在高精度时钟模式下，操作系统内核仍然需要周期性的tick中断，以便刷新内核的一些任务。hrtimer是基于事件的，不会周期性出发tick中断，所以为了实现周期性的tick中断（dynamic tick）：系统创建了一个模拟 tick 时钟的特殊 hrtimer，将其超时时间设置为一个tick时长，在超时回来后，完成对应的工作，然后再次设置下一个tick的超时时间，以此达到周期性tick中断的需求。</p>
<p>引入了dynamic tick，是为了能够在使用高精度时钟的同时节约能源，这样会产生tickless 情况下，会跳过一些 tick。</p>
<p>新内核对相关的时间硬件设备进行了统一的封装，定义了主要有下面两个结构：</p>
<p>时钟源设备（closk source device）：抽象那些能够提供计时功能的系统硬件，比如 RTC（Real Time Clock）、TSC（Time Stamp Counter），HPET，ACPI PM-Timer，PIT等。不同时钟源提供的精度不一样，现在pc大都是支持高精度模式（high-resolution mode）也支持低精度模式（low-resolution mode）。</p>
<p>时钟事件设备（clock event device）：系统中可以触发 one-shot（单次）或者周期性中断的设备都可以作为时钟事件设备。</p>
<p>当前内核同时存在新旧timer wheel 和 hrtimer两套timer的实现，内核启动后会进行从低精度模式到高精度时钟模式的切换，hrtimer模拟的tick中断将驱动传统的低精度定时器系统（基于时间轮）和内核进程调度。</p>

            </div>
            <hr>
            <div>
              <p>
                
                  <span>
                <i class="iconfont icon-inbox"></i>
                    
                      <a class="hover-with-bg" href="/categories/%E9%9D%A2%E7%BB%8F%E7%9F%A5%E8%AF%86%E6%B1%87%E6%80%BB/">面经知识汇总</a>
                      &nbsp;
                    
                  </span>&nbsp;&nbsp;
                
                
                  <span>
                <i class="iconfont icon-tag"></i>
                    
                      <a class="hover-with-bg" href="/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/">操作系统</a>
                    
                  </span>
                
              </p>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://zh.wikipedia.org/wiki/Wikipedia:CC_BY-SA_3.0%E5%8D%8F%E8%AE%AE%E6%96%87%E6%9C%AC" target="_blank" rel="nofollow noopener noopener">CC BY-SA 3.0协议</a> 。转载请注明出处！</p>
              
            </div>

            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc-start"></div>
<div id="toc">
  <p class="h5"><i class="far fa-list-alt"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->

  <div class="col-lg-7 mx-auto nopadding-md">
    <div class="container custom post-content mx-auto">
      <img src="https://octodex.github.com/images/jetpacktocat.png" srcset="/img/loading.gif" class="rounded mx-auto d-block mt-5" style="width:150px; height:150px;">
    </div>
  </div>


    
  </main>

  
    <a class="z-depth-1" id="scroll-top-button" href="#" role="button">
      <i class="fa fa-chevron-up scroll-top-arrow" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><b>Hexo</b></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"> <b>Fluid</b></a>
    </div>
    
  <div>
    
      <!-- 不蒜子统计PV -->
      
      <span id="busuanzi_container_site_pv" style="display: none">
      总访问量 <span id="busuanzi_value_site_pv"></span> 次
    </span>
    
    
      <!-- 不蒜子统计UV -->
      
      <span id="busuanzi_container_site_uv" style="display: none">
      总访客数 <span id="busuanzi_value_site_uv"></span> 人
    </span>
    
  </div>


    

    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/popper.js/1.16.1/umd/popper.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="https://cdn.staticfile.org/mdbootstrap/4.13.0/js/mdb.min.js" ></script>
<script  src="/js/main.js" ></script>


  <script  src="/js/lazyload.js" ></script>



  
  <script  src="https://cdn.staticfile.org/tocbot/4.10.0/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var navHeight = $('#navbar').height();
      var post = $('#post');
      var toc = $('#toc');
      var tocLimMax = post.offset().top + post.height() - navHeight;

      $(window).scroll(function () {
        var tocLimMin = $('#toc-start').offset().top - navHeight;
        var scroH = document.body.scrollTop + document.documentElement.scrollTop;

        if (tocLimMin <= scroH && scroH <= tocLimMax) {
          toc.css({
            'display': 'block',
            'position': 'fixed',
            'top': navHeight,
          });
        } else if (scroH <= tocLimMin) {
          toc.css({
            'position': '',
            'top': '',
          });
        } else if (scroH > tocLimMax) {
          toc.css('display', 'none');
        }
      });
      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: '.post-content',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        scrollSmooth: true,
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc > p').css('visibility', 'visible');
      }
      var offset = $('#board-ctn').css('margin-right')
      $('#toc-ctn').css({
        'right': offset
      })
    });
  </script>







  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




<!-- Plugins -->


  

  

  

  

  



  <script  src="https://cdn.staticfile.org/prettify/188.0.0/prettify.min.js" ></script>
  <script>
    $(document).ready(function () {
      $('pre').addClass('prettyprint  linenums');
      prettyPrint();
    })
  </script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "操作系统整理&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "left",
      visible: "hover",
      
      icon: "#"
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      getSearchFile(path);
      this.onclick = null
    }
  </script>



  <script defer src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <script>
    $("#post img:not(.no-zoom img, img[no-zoom])").each(
      function () {
        var element = document.createElement("a");
        $(element).attr("data-fancybox", "images");
        $(element).attr("href", $(this).attr("src"));
        $(this).wrap(element);
      }
    );
  </script>





  
  
    <script type="text/javascript">
      //定义获取词语下标
      var a_idx = 0;
      jQuery(document).ready(function ($) {
        //点击body时触发事件
        $("body").click(function (e) {
          //需要显示的词语
          var a = new Array("富强", "民主", "文明", "和谐", "自由", "平等", "公正", "法治", "爱国", "敬业", "诚信", "友善");
          //设置词语给span标签
          var $i = $("<span/>").text(a[a_idx]);
          //下标等于原来下标+1  余 词语总数
          a_idx = (a_idx + 1) % a.length;
          //获取鼠标指针的位置，分别相对于文档的左和右边缘。
          //获取x和y的指针坐标
          var x = e.pageX, y = e.pageY;
          //在鼠标的指针的位置给$i定义的span标签添加css样式
          $i.css({
            "z-index": 999,
            "top": y - 20,
            "left": x,
            "position": "absolute",
            "font-weight": "bold",
            "color": rand_color()
          });
          // 随机颜色
          function rand_color() {
            return "rgb(" + ~~(255 * Math.random()) + "," + ~~(255 * Math.random()) + "," + ~~(255 * Math.random()) + ")"
          }
          //在body添加这个标签
          $("body").append($i);
          //animate() 方法执行 CSS 属性集的自定义动画。
          //该方法通过CSS样式将元素从一个状态改变为另一个状态。CSS属性值是逐渐改变的，这样就可以创建动画效果。
          //详情请看http://www.w3school.com.cn/jquery/effect_animate.asp
          $i.animate({
            //将原来的位置向上移动180
            "top": y - 180,
            "opacity": 0
            //1500动画的速度
          }, 1500, function () {
            //时间到了自动删除
            $i.remove();
          });
        });
      })
      ;
    </script>
  








</body>
</html>
